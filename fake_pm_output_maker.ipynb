{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import emcee\n",
    "import corner\n",
    "from tqdm import tqdm\n",
    "\n",
    "import erfa\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "\n",
    "#matplotlib.rc('text',usetex=True)\n",
    "font = {'family' : 'serif',\n",
    "#        'weight' : 'bold',\n",
    "        'size'   : 16,}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_params(on_skew,off_skew,ratio,rot):\n",
    "    #on_skew = (a-d)/2\n",
    "    #off_skew = (b+c)/2\n",
    "    #ratio^2 = a*d-b*c\n",
    "    #tan(rot) = (b-c)/(a+d)\n",
    "    \n",
    "    tan_theta = np.tan(rot/180*np.pi)\n",
    "    sqrt_term = np.sqrt((tan_theta**2+1)*(ratio**2+on_skew**2+off_skew**2))\n",
    "    sign = np.sign(rot)\n",
    "    \n",
    "    a = sign*((sqrt_term+tan_theta**2*on_skew+on_skew)/(tan_theta**2+1))\n",
    "    b = sign*((tan_theta*sqrt_term+tan_theta**2*off_skew+off_skew)/(tan_theta**2+1))\n",
    "    c = sign*(-(tan_theta*sqrt_term)/(tan_theta**2+1)+off_skew)\n",
    "    d = sign*((sqrt_term)/(tan_theta**2+1)-on_skew)\n",
    "    \n",
    "    return a,b,c,d\n",
    "\n",
    "#test the size of changes in parameters versus the changes in output pixel position to get \n",
    "#a handle on appropriate parameter uncertainties\n",
    "\n",
    "'''Analyse the effect of changing/fixing the transformation parameters:\n",
    "1) use the first iteration of analysis to get a weighted average of each parameter (e.g. weighted by star counts);\n",
    "2) use those weighted average parameters (changing which ones are fixed) to see how the transformation changes\n",
    "for the X,Y of the found stars\n",
    "3) save the offsets in pixel distance and plot to summarize'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/Kevin_Astro/Astronomy/HST_Gaia_PMs/code/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in changes so that the G mags of the stars are draws from halo density profile\n",
    "#add in changes so that the proper motions are draws from what we expect for velocity ellipsoid & drawn distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.13445487019\n",
    "b = 0.98645672253\n",
    "c = -0.98680188642\n",
    "d = 0.13332047009\n",
    "\n",
    "# a = -0.38011904734\n",
    "# b = -0.91902649497\n",
    "# c = 0.91900293514\n",
    "# d = -0.38008157840\n",
    "\n",
    "pixel_scale_ratio = np.sqrt(a*d-b*c)\n",
    "rotation = np.arctan2(b-c,a+d)*180/np.pi\n",
    "on_axis_skew = 0.5*(a-d)\n",
    "off_axis_skew = 0.5*(b+c)\n",
    "print('Pixel Scale Ratio:',pixel_scale_ratio)\n",
    "print('Rotation (deg):',rotation)\n",
    "print('On Axis Skew:',on_axis_skew)\n",
    "print('Off Axis Skew:',off_axis_skew)\n",
    "\n",
    "np.array(get_matrix_params(on_axis_skew,off_axis_skew,pixel_scale_ratio,rotation)),np.array([a,b,c,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might want to incorporate realistic correlations in the uncertainties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m31_results = np.genfromtxt(f'{path}M31/M31_ra_11.675_dec_42.062_r_0.35.csv',names=True,delimiter=',')\n",
    "# m31_results = np.genfromtxt(f'{path}Fornax_dSph/Fornax_dSph_ra_39.997_dec_-34.449_r_0.92.csv',names=True,delimiter=',')\n",
    "# m31_results = np.genfromtxt(f'{path}Sculptor_dSph/Sculptor_dSph_ra_15.039_dec_-33.709_r_0.51.csv',names=True,delimiter=',')\n",
    "m31_results = np.genfromtxt(f'{path}COSMOS_field/Gaia/COSMOS_field_ra_150.119_dec_2.206_r_1.00_raw.csv',names=True,delimiter=',')\n",
    "\n",
    "gaia_pm_and_errs = np.array([m31_results['pmra'],m31_results['pmdec'],\n",
    "                             m31_results['pmra_error'],m31_results['pmdec_error']]).T\n",
    "gaia_pm_err_size = np.sqrt(np.power(gaia_pm_and_errs[:,2],2)+np.power(gaia_pm_and_errs[:,3],2))\n",
    "\n",
    "gaia_pos_and_errs = np.array([m31_results['ra'],m31_results['dec'],\n",
    "                             m31_results['ra_error'],m31_results['dec_error']]).T\n",
    "gaia_pos_err_size = np.sqrt(np.power(gaia_pos_and_errs[:,2],2)+np.power(gaia_pos_and_errs[:,3],2))\n",
    "\n",
    "\n",
    "# # pmra_string = 'pmra'\n",
    "# # pmra_err_string = 'pmra_error'\n",
    "# # pmdec_string = 'pmdec'\n",
    "# # pmdec_err_string = 'pmdec_error'\n",
    "# pmra_string = 'hst_gaia_pmra_wmean'\n",
    "# pmra_err_string = 'hst_gaia_pmra_wmean_error'\n",
    "# pmdec_string = 'hst_gaia_pmdec_wmean'\n",
    "# pmdec_err_string = 'hst_gaia_pmdec_wmean_error'\n",
    "\n",
    "# hst_pm_and_errs = np.array([m31_results[pmra_string],m31_results[pmdec_string],\n",
    "#                              m31_results[pmra_err_string],m31_results[pmdec_err_string]]).T\n",
    "# hst_pm_err_size = np.sqrt(np.power(hst_pm_and_errs[:,2],2)+np.power(hst_pm_and_errs[:,3],2))\n",
    "\n",
    "# plt.figure(figsize=([6,5]))\n",
    "# plt.scatter(m31_results['gmag'],gaia_pm_err_size,color='k',label='Gaia',s=2) \n",
    "# plt.scatter(m31_results['gmag'],hst_pm_err_size,color='r',label='Gaia+HST',s=2) \n",
    "# plt.legend(loc='best',markerscale=10)\n",
    "# plt.show()\n",
    "\n",
    "# pm_sizes = np.sqrt(np.power(m31_results[pmra_string],2)+np.power(m31_results[pmdec_string],2))\n",
    "# pm_size_errs = np.sqrt(np.power(m31_results[pmra_err_string]*m31_results[pmra_string]/pm_sizes,2)+\\\n",
    "#                        np.power(m31_results[pmdec_err_string]*m31_results[pmdec_string]/pm_sizes,2))\n",
    "# try:\n",
    "#     pm_size_and_errs = np.array([m31_results[pmra_string],m31_results[pmdec_string],\\\n",
    "#                                  m31_results[pmra_err_string],m31_results[pmdec_err_string],\\\n",
    "#                                  m31_results['gmag'],m31_results['F814W_mean']]).T\n",
    "# except:\n",
    "#     pm_size_and_errs = np.array([m31_results[pmra_string],m31_results[pmdec_string],\\\n",
    "#                                  m31_results[pmra_err_string],m31_results[pmdec_err_string],\\\n",
    "#                                  m31_results['gmag'],m31_results['F775W_mean']]).T\n",
    "# keep = np.all(np.isfinite(pm_size_and_errs),axis=1) & (m31_results['gmag'] > 18) & (pm_sizes < 25)# & (pm_sizes > 0)\n",
    "# pm_size_and_errs = pm_size_and_errs[keep]\n",
    "# print(len(pm_size_and_errs))\n",
    "\n",
    "# ave_pmra = np.median(pm_size_and_errs[:,0])\n",
    "# ave_pmdec = np.median(pm_size_and_errs[:,1])\n",
    "# #shift pm distribution so that it is centered at 0,0\n",
    "# pm_size_and_errs[:,0] -= ave_pmra\n",
    "# pm_size_and_errs[:,1] -= ave_pmdec\n",
    "\n",
    "# corner.corner(pm_size_and_errs,labels=[r'$\\mu_{RA}$',r'$\\mu_{Dec}$',r'$\\sigma_{RA}$',\n",
    "#                                        r'$\\sigma_{Dec}$','$G$ (mag)','F814W (mag)'], \n",
    "#                           quantiles=[0.16, 0.5, 0.84], show_titles=True,\n",
    "#                           title_kwargs={\"fontsize\": 12},bins=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.copy(m31_results['gmag'])\n",
    "# y = np.copy(gaia_pm_err_size)\n",
    "# keep = np.isfinite(x) & np.isfinite(y) & (x > 18)\n",
    "# x = x[keep]\n",
    "# y = y[keep]\n",
    "\n",
    "# def model(x, A, B, C):\n",
    "#     #sigma(mag) = C+A*exp(mag/B)\n",
    "#     return A*np.exp(x/B)+C\n",
    "\n",
    "# popt, pcov = curve_fit(model, x, y, maxfev = 100000)\n",
    "# A,B,C = popt\n",
    "# x_vals = np.linspace(18,21.5,100)\n",
    "# y_vals = model(x_vals,A,B,C)\n",
    "\n",
    "# # n_models = 1000\n",
    "# # model_draws = np.zeros((n_models,len(x_vals)))\n",
    "# # for j in range(n_models):\n",
    "# #     curr_A,curr_B,curr_C = stats.multivariate_normal(mean=popt,cov=pcov,allow_singular=True).rvs()\n",
    "# #     model_draws[j] = model(x_vals,curr_A,curr_B,curr_C)\n",
    "\n",
    "# # model_bounds = np.percentile(model_draws,[16,50,84],axis=0)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x,y)\n",
    "# plt.plot(x_vals,y_vals,color='C1')\n",
    "# # plt.plot(x_vals,model_bounds[1],color='r')\n",
    "# # plt.fill_between(x_vals,model_bounds[0],model_bounds[2],color='r',alpha=0.3)\n",
    "# plt.xlabel('G (mag)')\n",
    "# plt.ylabel('$\\sqrt{\\sigma_{mu_{RA}}^2+\\sigma_{mu_{Dec}}^2}$ (mas/yr)')\n",
    "# plt.show()\n",
    "\n",
    "# print(y_vals[[0,-1]])\n",
    "\n",
    "x = np.copy(m31_results['gmag'])\n",
    "y = np.copy(gaia_pm_err_size)\n",
    "keep = np.isfinite(x) & np.isfinite(y) & (x > 18)# & (y < 10)\n",
    "x = x[keep]\n",
    "y = y[keep]\n",
    "\n",
    "n_bins = 3\n",
    "x_bins = np.linspace(18,21,n_bins+1)\n",
    "n_bins = 15\n",
    "x_bins = np.array([18,18.5,19,19.5,20,20.25,20.5,20.75,21])\n",
    "x_bins = np.array([18,18.5,19,19.5,20,20.25,20.5])\n",
    "n_bins = len(x_bins)-1\n",
    "x_centers = 0.5*(x_bins[1:]+x_bins[:-1])\n",
    "y_bins = np.zeros((n_bins,3))\n",
    "y_compare = np.zeros((len(x),3))\n",
    "for j in range(n_bins):\n",
    "    in_bin = (x > x_bins[j]) & (x <= x_bins[j+1])\n",
    "    if np.sum(in_bin) == 0:\n",
    "#         y_bins[j] = np.nan\n",
    "        continue\n",
    "    y_bins[j] = np.percentile(y[in_bin],[16,50,84])\n",
    "    y_compare[in_bin] = y_bins[j]\n",
    "    \n",
    "# outliers = (y-y_compare[:,1] > 3*(y_compare[:,2]-y_compare[:,1])) | \\\n",
    "#             (y-y_compare[:,1] < -3*(y_compare[:,1]-y_compare[:,0]))\n",
    "# keep = ~outliers\n",
    "# x = x[keep]\n",
    "# y = y[keep]\n",
    "\n",
    "# y_bins = np.zeros((n_bins,3))\n",
    "# y_compare = np.zeros((len(x),3))\n",
    "# for j in range(n_bins):\n",
    "#     in_bin = (x > x_bins[j]) & (x <= x_bins[j+1])\n",
    "#     y_bins[j] = np.percentile(y[in_bin],[16,50,84])\n",
    "#     y_compare[in_bin] = y_bins[j]\n",
    "\n",
    "interp_pm_relationship = scipy.interpolate.interp1d(x_centers,y_bins[:,1],fill_value=\"extrapolate\")\n",
    "\n",
    "def pm_error(gmag):\n",
    "#     if gmag <= x_bins[0]:\n",
    "#         return y_bins[0,1]\n",
    "#     elif gmag >= x_bins[-1]:\n",
    "#         return y_bins[-1,1]\n",
    "#     else:\n",
    "#         ind = np.where((gmag > x_bins[:-1]) & (gmag <= x_bins[1:]))[0][0]\n",
    "#         return y_bins[ind,1]\n",
    "    return interp_pm_relationship(gmag)\n",
    "#     return np.sign(gmag)*0.5\n",
    "\n",
    "def model(x, A, B, C):\n",
    "    #sigma(mag) = C+A*exp(mag/B)\n",
    "    return A*np.exp(x/B)+C\n",
    "\n",
    "popt, pcov = curve_fit(model, x, y, maxfev = 100000)\n",
    "popt, pcov = curve_fit(model, x_centers, y_bins[:,1], sigma=0.5*(y_bins[:,2]-y_bins[:,0]),\n",
    "                               absolute_sigma=False, maxfev = 100000, p0=popt)\n",
    "A,B,C = popt\n",
    "x_vals = np.linspace(18,21.5,100)\n",
    "y_vals = model(x_vals,*popt)\n",
    "y_vals = pm_error(x_vals)\n",
    "\n",
    "# n_models = 1000\n",
    "# model_draws = np.zeros((n_models,len(x_vals)))\n",
    "# for j in range(n_models):\n",
    "#     curr_A,curr_B,curr_C = stats.multivariate_normal(mean=popt_pos,cov=pcov_pos,allow_singular=True).rvs()\n",
    "#     model_draws[j] = model(x_vals,curr_A,curr_B,curr_C)\n",
    "\n",
    "# model_bounds = np.percentile(model_draws,[16,50,84],axis=0)\n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x_vals,y_vals,color='C1')\n",
    "# plt.plot(x_vals,model_bounds[1],color='r')\n",
    "# plt.fill_between(x_vals,model_bounds[0],model_bounds[2],color='r',alpha=0.3)\n",
    "plt.plot(x_centers,y_bins[:,1],color='r')\n",
    "plt.fill_between(x_centers,y_bins[:,0],y_bins[:,2],color='r',alpha=0.3)\n",
    "plt.xlabel('G (mag)')\n",
    "plt.ylabel('$\\sqrt{\\sigma_{\\mu_{RA}}^2+\\sigma_{\\mu_{Dec}}^2}$ (mas/yr)')\n",
    "plt.show()\n",
    "\n",
    "print(y_vals[[0,-1]])\n",
    "print(y_bins[[0,-1],1])\n",
    "\n",
    "x = np.copy(m31_results['gmag'])\n",
    "y = np.copy(gaia_pos_err_size)\n",
    "keep = np.isfinite(x) & np.isfinite(y) & (x > 18) & (y < 10)\n",
    "x = x[keep]\n",
    "y = y[keep]\n",
    "\n",
    "n_bins = 15\n",
    "x_bins = np.linspace(18,21.5,n_bins+1)\n",
    "n_bins = 15\n",
    "x_bins = np.array([18,18.5,19,19.5,20,20.25,20.5,20.75,21,21.25,21.5])\n",
    "x_bins = np.array([18,18.5,19,19.5,20,20.25,20.5])\n",
    "stop_bins = np.where(x_bins > x.max())[0][-1]\n",
    "x_bins = x_bins[:stop_bins+1]\n",
    "print(x_bins)\n",
    "n_bins = len(x_bins)-1\n",
    "x_centers = 0.5*(x_bins[1:]+x_bins[:-1])\n",
    "y_bins = np.zeros((n_bins,3))\n",
    "y_compare = np.zeros((len(x),3))\n",
    "for j in range(n_bins):\n",
    "    in_bin = (x > x_bins[j]) & (x <= x_bins[j+1])\n",
    "    if np.sum(in_bin) == 0:\n",
    "#         y_bins[j] = np.nan\n",
    "        continue\n",
    "    y_bins[j] = np.percentile(y[in_bin],[16,50,84])\n",
    "    y_compare[in_bin] = y_bins[j]\n",
    "    \n",
    "outliers = (y-y_compare[:,1] > 3*(y_compare[:,2]-y_compare[:,1])) | \\\n",
    "            (y-y_compare[:,1] < -3*(y_compare[:,1]-y_compare[:,0]))\n",
    "keep = ~outliers\n",
    "x = x[keep]\n",
    "y = y[keep]\n",
    "\n",
    "y_bins = np.zeros((n_bins,3))\n",
    "y_compare = np.zeros((len(x),3))\n",
    "for j in range(n_bins):\n",
    "    in_bin = (x > x_bins[j]) & (x <= x_bins[j+1])\n",
    "    if np.sum(in_bin) == 0:\n",
    "#         y_bins[j] = np.nan\n",
    "        continue\n",
    "    y_bins[j] = np.percentile(y[in_bin],[16,50,84])\n",
    "    y_compare[in_bin] = y_bins[j]\n",
    "\n",
    "interp_pos_relationship = scipy.interpolate.interp1d(x_centers,y_bins[:,1],fill_value=\"extrapolate\")\n",
    "\n",
    "def pos_error(gmag):\n",
    "#     if gmag <= x_bins[0]:\n",
    "#         return y_bins[0,1]\n",
    "#     elif gmag >= x_bins[-1]:\n",
    "#         return y_bins[-1,1]\n",
    "#     else:\n",
    "#         ind = np.where((gmag > x_bins[:-1]) & (gmag <= x_bins[1:]))[0][0]\n",
    "#         return y_bins[ind,1]\n",
    "    return interp_pos_relationship(gmag)\n",
    "#     return np.sign(gmag)*0.5\n",
    "\n",
    "def model(x, A, B, C):\n",
    "    #sigma(mag) = C+A*exp(mag/B)\n",
    "    return A*np.exp(x/B)+C\n",
    "\n",
    "popt_pos, pcov_pos = curve_fit(model, x, y, maxfev = 100000)\n",
    "popt_pos, pcov_pos = curve_fit(model, x_centers, y_bins[:,1], sigma=0.5*(y_bins[:,2]-y_bins[:,0]),\n",
    "                               absolute_sigma=False, maxfev = 100000, p0=popt_pos)\n",
    "A,B,C = popt_pos\n",
    "x_vals = np.linspace(18,21.5,100)\n",
    "y_vals = model(x_vals,*popt_pos)\n",
    "y_vals = pos_error(x_vals)\n",
    "\n",
    "# n_models = 1000\n",
    "# model_draws = np.zeros((n_models,len(x_vals)))\n",
    "# for j in range(n_models):\n",
    "#     curr_A,curr_B,curr_C = stats.multivariate_normal(mean=popt_pos,cov=pcov_pos,allow_singular=True).rvs()\n",
    "#     model_draws[j] = model(x_vals,curr_A,curr_B,curr_C)\n",
    "\n",
    "# model_bounds = np.percentile(model_draws,[16,50,84],axis=0)\n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x_vals,y_vals,color='C1')\n",
    "# plt.plot(x_vals,model_bounds[1],color='r')\n",
    "# plt.fill_between(x_vals,model_bounds[0],model_bounds[2],color='r',alpha=0.3)\n",
    "plt.plot(x_centers,y_bins[:,1],color='r')\n",
    "plt.fill_between(x_centers,y_bins[:,0],y_bins[:,2],color='r',alpha=0.3)\n",
    "plt.xlabel('G (mag)')\n",
    "plt.ylabel('$\\sqrt{\\sigma_{RA}^2+\\sigma_{Dec}^2}$ (mas)')\n",
    "plt.show()\n",
    "\n",
    "print(y_vals[[0,-1]])\n",
    "print(y_bins[[0,-1],1])\n",
    "\n",
    "x = np.copy(m31_results['gmag'])\n",
    "y = np.copy(m31_results['parallax_error'])\n",
    "keep = np.isfinite(x) & np.isfinite(y) & (x > 18)# & (y < 10)\n",
    "x = x[keep]\n",
    "y = y[keep]\n",
    "\n",
    "n_bins = 3\n",
    "x_bins = np.linspace(18,21,n_bins+1)\n",
    "n_bins = 15\n",
    "x_bins = np.array([18,18.5,19,19.5,20,20.25,20.5,20.7,20.8,21])\n",
    "x_bins = np.array([18,18.5,19,19.5,20,20.25,20.5])\n",
    "n_bins = len(x_bins)-1\n",
    "x_centers = 0.5*(x_bins[1:]+x_bins[:-1])\n",
    "y_bins = np.zeros((n_bins,3))\n",
    "y_compare = np.zeros((len(x),3))\n",
    "for j in range(n_bins):\n",
    "    in_bin = (x > x_bins[j]) & (x <= x_bins[j+1])\n",
    "    if np.sum(in_bin) == 0:\n",
    "#         y_bins[j] = np.nan\n",
    "        continue\n",
    "    y_bins[j] = np.percentile(y[in_bin],[16,50,84])\n",
    "    y_compare[in_bin] = y_bins[j]\n",
    "    \n",
    "# outliers = (y-y_compare[:,1] > 3*(y_compare[:,2]-y_compare[:,1])) | \\\n",
    "#             (y-y_compare[:,1] < -3*(y_compare[:,1]-y_compare[:,0]))\n",
    "# keep = ~outliers\n",
    "# x = x[keep]\n",
    "# y = y[keep]\n",
    "\n",
    "# y_bins = np.zeros((n_bins,3))\n",
    "# y_compare = np.zeros((len(x),3))\n",
    "# for j in range(n_bins):\n",
    "#     in_bin = (x > x_bins[j]) & (x <= x_bins[j+1])\n",
    "#     y_bins[j] = np.percentile(y[in_bin],[16,50,84])\n",
    "#     y_compare[in_bin] = y_bins[j]\n",
    "\n",
    "interp_parallax_relationship = scipy.interpolate.interp1d(x_centers,y_bins[:,1],fill_value=\"extrapolate\")\n",
    "\n",
    "def parallax_error(gmag):\n",
    "#     if gmag <= x_bins[0]:\n",
    "#         return y_bins[0,1]\n",
    "#     elif gmag >= x_bins[-1]:\n",
    "#         return y_bins[-1,1]\n",
    "#     else:\n",
    "#         ind = np.where((gmag > x_bins[:-1]) & (gmag <= x_bins[1:]))[0][0]\n",
    "#         return y_bins[ind,1]\n",
    "    return interp_parallax_relationship(gmag)\n",
    "#     return np.sign(gmag)*0.5\n",
    "\n",
    "def model(x, A, B, C):\n",
    "    #sigma(mag) = C+A*exp(mag/B)\n",
    "    return A*np.exp(x/B)+C\n",
    "\n",
    "popt_pos, pcov_pos = curve_fit(model, x, y, maxfev = 100000)\n",
    "popt_pos, pcov_pos = curve_fit(model, x_centers, y_bins[:,1], sigma=0.5*(y_bins[:,2]-y_bins[:,0]),\n",
    "                               absolute_sigma=False, maxfev = 100000, p0=popt_pos)\n",
    "A,B,C = popt_pos\n",
    "x_vals = np.linspace(18,21.5,100)\n",
    "y_vals = model(x_vals,*popt_pos)\n",
    "y_vals = parallax_error(x_vals)\n",
    "\n",
    "# n_models = 1000\n",
    "# model_draws = np.zeros((n_models,len(x_vals)))\n",
    "# for j in range(n_models):\n",
    "#     curr_A,curr_B,curr_C = stats.multivariate_normal(mean=popt_pos,cov=pcov_pos,allow_singular=True).rvs()\n",
    "#     model_draws[j] = model(x_vals,curr_A,curr_B,curr_C)\n",
    "\n",
    "# model_bounds = np.percentile(model_draws,[16,50,84],axis=0)\n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x_vals,y_vals,color='C1')\n",
    "# plt.plot(x_vals,model_bounds[1],color='r')\n",
    "# plt.fill_between(x_vals,model_bounds[0],model_bounds[2],color='r',alpha=0.3)\n",
    "plt.plot(x_centers,y_bins[:,1],color='r')\n",
    "plt.fill_between(x_centers,y_bins[:,0],y_bins[:,2],color='r',alpha=0.3)\n",
    "plt.xlabel('G (mag)')\n",
    "plt.ylabel('$\\sigma_{\\mathrm{parallax}}$ (mas)')\n",
    "plt.show()\n",
    "\n",
    "print(y_vals[[0,-1]])\n",
    "print(y_bins[[0,-1],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw gmag in [18,21] based on measured distribution (plus add some noise at 0.1~mag scale)\n",
    "#get the size of the Gaia PM error from the measured relationship, pm_sigma(mag)\n",
    "#draw pmra_error (i.e. 30% to 70% of total error), and use to define the pmdec_error\n",
    "#IF the gmag > 21, then no Gaia-measure, so have pmra,pmdec = (0,0) with uncertainty (very_large e.g. 10mas/yr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####EXAMPLE OF MATRIX TRANFORMATION SECTION##########\n",
    "#             TRANSFORMATION MATRIX: X_2 = AG*(X_1-Xo)+BG*(Y_1-Yo)+Wo\n",
    "#                                    Y_2 = CG*(X_1-Xo)+DG*(Y_1-Yo)+Zo\n",
    "#\n",
    "#                                AG:  0.13445487019\n",
    "#                                BG:  0.98645672253\n",
    "#                                CG: -0.98680188642\n",
    "#                                DG:  0.13332047009\n",
    "#                                Xo:      2139.0912\n",
    "#                                Yo:      1624.4170\n",
    "#                                Wo:      4658.3364\n",
    "#                                Zo:      4915.2915\n",
    "#\n",
    "#                    ROTATION (deg):  82.27\n",
    "#                 PIXEL-SCALE RATIO:  0.99567211\n",
    "#    REAL IMG PIXEL SCALE (mas/pix): 49.78360526\n",
    "#\n",
    "#                      MAGNITUDE ZP:  33.13\n",
    "####From Jay Anderson's paper:\n",
    "#   rotation = arctan(B-C,A+D)\n",
    "#   pixel_scale_ratio = sqrt(A*D-B*C)\n",
    "#   on_axis_skew = 0.5*(A-D)\n",
    "#   off_axis_skew = 0.5*(B+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = -0.38011581651, -0.91903156178, 0.91899293411, -0.38007774492\n",
    "\n",
    "pixel_scale_ratio = np.sqrt(a*d-b*c)\n",
    "rotation = np.arctan2(b-c,a+d)*180/np.pi\n",
    "on_axis_skew = 0.5*(a-d)\n",
    "off_axis_skew = 0.5*(b+c)\n",
    "print('Pixel Scale Ratio:',pixel_scale_ratio)\n",
    "print('Rotation (deg):',rotation)\n",
    "print('On Axis Skew:',on_axis_skew)\n",
    "print('Off Axis Skew:',off_axis_skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_halo_name = 'fake_halo_000'\n",
    "outpath = f'/Volumes/Kevin_Astro/Astronomy/HST_Gaia_PMs/code/km_fake_halos/{fake_halo_name}/'\n",
    "\n",
    "#chosen_field == 'COSMOS':\n",
    "ra_center = '10:00:36.50'\n",
    "dec_center = '+02:20:47.8'\n",
    "\n",
    "field_coord = coord.SkyCoord(ra_center, dec_center, unit=(u.hourangle, u.deg))\n",
    "l = field_coord.galactic.l.radian\n",
    "b = field_coord.galactic.b.radian\n",
    "ra_deg = field_coord.ra.deg\n",
    "dec_deg = field_coord.ra.deg\n",
    "\n",
    "new_params = np.load(f'{outpath}indv_star_params.npy')\n",
    "new_param_labels = np.array(['Index','halo_mem','RA','Dec',\n",
    "                  'App_Mag_G','App_Mag_B','App_Mag_R',\n",
    "                  '[Fe/H]','Age','Mass','Dist.','Teff','log_g',\\\n",
    "                  'EEP','Lumin.','Phase',\\\n",
    "                  'vr','vphi_or_vz','vtheta_or_vt',\\\n",
    "                  'pm_l_cosb','pm_b','rad_vel_gsr','radius','logweight'])\n",
    "halo_velocity_params = np.load(f'{outpath}halo_velocity_params.npy')\n",
    "\n",
    "new_param_weights = np.exp(new_params[:,-1]-new_params[:,-1].max())\n",
    "new_param_weights /= np.sum(new_param_weights)\n",
    "\n",
    "halo_stars = (new_params[:,1] == 1)\n",
    "disk_stars = ~halo_stars\n",
    "\n",
    "curr_coords = coord.SkyCoord(new_params[:,2],new_params[:,3], unit=(u.deg, u.deg))\n",
    "curr_ls,curr_bs = curr_coords.galactic.l.deg,curr_coords.galactic.b.deg,\n",
    "all_coords = SkyCoord(l=curr_ls*u.degree, b=curr_bs*u.degree, distance=new_params[:,10]*u.kpc,\n",
    "                      pm_l_cosb=new_params[:,19]*u.mas/u.yr, pm_b=new_params[:,20]*u.mas/u.yr,\n",
    "                      frame='galactic')\n",
    "pm_ras = all_coords.icrs.pm_ra_cosdec.value/np.cos(new_params[:,3]*np.pi/180)\n",
    "pm_decs = all_coords.icrs.pm_dec.value\n",
    "\n",
    "new_param_pms = np.array([pm_ras,pm_decs]).T\n",
    "new_param_pm_lbs = np.array([new_params[:,19]/np.cos(curr_bs*np.pi/180),new_params[:,20]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 30\n",
    "alpha = 0.5\n",
    "vel_range=[-50,20]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "vals = new_params[:,4]\n",
    "if np.sum(halo_stars) > 0:\n",
    "    plt.hist(vals[halo_stars],weights=new_param_weights[halo_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo')\n",
    "if np.sum(disk_stars) > 0:\n",
    "    plt.hist(vals[disk_stars],weights=new_param_weights[disk_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk')\n",
    "plt.hist(vals,weights=new_param_weights,alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total')\n",
    "plt.xlabel('$m_G$ (mag)')\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "vals = 1/new_params[:,10]\n",
    "# bins = np.logspace(np.log10(vals.min()),np.log10(vals.max()),30+1)\n",
    "bins = np.logspace(np.log10(1e-2),np.log10(vals.max()),30+1)\n",
    "if np.sum(halo_stars) > 0:\n",
    "    plt.hist(vals[halo_stars],weights=new_param_weights[halo_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo')\n",
    "if np.sum(disk_stars) > 0:\n",
    "    plt.hist(vals[disk_stars],weights=new_param_weights[disk_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk')\n",
    "plt.hist(vals,weights=new_param_weights,alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total')\n",
    "plt.xlabel('Parallax (mas)')\n",
    "plt.legend(loc=2)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "vals = pm_ras\n",
    "bins = 30\n",
    "if np.sum(halo_stars) > 0:\n",
    "    plt.hist(vals[halo_stars],weights=new_param_weights[halo_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo',range=vel_range)\n",
    "if np.sum(disk_stars) > 0:\n",
    "    plt.hist(vals[disk_stars],weights=new_param_weights[disk_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk',range=vel_range)\n",
    "plt.hist(vals,weights=new_param_weights,alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total',range=vel_range)\n",
    "plt.xlabel('$\\mu_{\\mathrm{RA}}$ (mas/yr)')\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "vals = pm_decs\n",
    "bins = 30\n",
    "if np.sum(halo_stars) > 0:\n",
    "    plt.hist(vals[halo_stars],weights=new_param_weights[halo_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo',range=vel_range)\n",
    "if np.sum(disk_stars) > 0:\n",
    "    plt.hist(vals[disk_stars],weights=new_param_weights[disk_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk',range=vel_range)\n",
    "plt.hist(vals,weights=new_param_weights,alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total',range=vel_range)\n",
    "plt.xlabel('$\\mu_{\\mathrm{Dec}}$ (mas/yr)')\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n",
    "\n",
    "faint_stars = (new_params[:,4] > 21)\n",
    "\n",
    "bins = 30\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Faint Stars')\n",
    "vals = new_params[:,4]\n",
    "if np.sum(halo_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[halo_stars&faint_stars],weights=new_param_weights[halo_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo')\n",
    "if np.sum(disk_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[disk_stars&faint_stars],weights=new_param_weights[disk_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk')\n",
    "plt.hist(vals[faint_stars],weights=new_param_weights[faint_stars],alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total')\n",
    "plt.xlabel('$m_G$ (mag)')\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Faint Stars')\n",
    "vals = 1/new_params[:,10]\n",
    "# bins = np.logspace(np.log10(vals.min()),np.log10(vals.max()),30+1)\n",
    "bins = np.logspace(np.log10(1e-2),np.log10(vals.max()),30+1)\n",
    "if np.sum(halo_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[halo_stars&faint_stars],weights=new_param_weights[halo_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo')\n",
    "if np.sum(disk_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[disk_stars&faint_stars],weights=new_param_weights[disk_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk')\n",
    "plt.hist(vals[faint_stars],weights=new_param_weights[faint_stars],alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total')\n",
    "plt.xlabel('Parallax (mas)')\n",
    "plt.legend(loc=2)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Faint Stars')\n",
    "vals = pm_ras\n",
    "bins = 30\n",
    "if np.sum(halo_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[halo_stars&faint_stars],weights=new_param_weights[halo_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo',range=vel_range)\n",
    "if np.sum(disk_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[disk_stars&faint_stars],weights=new_param_weights[disk_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk',range=vel_range)\n",
    "plt.hist(vals[faint_stars],weights=new_param_weights[faint_stars],alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total',range=vel_range)\n",
    "plt.xlabel('$\\mu_{\\mathrm{RA}}$ (mas/yr)')\n",
    "plt.legend(loc=2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Faint Stars')\n",
    "vals = pm_decs\n",
    "bins = 30\n",
    "if np.sum(halo_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[halo_stars&faint_stars],weights=new_param_weights[halo_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C0',label='Halo',range=vel_range)\n",
    "if np.sum(disk_stars&faint_stars) > 0:\n",
    "    plt.hist(vals[disk_stars&faint_stars],weights=new_param_weights[disk_stars&faint_stars],alpha=alpha,\n",
    "             bins=bins,histtype='step',lw=3,color='C1',label='Disk',range=vel_range)\n",
    "plt.hist(vals[faint_stars],weights=new_param_weights[faint_stars],alpha=alpha,\n",
    "         bins=bins,histtype='step',lw=3,color='C2',label='Total',range=vel_range)\n",
    "plt.xlabel('$\\mu_{\\mathrm{Dec}}$ (mas/yr)')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_params = np.zeros_like(new_params)\n",
    "chosen_inds = np.random.choice(len(new_params),p=new_param_weights,size=len(new_params))\n",
    "resampled_params = np.copy(new_params[chosen_inds])\n",
    "resampled_param_pms = np.copy(new_param_pms[chosen_inds])\n",
    "resampled_param_pm_lbs = np.copy(new_param_pm_lbs[chosen_inds])\n",
    "\n",
    "resampled_halo = (resampled_params[:,1] == 1)\n",
    "resampled_disk = ~resampled_halo\n",
    "\n",
    "size = 1\n",
    "alpha = 0.2\n",
    "\n",
    "print('mu_RA',np.median(resampled_param_pms[:,0]),0.5*np.diff(np.percentile(resampled_param_pms[:,0],[16,84]))[0])\n",
    "print('mu_Dec',np.median(resampled_param_pms[:,1]),0.5*np.diff(np.percentile(resampled_param_pms[:,1],[16,84]))[0])\n",
    "print('parallax',np.median(1/resampled_params[:,10]),0.5*np.diff(np.percentile(1/resampled_params[:,10],[16,84]))[0])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.gca().set_aspect('equal')\n",
    "if np.sum(resampled_halo) > 0:\n",
    "    plt.scatter(resampled_param_pm_lbs[resampled_halo,0],resampled_param_pm_lbs[resampled_halo,1],\n",
    "                color='C0',label='Halo',zorder=1e10,s=size,alpha=alpha)\n",
    "if np.sum(resampled_disk) > 0:\n",
    "    plt.scatter(resampled_param_pm_lbs[resampled_disk,0],resampled_param_pm_lbs[resampled_disk,1],\n",
    "                color='C1',label='Disk',zorder=-1e10,s=size,alpha=alpha)\n",
    "plt.legend(loc=4,markerscale=10)\n",
    "plt.axhline(0,c='k',ls='--',lw=0.5,zorder=1e20)\n",
    "plt.axvline(0,c='k',ls='--',lw=0.5,zorder=1e20)\n",
    "plt.xlabel('$\\mu_{l}$ (mas/yr)')\n",
    "plt.ylabel('$\\mu_{b}$ (mas/yr)')\n",
    "bounds = np.percentile(resampled_param_pm_lbs,[16,50,84],axis=0).T\n",
    "n_sigma = 10\n",
    "xlim = bounds[0,1]-n_sigma*(bounds[0,1]-bounds[0,0]),bounds[0,1]+n_sigma*(bounds[0,2]-bounds[0,1])\n",
    "ylim = bounds[1,1]-n_sigma*(bounds[1,1]-bounds[1,0]),bounds[1,1]+n_sigma*(bounds[1,2]-bounds[1,1])\n",
    "plt.xlim(xlim);plt.ylim(ylim)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.gca().set_aspect('equal')\n",
    "if np.sum(resampled_halo) > 0:\n",
    "    plt.scatter(resampled_param_pms[resampled_halo,0],resampled_param_pms[resampled_halo,1],\n",
    "                color='C0',label='Halo',zorder=1e10,s=size,alpha=alpha)\n",
    "if np.sum(resampled_disk) > 0:\n",
    "    plt.scatter(resampled_param_pms[resampled_disk,0],resampled_param_pms[resampled_disk,1],\n",
    "                color='C1',label='Disk',zorder=-1e10,s=size,alpha=alpha)\n",
    "plt.legend(loc=3,markerscale=10)\n",
    "plt.axhline(0,c='k',ls='--',lw=0.5,zorder=1e20)\n",
    "plt.axvline(0,c='k',ls='--',lw=0.5,zorder=1e20)\n",
    "plt.xlabel('$\\mu_{\\mathrm{RA}}$ (mas/yr)')\n",
    "plt.ylabel('$\\mu_{\\mathrm{Dec}}$ (mas/yr)')\n",
    "bounds = np.percentile(resampled_param_pms,[16,50,84],axis=0).T\n",
    "n_sigma = 10\n",
    "xlim = bounds[0,1]-n_sigma*(bounds[0,1]-bounds[0,0]),bounds[0,1]+n_sigma*(bounds[0,2]-bounds[0,1])\n",
    "ylim = bounds[1,1]-n_sigma*(bounds[1,1]-bounds[1,0]),bounds[1,1]+n_sigma*(bounds[1,2]-bounds[1,1])\n",
    "plt.xlim(xlim);plt.ylim(ylim)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "chosen_halo_star = new_params[np.random.choice(np.where(halo_stars)[0],\n",
    "                                               p=new_param_weights[halo_stars]/np.sum(new_param_weights[halo_stars]))]\n",
    "chosen_disk_star = new_params[np.random.choice(np.where(disk_stars)[0],\n",
    "                                               p=new_param_weights[disk_stars]/np.sum(new_param_weights[disk_stars]))]\n",
    "\n",
    "chosen_star = chosen_disk_star\n",
    "# chosen_star = chosen_halo_star\n",
    "\n",
    "ra,dec,dist = chosen_star[[2,3,10]]\n",
    "dist = 0.1\n",
    "dist = 1\n",
    "pm_l_cosb,pm_b,vrad = chosen_star[[19,20,21]]\n",
    "pm_l_cosb,pm_b,vrad = 0,0,0\n",
    "curr_coord = coord.SkyCoord(ra,dec, unit=(u.deg, u.deg))\n",
    "curr_l,curr_b = curr_coord.galactic.l.deg,curr_coord.galactic.b.deg,\n",
    "print(curr_l,curr_b,dist,pm_l_cosb,pm_b,vrad)\n",
    "print(1/dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime = 11.35\n",
    "dtime = 11.5\n",
    "dtime = 0.95\n",
    "# dtime = 0.5\n",
    "\n",
    "c = SkyCoord(l=curr_l*u.degree, b=curr_b*u.degree, distance=dist*u.kpc,\n",
    "             pm_l_cosb=pm_l_cosb*u.mas/u.yr, pm_b=pm_b*u.mas/u.yr,\n",
    "             radial_velocity=vrad*u.km/u.s,\n",
    "             frame='galactic',\n",
    "             obstime=Time('2006-01-21 05:11:23.5'))\n",
    "\n",
    "print(c.icrs.ra.deg,c.icrs.dec.deg,c.distance.kpc,\n",
    "      c.icrs.pm_ra_cosdec.value/np.cos(dec*np.pi/180),c.icrs.pm_dec.value,c.radial_velocity)\n",
    "new_c = c.apply_space_motion(dt=dtime*u.year)\n",
    "print()\n",
    "print(new_c.icrs.ra.deg,new_c.icrs.dec.deg,new_c.distance.kpc,\n",
    "      new_c.icrs.pm_ra_cosdec.value/np.cos(dec*np.pi/180),new_c.icrs.pm_dec.value,new_c.radial_velocity)\n",
    "ra_change = (new_c.icrs.ra.deg-c.icrs.ra.deg)*3600*1000 #in mas\n",
    "dec_change = (new_c.icrs.dec.deg-c.icrs.dec.deg)*3600*1000 #in mas\n",
    "print(np.round(np.array([ra_change,dec_change])/dtime,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = SkyCoord(l=curr_l*u.degree, b=curr_b*u.degree, distance=dist*u.kpc,\n",
    "             pm_l_cosb=pm_l_cosb*u.mas/u.yr, pm_b=pm_b*u.mas/u.yr,\n",
    "             frame='galactic',\n",
    "             obstime=Time('2006-01-21 05:11:23.5'))\n",
    "\n",
    "print(c.icrs.ra.deg,c.icrs.dec.deg,c.distance.kpc,\n",
    "      c.icrs.pm_ra_cosdec.value/np.cos(dec*np.pi/180),c.icrs.pm_dec.value,c.radial_velocity)\n",
    "new_c = c.apply_space_motion(dt=dtime*u.year)\n",
    "print()\n",
    "print(new_c.icrs.ra.deg,new_c.icrs.dec.deg,new_c.distance.kpc,\n",
    "      new_c.icrs.pm_ra_cosdec.value/np.cos(dec*np.pi/180),new_c.icrs.pm_dec.value,new_c.radial_velocity)\n",
    "ra_change = (new_c.icrs.ra.deg-c.icrs.ra.deg)*3600*1000 #in mas\n",
    "dec_change = (new_c.icrs.dec.deg-c.icrs.dec.deg)*3600*1000 #in mas\n",
    "print(np.round(np.array([ra_change,dec_change])/dtime,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(new_param_weights[1/new_params[:,10] > 0.5*0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_ra_dec_per_parallax(hst_time,gaia_time,ra,dec):\n",
    "    #THIS CODE IS REPURPOSED FROM CODE FROM MELODIE KAO\n",
    "    \n",
    "    #choose any parallax because we will scale by it later\n",
    "    parallax = 1.0*u.mas\n",
    "    distance = (1/parallax.value)*u.kpc\n",
    "    delta_time = (gaia_time-hst_time).to(u.year).value\n",
    "    dates = hst_time+np.array([0,delta_time])*u.year\n",
    "    \n",
    "    sun_loc = astropy.coordinates.get_sun(dates)\n",
    "    \n",
    "    sun_skycoord = SkyCoord(frame='gcrs', obstime=dates,\n",
    "                            ra = sun_loc.ra, dec = sun_loc.dec)\n",
    "    sun_eclon = sun_skycoord.geocentrictrueecliptic.lon\n",
    "    sun_eclat = sun_skycoord.geocentrictrueecliptic.lat\n",
    "\n",
    "#     coord_gaia = SkyCoord( ra          = ra*u.deg,\n",
    "#                            dec         = dec*u.deg,\n",
    "#                            distance    = distance*u.kpc,\n",
    "#                            obstime     = gaia_ref_epoch)\n",
    "\n",
    "    coord_gaia = SkyCoord( ra          = ra*u.deg,\n",
    "                           dec         = dec*u.deg,\n",
    "                           distance    = distance,\n",
    "#                            pm_ra_cosdec= c.icrs.pm_ra_cosdec,\n",
    "#                            pm_dec      = c.icrs.pm_dec,\n",
    "                           obstime     = gaia_time)\n",
    "\n",
    "    # Get geocentric ecliptic coordinates of star after correcting for pm\n",
    "    star_eclon = coord_gaia.geocentrictrueecliptic.lon\n",
    "    star_eclat = coord_gaia.geocentrictrueecliptic.lat\n",
    "\n",
    "    plx_delta_eclon = -parallax * np.sin(star_eclon - sun_eclon) / np.cos(star_eclat)\n",
    "    plx_delta_eclat = -parallax * np.cos(star_eclon - sun_eclon) * np.sin(star_eclat)\n",
    "\n",
    "    offset_lon = plx_delta_eclon - plx_delta_eclon[1] #the second date is Gaia\n",
    "    offset_lat = plx_delta_eclat - plx_delta_eclat[1]\n",
    "\n",
    "    offset_total = np.sqrt(np.power(offset_lon,2)+np.power(offset_lat,2))\n",
    "\n",
    "    #### COMPUTE \tparallax and proper motion offsets in equatorial coordinates\n",
    "    # Ecliptic coordinates: pm-corrected location of star + the parallax offset at each date\n",
    "    coord_plx = astropy.coordinates.GeocentricTrueEcliptic(\n",
    "                    lon = star_eclon + plx_delta_eclon,\n",
    "                    lat = star_eclat + plx_delta_eclat)\n",
    "\n",
    "    # Transform the pm-corrected location of the star + parallax offset at each date to ICRS coordinates (ra/dec)\n",
    "    coord_plx_icrs = coord_plx.transform_to(astropy.coordinates.ICRS)\n",
    "    # FIX THIS AT SOME POINT\n",
    "    # WARNING: AstropyDeprecationWarning: Transforming a frame instance to a frame class \n",
    "    # (as opposed to another frame instance) will not be supported in the future.  \n",
    "    # Either explicitly instantiate the target frame, or first convert the \n",
    "    # source frame instance to a `astropy.coordinates.SkyCoord` and use its\n",
    "    # `transform_to()` method. [astropy.coordinates.baseframe]\n",
    "\n",
    "    plx_delta_ra_dec = coord_gaia.spherical_offsets_to(coord_plx_icrs)\n",
    "    plx_delta_ra   = plx_delta_ra_dec[0]\n",
    "    plx_delta_dec  = plx_delta_ra_dec[1]\n",
    "\n",
    "    offset_ra = plx_delta_ra - plx_delta_ra[1] #the second date is Gaia\n",
    "    offset_dec = plx_delta_dec - plx_delta_dec[1]\n",
    "    offset_ra_dec_total = np.sqrt(np.power(offset_ra,2)+np.power(offset_dec,2))\n",
    "\n",
    "    offset_ra_div_para = offset_ra.to(u.mas)/parallax\n",
    "    offset_dec_div_para = offset_dec.to(u.mas)/parallax\n",
    "    offset_ra_dec_total_div_para = np.sqrt(np.power(offset_ra_div_para,2)+np.power(offset_dec_div_para,2))    \n",
    "    \n",
    "    return np.array([offset_ra_div_para.value[0],offset_dec_div_para.value[0]])\n",
    "\n",
    "delta_t = dtime\n",
    "\n",
    "gaia_ref_epoch = Time(2016.0, format='jyear',scale='tcb')\n",
    "gaia_date = gaia_ref_epoch #Time('2016-01-01T00:00:00', format='isot', scale='utc')\n",
    "hst_date = gaia_date-delta_t*u.year\n",
    "\n",
    "offset_ra_dec_div_para = delta_ra_dec_per_parallax(hst_date,gaia_date,ra,dec)\n",
    "offset_ra_dec_div_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = dtime\n",
    "\n",
    "gaia_ref_epoch = Time(2016.0, format='jyear',scale='tcb')\n",
    "gaia_date = gaia_ref_epoch #Time('2016-01-01T00:00:00', format='isot', scale='utc')\n",
    "hst_date = gaia_date-delta_t*u.year\n",
    "\n",
    "dates = gaia_date+np.linspace(0,-delta_t,100)*u.year\n",
    "# dates = gaia_date-np.array([delta_t,0])*u.year\n",
    "\n",
    "# Get geocentric ecliptic coordinates of Sun \n",
    "\n",
    "sun_loc = astropy.coordinates.get_sun(dates)\n",
    "sun_skycoord = SkyCoord(frame='gcrs', obstime=dates,\n",
    "                        ra = sun_loc.ra, dec = sun_loc.dec)\n",
    "sun_eclon = sun_skycoord.geocentrictrueecliptic.lon\n",
    "sun_eclat = sun_skycoord.geocentrictrueecliptic.lat\n",
    "\n",
    "parallax = 1/c.icrs.distance.value*u.mas #in mas\n",
    "coord_j2000 = SkyCoord( ra          = c.icrs.ra.value*u.deg,\n",
    "                        dec         = c.icrs.dec.value*u.deg,\n",
    "#                         distance    = c.icrs.distance,\n",
    "#                         pm_ra_cosdec= c.icrs.pm_ra_cosdec,\n",
    "#                         pm_dec      = c.icrs.pm_dec,\n",
    "                        obstime     = gaia_ref_epoch)\n",
    "coord_epoch1 = coord_j2000\n",
    "\n",
    "# Get geocentric ecliptic coordinates of star after correcting for pm\n",
    "star_eclon = coord_epoch1.geocentrictrueecliptic.lon\n",
    "star_eclat = coord_epoch1.geocentrictrueecliptic.lat\n",
    "\n",
    "plx_delta_eclon = -parallax * np.sin(star_eclon - sun_eclon) / np.cos(star_eclat)\n",
    "plx_delta_eclat = -parallax * np.cos(star_eclon - sun_eclon) * np.sin(star_eclat)\n",
    "\n",
    "#### PLOT \tparallax offset ellipse in ecliptic coordinates\n",
    "#### \t\tRobin M. Green: \"...the annual path of a star due to parallax is an\n",
    "####                 ellipse of semimajor axis ùúã, semiminor axis ùúãsinùõΩ,\n",
    "####                 and therefore of eccentricity cosùõΩ\n",
    "offset_lon = plx_delta_eclon - plx_delta_eclon[0]\n",
    "offset_lat = plx_delta_eclat - plx_delta_eclat[0]\n",
    "\n",
    "offset_total = np.sqrt(np.power(offset_lon,2)+np.power(offset_lat,2))\n",
    "print(np.max(np.abs(offset_lon)),np.max(np.abs(offset_lat)),np.max(offset_total))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "# plt.plot(plx_delta_eclon.to(u.mas).value, plx_delta_eclat.to(u.mas).value)\n",
    "# plt.scatter(plx_delta_eclon.to(u.mas).value[0], plx_delta_eclat.to(u.mas).value[0],color='g',s=100)\n",
    "# plt.scatter(plx_delta_eclon.to(u.mas).value[-1], plx_delta_eclat.to(u.mas).value[-1],color='r',s=100)\n",
    "plt.plot(offset_lon.to(u.mas).value, offset_lat.to(u.mas).value)\n",
    "plt.scatter(offset_lon.to(u.mas).value[0], offset_lat.to(u.mas).value[0],color='g',s=100)\n",
    "plt.scatter(offset_lon.to(u.mas).value[-1], offset_lat.to(u.mas).value[-1],color='r',s=100)\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Ecliptic longitude offset (mas)')\n",
    "plt.ylabel('Ecliptic latitude offset (mas)')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "#### COMPUTE \tparallax and proper motion offsets in equatorial coordinates\n",
    "# Ecliptic coordinates: pm-corrected location of star + the parallax offset at each date\n",
    "coord_plx = astropy.coordinates.GeocentricTrueEcliptic(\n",
    "                lon = star_eclon + plx_delta_eclon,\n",
    "                lat = star_eclat + plx_delta_eclat)\n",
    "\n",
    "# Transform the pm-corrected location of the star + parallax offset at each date to ICRS coordinates (ra/dec)\n",
    "coord_plx_icrs = coord_plx.transform_to(astropy.coordinates.ICRS)\n",
    "# FIX THIS AT SOME POINT\n",
    "# WARNING: AstropyDeprecationWarning: Transforming a frame instance to a frame class \n",
    "# (as opposed to another frame instance) will not be supported in the future.  \n",
    "# Either explicitly instantiate the target frame, or first convert the \n",
    "# source frame instance to a `astropy.coordinates.SkyCoord` and use its\n",
    "# `transform_to()` method. [astropy.coordinates.baseframe]\n",
    "\n",
    "plx_delta_ra_dec = coord_epoch1.spherical_offsets_to(coord_plx_icrs)\n",
    "plx_delta_ra   = plx_delta_ra_dec[0]\n",
    "plx_delta_dec  = plx_delta_ra_dec[1]\n",
    "\n",
    "offset_ra = plx_delta_ra - plx_delta_ra[0]\n",
    "offset_dec = plx_delta_dec - plx_delta_dec[0]\n",
    "offset_ra_dec_total = np.sqrt(np.power(offset_ra,2)+np.power(offset_dec,2))\n",
    "\n",
    "print( 'target star PARALLAX delta RA:  {:.5f}'.format(offset_ra[-1].to(u.mas)))\n",
    "print( 'target star PARALLAX delta Dec: {:.5f}'.format(offset_dec[-1].to(u.mas)))\n",
    "print( 'target star PARALLAX offset:    {:.5f}'.format(offset_ra_dec_total[-1].to(u.mas)))\n",
    "\n",
    "offset_ra_div_para = offset_ra.to(u.mas)/parallax\n",
    "offset_dec_div_para = offset_dec.to(u.mas)/parallax\n",
    "offset_ra_dec_total_div_para = np.sqrt(np.power(offset_ra_div_para,2)+np.power(offset_dec_div_para,2))\n",
    "\n",
    "print( 'target star delta RA/parallax:  {:.5f}'.format(offset_ra_div_para[-1]))\n",
    "print( 'target star delta Dec/parallax: {:.5f}'.format(offset_dec_div_para[-1]))\n",
    "print( 'target star offset/parallax:    {:.5f}'.format(offset_ra_dec_total_div_para[-1]))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(offset_ra.to(u.mas).value, offset_dec.to(u.mas).value)\n",
    "plt.scatter(offset_ra.to(u.mas).value[0], offset_dec.to(u.mas).value[0],color='g',s=100)\n",
    "plt.scatter(offset_ra.to(u.mas).value[-1], offset_dec.to(u.mas).value[-1],color='r',s=100)\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.xlabel(r'$\\Delta$RA (mas)')\n",
    "plt.ylabel(r'$\\Delta$Dec (mas)')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(offset_ra_div_para.value, offset_dec_div_para.value)\n",
    "plt.scatter(offset_ra_div_para.value[0], offset_dec_div_para.value[0],color='g',s=100)\n",
    "plt.scatter(offset_ra_div_para.value[-1], offset_dec_div_para.value[-1],color='r',s=100)\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.xlabel(r'$\\Delta$RA/parallax')\n",
    "plt.ylabel(r'$\\Delta$Dec/parallax')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "#delta_{RA,Dec}/parallax is a constant number for each star at a given time\n",
    "#so we can use any parallax we want to calculate these vectors for each star\n",
    "#and then get the offsets from parallax using the current drawn parallax and these vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model a star's parallax motion over a few years\n",
    "\n",
    "dist = 10 #kpc\n",
    "x_ang,y_ang = 179,20 #like RA,Dec\n",
    "#polar coords\n",
    "theta = (90-y_ang)*np.pi/180\n",
    "phi = x_ang*np.pi/180\n",
    "\n",
    "#put sun at (x,y,z) = 0\n",
    "n_years = 3\n",
    "times = np.arange(0,n_years,1/365) #in years\n",
    "#use plane of earth's orbit to get x,y,z at each time\n",
    "angles = np.linspace(0,np.pi*2*n_years,len(times))\n",
    "\n",
    "#conversion ratios\n",
    "kpc_to_au = 2.063e8\n",
    "kpc_to_km = 3.086e16\n",
    "year_to_sec = 365*24*3600\n",
    "radian_to_mas = 180/np.pi*3600*1000\n",
    "\n",
    "earth_dist = 1/kpc_to_au #1AU in kpc\n",
    "#position of earth in the plane of it's orbit, with sun at center\n",
    "plane_x = earth_dist*np.cos(angles)\n",
    "plane_y = earth_dist*np.sin(angles)\n",
    "plane_z = np.zeros(len(angles))\n",
    "\n",
    "earth_norm_plane = (0,0,1) #direction of the z vector of the earth's plane\n",
    "#the cross product of plane_x with plane_y has to be equal to the earth_norm_plane\n",
    "# #rotate the plane of the earth's orbit\n",
    "earth_x = plane_x\n",
    "earth_y = plane_y\n",
    "earth_z = plane_z\n",
    "\n",
    "star_vel = (-10,-10,0) #vx,vy,vz in km/s\n",
    "star_vx = (star_vel[0]*year_to_sec/kpc_to_km)\n",
    "star_vy = (star_vel[1]*year_to_sec/kpc_to_km)\n",
    "star_vz = (star_vel[2]*year_to_sec/kpc_to_km)\n",
    "star_x = dist*np.sin(theta)*np.cos(phi)+star_vx*times\n",
    "star_y = dist*np.sin(theta)*np.sin(phi)+star_vy*times\n",
    "star_z = dist*np.cos(theta)+star_vz*times\n",
    "# star_vel = (100,10,10) #in vrad (km/s), mu_theta (mas/yr), mu_phi (mas/yr)\n",
    "# star_vx,star_vy,star_vz = \n",
    "# star_vx,star_vy,star_vz = \n",
    "\n",
    "\n",
    "star_planet_vector = np.array([star_x-earth_x,star_y-earth_y,star_z-earth_z]).T\n",
    "star_planet_vector_sphere = np.zeros_like(star_planet_vector)\n",
    "star_planet_vector_sphere[:,0] = np.sqrt(np.sum(np.power(star_planet_vector,2),axis=1))\n",
    "star_planet_vector_sphere[:,1] = np.arccos(star_planet_vector[:,2]/star_planet_vector_sphere[:,0]) #polar angle\n",
    "star_planet_vector_sphere[:,2] = np.sign(star_planet_vector[:,1])*np.arccos(star_planet_vector[:,0]/np.sqrt(np.sum(np.power(star_planet_vector[:,:2],2),axis=1)))\n",
    "\n",
    "delta_dec = (star_planet_vector_sphere[:,1]-star_planet_vector_sphere[0,1])*radian_to_mas\n",
    "delta_ra = (star_planet_vector_sphere[:,2]-star_planet_vector_sphere[0,2])*radian_to_mas\n",
    "delta_total = np.sqrt(np.power(delta_ra,2)+np.power(delta_dec,2))\n",
    "\n",
    "print(f'Max offset of {np.round(delta_total.max(),2)} mas')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(delta_ra,delta_dec)\n",
    "plt.xlabel(r'$\\Delta$RA (mas)')\n",
    "plt.ylabel(r'$\\Delta$Dec (mas)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(times,delta_ra,label=r'RA')\n",
    "plt.plot(times,delta_dec,label=r'Dec')\n",
    "plt.plot(times,delta_total,label=r'Total')\n",
    "plt.xlabel(r'Time (years)')\n",
    "plt.ylabel(r'$\\Delta$Angle (mas)')\n",
    "leg = plt.legend(loc='best')\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigma_v_{phi,theta} = 70 km/s at r = 24kpc gives dtheta/dt = 0.615 mas/yr\n",
    "\n",
    "\n",
    "pm_center = np.array([1,-3])\n",
    "# pm_center = np.array([0,0])\n",
    "pm_errs = np.array([2.5,2.5])\n",
    "\n",
    "n_draws = 10000\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "mu_draws = np.zeros((n_draws,2))\n",
    "mu_draws[:,0] = np.random.randn(n_draws)*pm_errs[0]+pm_center[0]\n",
    "mu_draws[:,1] = np.random.randn(n_draws)*pm_errs[1]+pm_center[1]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.scatter(mu_draws[:,0],mu_draws[:,1],s=1,alpha=0.5)\n",
    "plt.axhline(0,c='k',lw=0.5,ls='--')\n",
    "plt.axvline(0,c='k',lw=0.5,ls='--')\n",
    "plt.xlabel(r'$\\mu_x$ (mas/yr)')\n",
    "plt.ylabel(r'$\\mu_y$ (mas/yr)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_size_and_errs = np.copy([new_param_pms[:,0],new_param_pms[:,1],\n",
    "                            np.zeros_like(new_param_pms[:,0]),np.zeros_like(new_param_pms[:,0]),\n",
    "                            new_params[:,4],new_params[:,4]]).T\n",
    "\n",
    "large_pms = np.sqrt(np.power(new_param_pms[:,0],2)+np.power(new_param_pms[:,1],2)) > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots = False\n",
    "# show_plots = True\n",
    "\n",
    "# #from Fornax real data\n",
    "fake_field_params = {\n",
    "                     'FAKE_FIELD_01':np.array([-112.46963132241382,  0.9945134860058175,  4972.7290,  \n",
    "                                               5065.2474, -1.903579499998309e-05,  -1.931383499997885e-05,\n",
    "                                               2086.6321,2304.2309]),\n",
    "                     'FAKE_FIELD_02':np.array([-112.46963132241382,  0.9945134860058175,  4972.7290,  \n",
    "                                               5065.2474, -1.903579499998309e-05,  -1.931383499997885e-05,\n",
    "                                               2086.6321,2304.2309]),\n",
    "                     'FAKE_FIELD_03':np.array([-112.46963132241382,  0.9945134860058175,  4972.7290,  \n",
    "                                               5065.2474, -1.903579499998309e-03,  -1.931383499997885e-03,\n",
    "                                               2086.6321,2304.2309]),\n",
    "                     'FAKE_FIELD_04':np.array([180,  0.9945134860058175,  4972.7290,  \n",
    "                                               5065.2474, -1.903579499998309e-05,  -1.931383499997885e-05,\n",
    "                                               2086.6321,2304.2309]),\n",
    "                    }\n",
    "#for fake_field_02, have a list of stationary points\n",
    "\n",
    "n_star_options = np.array([5,10,15,20,25,30,40,50,75,100,150,200])[::-1]\n",
    "\n",
    "# n_star_options = np.array([1000])[::-1]\n",
    "# n_star_options = np.array([5,6,7,8,9,10,11,12,13,14,15])[::-1]\n",
    "seed_options = np.arange(101,105+1).astype(int)\n",
    "# seed_options = np.array([101]).astype(int)\n",
    "# time_options = np.array([5,6,7,8,9,10,12.5,15,17.5,20])\n",
    "\n",
    "time_options = np.array([5,7.5,10,12.5,15])[::-1]\n",
    "time_options = np.sort(np.append(time_options,time_options+0.5))[::-1]\n",
    "# time_options = np.array([10,11,12,13,14,15])[::-1]\n",
    "\n",
    "print('Current number of combinations:',len(fake_field_params)*n_star_options.size*seed_options.size*time_options.size)\n",
    "#what is the uncertainty on measuring the positions? \n",
    "hst_pix_sigmas = 0.5/50 #in hst pixels from https://ui.adsabs.harvard.edu/abs/2022ApJ...933...76D/abstract\n",
    "\n",
    "#chosen_field == 'COSMOS':\n",
    "ra_center = '10:00:36.50'\n",
    "dec_center = '+02:20:47.8'\n",
    "\n",
    "field_coord = coord.SkyCoord(ra_center, dec_center, unit=(u.hourangle, u.deg))\n",
    "l = field_coord.galactic.l.radian\n",
    "b = field_coord.galactic.b.radian\n",
    "ra_deg = field_coord.ra.deg\n",
    "dec_deg = field_coord.dec.deg\n",
    "\n",
    "time_offsets = (-0.001,0.001) #in years, from the Gaia Time (2016.0)\n",
    "\n",
    "for field_ind,chosen_field in enumerate(fake_field_params):\n",
    "    continue\n",
    "    \n",
    "    if not os.path.isdir(f'{path}{chosen_field}/'):\n",
    "        os.makedirs(f'{path}{chosen_field}/')\n",
    "        \n",
    "    field_num = int(chosen_field.split('_')[-1])\n",
    "    if field_num not in [4]:\n",
    "        continue\n",
    "#     if field_num not in [3,4]:\n",
    "#         continue\n",
    "        \n",
    "    for nstar_ind,n_star in enumerate(n_star_options):\n",
    "        nstar = n_star\n",
    "        n_stars = n_star\n",
    "        n_star_string = f'n{n_star:03d}'\n",
    "        for time_ind,delta_time in enumerate(time_options):\n",
    "            time_string = f't{round(delta_time*10):03d}'\n",
    "            \n",
    "            #ensure there are at least 200 stars when summing over the seeds\n",
    "            n_seed_options = max(5,int(round(200/n_star)))\n",
    "            seed_options = np.arange(101,101+n_seed_options,1).astype(int)\n",
    "            \n",
    "            for seed_ind,seed in enumerate(seed_options):\n",
    "                \n",
    "                chosen_params = fake_field_params[chosen_field]\n",
    "                rot,ratio,w0,z0,on_skew,off_skew,x0,y0 = chosen_params\n",
    "                a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "                det = a*d-b*c\n",
    "                #inverse matrix for de-transforming\n",
    "                ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                mag_zp = 32.40\n",
    "                orig_pix_scale = 50 #mas/year\n",
    "                orig_pix_ratio = orig_pix_scale\n",
    "                pix_scale = orig_pix_scale*ratio\n",
    "                \n",
    "                ra,dec = ra_deg,dec_deg #near M31\n",
    "                \n",
    "                seed_string = f's{seed:03d}'\n",
    "\n",
    "                np.random.seed(((n_star+0)*(seed)*(field_num+1000)*int(delta_time*10+10000))%(2**32))\n",
    "                print(field_num,n_star_string,time_string,seed_string)\n",
    "                \n",
    "                image_name = f'FF{n_star_string}{time_string}{seed_string}'\n",
    "                trans_path = f'{path}{chosen_field}/HST/mastDownload/HST/{image_name}/'\n",
    "                trans_file = f'{trans_path}{image_name}_6p_transformation.txt'\n",
    "                truths = np.array([rot,ratio,w0,z0,on_skew,off_skew])\n",
    "                \n",
    "                if not os.path.isdir(trans_path):\n",
    "                    os.makedirs(trans_path)\n",
    "                print(trans_path)\n",
    "                \n",
    "                #save the truth\n",
    "                truth_trans_file = f'{trans_path}{image_name}_6p_transformation_TRUTH.npy'\n",
    "                np.save(f'{truth_trans_file}',np.array([a,b,c,d,x0,y0,w0,z0,rot,ratio,on_skew,off_skew]))\n",
    "\n",
    "                mat_file = f'{trans_path}{image_name}_flc.MAT'\n",
    "\n",
    "                #just use 4096 pixels in each dimension, with (0,0) in the center\n",
    "                pix_dims = (4096,4096)\n",
    "                xranges = (0,pix_dims[0])\n",
    "                yranges = (0,pix_dims[1])\n",
    "\n",
    "                with open(mat_file,'w') as f:\n",
    "                    #each row is a star\n",
    "\n",
    "                    #draw PMs and errors from real measurements, then add noise\n",
    "#                     star_inds = np.random.choice(len(pm_size_and_errs),size=n_star,replace=False) \n",
    "\n",
    "                    temp_param_weights = np.copy(new_param_weights)\n",
    "#                     temp_param_weights[large_pms] = 0\n",
    "#                     temp_param_weights /= np.sum(temp_param_weights)\n",
    "                    star_inds = np.random.choice(len(new_param_weights),\n",
    "                                                 p=temp_param_weights,\n",
    "                                                 size=n_star,replace=True) \n",
    "\n",
    "                    star_pm_and_errs = pm_size_and_errs[star_inds]\n",
    "                    star_gmags = star_pm_and_errs[:,-2]\n",
    "                    star_hst_mags = star_pm_and_errs[:,-1]\n",
    "                    star_pm_errs = star_pm_and_errs[:,[2,3]]\n",
    "                    star_pms = star_pm_and_errs[:,[0,1]]\n",
    "#                     star_pms = np.array([np.random.randn(n_star)*pm_errs[0]+pm_center[0],\\\n",
    "#                                          np.random.randn(n_star)*pm_errs[1]+pm_center[1]]).T\n",
    "                    star_pm_size = np.sqrt(np.power(star_pms[:,0],2)+np.power(star_pms[:,1],2))\n",
    "#                     star_pm_dist_params = 0,0.5*np.diff(np.percentile(star_pm_size,[0.5,99.5]))[0]\n",
    "                    star_pm_dist_params = np.median(star_pm_size),0.5*np.diff(np.percentile(star_pm_size,[16,84]))[0]\n",
    "                    outliers = np.where((star_pm_size-star_pm_dist_params[0]) > 10*star_pm_dist_params[1])[0]\n",
    "\n",
    "                    replace_n_star = len(outliers)\n",
    "                    replace_count = 0\n",
    "                    while replace_n_star > 0:\n",
    "                        break\n",
    "#                         replace_star_inds = np.random.choice(len(pm_size_and_errs),size=replace_n_star,replace=False)\n",
    "                        replace_star_inds = np.random.choice(len(new_param_weights),\n",
    "                                                                 p=temp_param_weights,\n",
    "                                                                 size=replace_n_star,replace=True)\n",
    "                        star_inds[outliers] = replace_star_inds\n",
    "\n",
    "                        replace_star_pm_and_errs = pm_size_and_errs[replace_star_inds]\n",
    "                        replace_star_gmags = replace_star_pm_and_errs[:,-2]\n",
    "                        replace_star_hst_mags = replace_star_pm_and_errs[:,-1]\n",
    "                        replace_star_pm_errs = replace_star_pm_and_errs[:,[2,3]]\n",
    "                        replace_star_pms = replace_star_pm_and_errs[:,[0,1]]\n",
    "#                         replace_star_pms = replace_star_pm_and_errs[:,[0,1]]+np.random.randn((2*replace_n_star)).reshape((replace_n_star,2))*replace_star_pm_errs\n",
    "#                         replace_star_pms = np.array([np.random.randn(replace_n_star)*pm_errs[0]+pm_center[0],\\\n",
    "#                                                      np.random.randn(replace_n_star)*pm_errs[1]+pm_center[1]]).T\n",
    "                        replace_star_pm_size = np.sqrt(np.power(replace_star_pms[:,0],2)+np.power(replace_star_pms[:,1],2))\n",
    "                        star_pms[outliers] = np.copy(replace_star_pms)\n",
    "                        star_pm_and_errs[outliers] = np.copy(replace_star_pm_and_errs)\n",
    "                        star_pm_size[outliers] = np.copy(replace_star_pm_size)\n",
    "                        outliers = np.where((star_pm_size-star_pm_dist_params[0]) > 10*star_pm_dist_params[1])[0]\n",
    "                        replace_n_star = len(outliers)\n",
    "                        replace_count += 1\n",
    "#                     print(star_pm_dist_params,np.sum(outliers),replace_count)\n",
    "\n",
    "                    star_gmags = star_pm_and_errs[:,-2]\n",
    "                    star_hst_mags = star_pm_and_errs[:,-1]\n",
    "                    star_pm_errs = star_pm_and_errs[:,[2,3]]\n",
    "                    star_dists = new_params[star_inds,10] #in kpc\n",
    "                    star_parallaxes = 1/star_dists\n",
    "                    gaia_time_offsets = np.random.rand(n_star)*(time_offsets[1]-time_offsets[0])+time_offsets[0]\n",
    "                    star_gaia_times = gaia_ref_epoch+gaia_time_offsets*u.year\n",
    "                    star_hst_times = gaia_ref_epoch-np.ones(n_star)*delta_time*u.year\n",
    "                    star_delta_times = (star_gaia_times-star_hst_times).to(u.year).value\n",
    "                    \n",
    "                    np.save(f'{trans_path}{image_name}_HST_Gaia_times.npy',\n",
    "                            np.array([star_hst_times.value,star_gaia_times.value]).T)\n",
    "                                            \n",
    "                    stationary = np.zeros(len(star_inds)).astype(bool)\n",
    "                    if chosen_field == 'FAKE_FIELD_02':\n",
    "                        #make one of the stars a stationary source\n",
    "                        n_stationary = 1\n",
    "#                         n_stationary = n_star\n",
    "#                         n_stationary = int(0.5*n_star)\n",
    "                        stationary[:n_stationary] = True\n",
    "                    star_pms[stationary] = 0.0\n",
    "                    star_parallaxes[stationary] = 1e-6 #mas, corresponds to a giga-parsec distance\n",
    "                    star_dists[stationary] = np.power(star_parallaxes[stationary],-1)\n",
    "            \n",
    "                    np.save(f'{trans_path}{image_name}_true_PMs.npy',star_pms) #chosen PMs in RA,Dec (mas/year)\n",
    "                    np.save(f'{trans_path}{image_name}_true_parallaxes.npy',star_parallaxes) #mas\n",
    "                    np.save(f'{trans_path}{image_name}_stationary_points.npy',stationary) #booleans of whether point is stationary\n",
    "                    \n",
    "                    #get Gaia-measured PMs and errors for building priors\n",
    "                    faint_stars = (star_gmags > 21)\n",
    "#                     gaia_pm_err_sizes = model(star_gmags,*popt)\n",
    "                    gaia_pm_err_sizes = pm_error(star_gmags)\n",
    "                    pm_frac_ranges = [0.9,1.1] #pm_x_err/pm_y_err = frac\n",
    "                    frac_draws = np.random.rand(n_star)*(pm_frac_ranges[1]-pm_frac_ranges[0])+pm_frac_ranges[0]\n",
    "                    gaia_pmdec_err = gaia_pm_err_sizes*np.sqrt(1/(1+np.power(frac_draws,2)))\n",
    "                    gaia_pmra_err = gaia_pmdec_err*frac_draws                  \n",
    "                    \n",
    "                    gaia_pm_errs = np.array([gaia_pmra_err,gaia_pmdec_err]).T\n",
    "                    gaia_pms = star_pms+np.random.randn((2*n_star)).reshape((n_star,2))*gaia_pm_errs\n",
    "                    #no Gaia measure for stars fainter than G=21, so give 0 pm and large uncertainty for prior\n",
    "                    gaia_pms[faint_stars] = 0\n",
    "                    gaia_pm_errs[faint_stars] = 50                       \n",
    "                    gaia_pms_and_errs = np.array([gaia_pms,gaia_pm_errs])\n",
    "                    \n",
    "                    gaia_pos_err_sizes = pos_error(star_gmags)\n",
    "                    pos_frac_ranges = [0.9,1.1] #x_err/y_err = frac\n",
    "                    frac_draws = np.random.rand(n_star)*(pos_frac_ranges[1]-pos_frac_ranges[0])+pos_frac_ranges[0]\n",
    "                    gaia_dec_err = gaia_pos_err_sizes*np.sqrt(1/(1+np.power(frac_draws,2)))\n",
    "                    gaia_ra_err = gaia_dec_err*frac_draws     \n",
    "                    gaia_pos_errs = np.array([gaia_ra_err,gaia_dec_err]).T\n",
    "                    \n",
    "                    gaia_parallax_errs = parallax_error(star_gmags)\n",
    "                    #gaia data has some negative parallaxes in it\n",
    "                    gaia_parallaxes = star_parallaxes+np.random.randn(n_star)*gaia_parallax_errs\n",
    "#                     norm_loc = star_parallaxes\n",
    "#                     norm_scale = gaia_parallax_errs\n",
    "#                     norm_a, norm_b = (0 - norm_loc) / norm_scale, (np.inf - norm_loc) / norm_scale\n",
    "#                     gaia_parallaxes = stats.truncated_normal(loc=norm_loc,\n",
    "#                                                                  scale=norm_scale,\n",
    "#                                                                  a=norm_a,b=norm_b).rvs()\n",
    "                    \n",
    "                    parallax_offset_vector = np.zeros((n_star,2)) #(delta_ra/parallax,delta_dec/parallax)\n",
    "                    for star_ind in range(n_star):\n",
    "                        hst_date = star_hst_times[star_ind]\n",
    "                        gaia_date = star_gaia_times[star_ind]\n",
    "                        parallax_offset_vector[star_ind] = delta_ra_dec_per_parallax(hst_date,gaia_date,\n",
    "                                                                                     ra_deg,dec_deg)        \n",
    "                        \n",
    "                    np.save(f'{trans_path}{image_name}_GaiaMeasure_PMs.npy',gaia_pms_and_errs)\n",
    "                    np.save(f'{trans_path}{image_name}_GaiaMeasure_RADec_errs.npy',gaia_pos_errs)\n",
    "                    np.save(f'{trans_path}{image_name}_GaiaMeasure_parallaxes.npy',\n",
    "                                                np.array([gaia_parallaxes,gaia_parallax_errs]).T)\n",
    "                    \n",
    "                    #change it so that RA = -x_Gaia, Dec = y_Gaia\n",
    "                    star_pixel_changes = star_pms*(star_delta_times[:,None]/pix_scale) \n",
    "                    star_pixel_changes[:,0] *= -1 #so that x_Gaia = -RA\n",
    "                    star_pixel_changes_parallax = -1*(star_parallaxes/pix_scale)[:,None]*parallax_offset_vector \n",
    "                    star_pixel_changes_parallax[:,0] *= -1 #so that x_Gaia = -RA\n",
    "                    star_pixel_pos_errs = gaia_pos_errs/pix_scale \n",
    "                    \n",
    "                    #[X_Gaia, Y_Gaia, X_hst, Y_hst, mag_Gaia, mag_hst, delta_X_G, delta_Y_G, X_trans, Y_trans] (all in pixels)\n",
    "                    \n",
    "                    all_measures = {\n",
    "                                    'dX_Gaia':np.zeros(nstar),'dY_Gaia':np.zeros(nstar),\n",
    "                                    'X_Gaia':np.zeros(nstar),'Y_Gaia':np.zeros(nstar),\n",
    "                                    'X_HST':np.zeros(nstar),'Y_HST':np.zeros(nstar),\n",
    "                                   }\n",
    "                    \n",
    "                    all_dx = np.zeros(n_star)\n",
    "                    all_dy = np.zeros(n_star)\n",
    "                    all_offsets = np.zeros((n_star,2))\n",
    "                    \n",
    "                    true_gaia_xy = np.zeros((n_star,2))\n",
    "                    for j in range(n_star):\n",
    "                        #add the change from the PM and the parallax\n",
    "                        #curr_pixel_changes IS IN GAIA X,Y, SO TRANSFORM TO HST X,Y\n",
    "                        curr_pixel_changes = np.copy(star_pixel_changes[j]+star_pixel_changes_parallax[j])\n",
    "                        curr_pixel_changes_x_HST = ai*curr_pixel_changes[0]+bi*curr_pixel_changes[1]\n",
    "                        curr_pixel_changes_y_HST = ci*curr_pixel_changes[0]+di*curr_pixel_changes[1]\n",
    "                        curr_pixel_changes[0] = curr_pixel_changes_x_HST\n",
    "                        curr_pixel_changes[1] = curr_pixel_changes_y_HST\n",
    "                        \n",
    "                        curr_pixel_pos_errs = star_pixel_pos_errs[j]\n",
    "\n",
    "                        #choose a starting position that is inside of the x and y limits for HST\n",
    "                        curr_hst_x_range = max(xranges[0],xranges[0]+curr_pixel_changes[0]),\\\n",
    "                                           min(xranges[1],xranges[1]-curr_pixel_changes[0])\n",
    "                        curr_hst_y_range = max(yranges[0],yranges[0]+curr_pixel_changes[1]),\\\n",
    "                                           min(yranges[1],yranges[1]-curr_pixel_changes[1])\n",
    "                        \n",
    "                        found_good = False\n",
    "                        \n",
    "                        while not found_good:\n",
    "\n",
    "                            chosen_hst_x = np.random.rand()*(curr_hst_x_range[1]-curr_hst_x_range[0])+curr_hst_x_range[0]\n",
    "                            chosen_hst_y = np.random.rand()*(curr_hst_y_range[1]-curr_hst_y_range[0])+curr_hst_y_range[0]\n",
    "\n",
    "                            hst_start_pix = np.array((chosen_hst_x,chosen_hst_y))\n",
    "                            hst_end_pix = np.array((chosen_hst_x+curr_pixel_changes[0],chosen_hst_y+curr_pixel_changes[1]))\n",
    "\n",
    "                            gaia_start_pix = np.array((a*(hst_start_pix[0]-x0)+b*(hst_start_pix[1]-y0)+w0,\\\n",
    "                                              c*(hst_start_pix[0]-x0)+d*(hst_start_pix[1]-y0)+z0))\n",
    "                            gaia_end_pix = np.array((a*(hst_end_pix[0]-x0)+b*(hst_end_pix[1]-y0)+w0,\\\n",
    "                                            c*(hst_end_pix[0]-x0)+d*(hst_end_pix[1]-y0)+z0))\n",
    "                            true_gaia_xy[j] = np.copy(gaia_end_pix)\n",
    "\n",
    "                            hst_pixel_errors = np.random.randn(4)*hst_pix_sigmas\n",
    "\n",
    "                            #add noise to HST pixels\n",
    "                            hst_start_pix[0] += hst_pixel_errors[0]\n",
    "                            hst_start_pix[1] += hst_pixel_errors[1]\n",
    "                            hst_end_pix[0] += hst_pixel_errors[2]\n",
    "                            hst_end_pix[1] += hst_pixel_errors[3]\n",
    "\n",
    "                            trans_start_pix = np.array((a*(hst_start_pix[0]-x0)+b*(hst_start_pix[1]-y0)+w0,\\\n",
    "                                                        c*(hst_start_pix[0]-x0)+d*(hst_start_pix[1]-y0)+z0))\n",
    "\n",
    "                            gaia_pixel_errors = np.random.randn(2)*curr_pixel_pos_errs[0],\\\n",
    "                                                np.random.randn(2)*curr_pixel_pos_errs[1]\n",
    "                            #add noise to Gaia pixels\n",
    "                            gaia_start_pix[0] += gaia_pixel_errors[0][0]\n",
    "                            gaia_start_pix[1] += gaia_pixel_errors[1][0]\n",
    "                            gaia_end_pix[0] += gaia_pixel_errors[0][1]\n",
    "                            gaia_end_pix[1] += gaia_pixel_errors[1][1]\n",
    "                            \n",
    "                            detrans_end_pix = np.array((ai*(gaia_end_pix[0]-w0)+bi*(gaia_end_pix[1]-z0)+x0,\\\n",
    "                                                        ci*(gaia_end_pix[0]-w0)+di*(gaia_end_pix[1]-z0)+y0))\n",
    "                            \n",
    "                            total_move = np.sqrt((detrans_end_pix[0]-hst_start_pix[0])**2+\n",
    "                                                 (detrans_end_pix[1]-hst_start_pix[1])**2)\n",
    "                            total_offset = np.sqrt((detrans_end_pix[0]-hst_start_pix[0]-curr_pixel_changes[0])**2+\n",
    "                                                   (detrans_end_pix[1]-hst_start_pix[1]-curr_pixel_changes[1])**2)\n",
    "                            total_offset_x = (detrans_end_pix[0]-hst_start_pix[0]-curr_pixel_changes[0])\n",
    "                            total_offset_y = (detrans_end_pix[1]-hst_start_pix[1]-curr_pixel_changes[1])\n",
    "#                             if total_move < 1.0:\n",
    "#                                 found_good = True\n",
    "                            found_good = True                                \n",
    "                        \n",
    "                        curr_star_params = np.zeros(10)*np.nan\n",
    "                        curr_star_params[0] = gaia_end_pix[0]\n",
    "                        curr_star_params[1] = gaia_end_pix[1]\n",
    "                        curr_star_params[2] = hst_start_pix[0]\n",
    "                        curr_star_params[3] = hst_start_pix[1]\n",
    "                        curr_star_params[4] = star_gmags[j]\n",
    "                        curr_star_params[5] = star_hst_mags[j]\n",
    "                        curr_star_params[6] = gaia_end_pix[0]-trans_start_pix[0]\n",
    "                        curr_star_params[7] = gaia_end_pix[1]-trans_start_pix[1]\n",
    "                        curr_star_params[8] = trans_start_pix[0]\n",
    "                        curr_star_params[9] = trans_start_pix[1]\n",
    "                        \n",
    "                        all_dx[j] = curr_star_params[6]\n",
    "                        all_dy[j] = curr_star_params[7]\n",
    "                        all_offsets[j] = total_offset_x,total_offset_y\n",
    "                        \n",
    "                        all_measures['X_Gaia'][j] = gaia_end_pix[0]\n",
    "                        all_measures['Y_Gaia'][j] = gaia_end_pix[1]\n",
    "                        all_measures['X_HST'][j] = hst_start_pix[0]\n",
    "                        all_measures['Y_HST'][j] = hst_start_pix[1]\n",
    "                        all_measures['dX_Gaia'][j] = curr_star_params[6]\n",
    "                        all_measures['dY_Gaia'][j] = curr_star_params[7]\n",
    "                        \n",
    "                        np.save(f'{trans_path}{image_name}_true_Gaia_RADec.npy',true_gaia_xy)\n",
    "\n",
    "                        #transform the start and stop coordinates from HST to Gaia\n",
    "                        output_string = ' '.join(['%14.4f'%val for val in curr_star_params])\n",
    "                        f.write(output_string+'\\n')\n",
    "                n_threads = 4\n",
    "\n",
    "                poss_fixed_params = []\n",
    "\n",
    "                trans_params = ['Xo','Yo','Wo','Zo','rot','pix_scale_ratio','on_axis_skew','off_axis_skew']\n",
    "\n",
    "            #             TRANSFORMATION MATRIX: X_2 = AG*(X_1-Xo)+BG*(Y_1-Yo)+Wo\n",
    "            #                                    Y_2 = CG*(X_1-Xo)+DG*(Y_1-Yo)+Zo\n",
    "\n",
    "                n_images = 1\n",
    "\n",
    "                param_outputs = np.zeros((n_images,len(trans_params)))\n",
    "                param_outputs[:,0] = x0\n",
    "                param_outputs[:,1] = y0\n",
    "                param_outputs[:,2] = w0\n",
    "                param_outputs[:,3] = z0\n",
    "                param_outputs[:,4] = rot\n",
    "                param_outputs[:,5] = ratio\n",
    "                param_outputs[:,6] = on_skew\n",
    "                param_outputs[:,7] = off_skew\n",
    "\n",
    "                n_stars = n_star\n",
    "\n",
    "#                 delta_times = np.ones(n_stars)*delta_time\n",
    "                delta_times = star_delta_times\n",
    "\n",
    "                x,y = all_measures['X_HST'],all_measures['Y_HST']\n",
    "                x_g,y_g = all_measures['X_Gaia'],all_measures['Y_Gaia']\n",
    "                true_dx_g,true_dy_g = all_measures['dX_Gaia'],all_measures['dY_Gaia']\n",
    "                img_nums = np.array([0]*len(x))\n",
    "                gaia_ra_errs = gaia_ra_err\n",
    "                gaia_dec_errs = gaia_dec_err\n",
    "                not_stationary = ~stationary\n",
    "\n",
    "                hst_cov = np.zeros((2,2))\n",
    "                hst_cov[0,0] = hst_pix_sigmas**2\n",
    "                hst_cov[1,1] = hst_pix_sigmas**2   \n",
    "\n",
    "                gaia_covs = np.zeros((len(x),2,2)) #in mas, so remember to convert\n",
    "                gaia_covs[:,0,0] = np.power(gaia_ra_errs,2)\n",
    "                gaia_covs[:,1,1] = np.power(gaia_dec_errs,2)\n",
    "\n",
    "                n_im_show = min(2,n_images)\n",
    "                n_param_shared = 0\n",
    "                n_param_indv = 6      \n",
    "\n",
    "                #first guess\n",
    "                pos0 = []\n",
    "                dimLabels = []\n",
    "                #widths to explore for pos0\n",
    "                pos0_widths = []\n",
    "                rot_width = 0.01\n",
    "                ratio_width = 1e-4\n",
    "                wo_width = 0.1\n",
    "                zo_width = 0.1\n",
    "                skew_width = 1e-4\n",
    "                for j in range(n_images):\n",
    "                    xo,yo,wo,zo,rot,ratio,on_skew,off_skew = param_outputs[j]\n",
    "                    pos0.extend([rot,ratio,wo,zo,on_skew,off_skew])\n",
    "                    pos0_widths.extend([rot_width,ratio_width,wo_width,zo_width,skew_width,skew_width])\n",
    "                    dimLabels.extend(['rot$_{%d}$'%(j+1),'ratio$_{%d}$'%(j+1),r'W0$_{%d}$'%(j+1),r'Z0$_{%d}$'%(j+1),'on_skew$_{%d}$'%(j+1),'off_skew$_{%d}$'%(j+1),])\n",
    "                pos0 = np.array(pos0)\n",
    "                orig_pos0 = np.copy(pos0)\n",
    "                pos0_widths = np.array(pos0_widths)\n",
    "\n",
    "                nwalkers,ndim,nsteps = int(len(pos0)*3),len(pos0),100\n",
    "                nwalkers,ndim,nsteps = int(len(pos0)*10),len(pos0),500\n",
    "                nwalkers,ndim,nsteps = max(200,int(len(pos0)*10)),len(pos0),2000\n",
    "                nsteps = 500\n",
    "            #    nwalkers,ndim,nsteps = int(len(pos0)*2),len(pos0),100\n",
    "\n",
    "            #     pos = pos0*(1+1e-3*np.random.randn(nwalkers*ndim).reshape((nwalkers,ndim)))\n",
    "                pos = pos0+np.random.randn(nwalkers*ndim).reshape((nwalkers,ndim))*pos0_widths*0.1\n",
    "                burnin = int(0.7*nsteps)\n",
    "\n",
    "                def lnpost(params):        \n",
    "                    rots = params[0::n_param_indv]\n",
    "                    ratios = params[1::n_param_indv]\n",
    "                    w0s = params[2::n_param_indv]\n",
    "                    z0s = params[3::n_param_indv]\n",
    "                    on_skews = params[4::n_param_indv]\n",
    "                    off_skews = params[5::n_param_indv]\n",
    "                    x0s = param_outputs[:,0]\n",
    "                    y0s = param_outputs[:,1]\n",
    "\n",
    "                    if np.any(np.abs(w0s-param_outputs[:,2]) > 1000):\n",
    "                        return -np.inf\n",
    "                    if np.any(np.abs(z0s-param_outputs[:,3]) > 1000):\n",
    "                        return -np.inf\n",
    "                    if np.any(np.abs(rots-param_outputs[:,4]) > 20):\n",
    "                        return -np.inf\n",
    "\n",
    "                    ll = np.zeros(len(x))\n",
    "                    lp = np.zeros(len(x))\n",
    "\n",
    "                    for j in range(len(x0s)):\n",
    "                        curr_img = np.where(img_nums == j)[0]\n",
    "                        curr_x,curr_y = x[curr_img],y[curr_img]\n",
    "                        curr_x_g,curr_y_g = x_g[curr_img],y_g[curr_img]\n",
    "\n",
    "                        x0,y0,w0,z0 = x0s[j],y0s[j],w0s[j],z0s[j]\n",
    "                        rot,ratio = rots[j],ratios[j]\n",
    "                        on_skew,off_skew = on_skews[j],off_skews[j]\n",
    "                        a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "\n",
    "                        x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                        y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                        dx_trans = curr_x_g-x_trans\n",
    "                        dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        if np.any(np.abs(dx_trans) > 100) or np.any(np.abs(dy_trans) > 100):\n",
    "                            a,b,c,d = -1*np.array([a,b,c,d])\n",
    "\n",
    "                            x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                            y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                            dx_trans = curr_x_g-x_trans\n",
    "                            dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        det = a*d-b*c\n",
    "                        #inverse matrix for de-transforming\n",
    "                        ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                        matrix = np.array([[a,b],[c,d]])\n",
    "                        inv_matrix = np.array([[ai,bi],[ci,di]])\n",
    "\n",
    "                        x_final = ai*(curr_x_g-w0)+bi*(curr_y_g-z0)+x0 #HST final position\n",
    "                        y_final = ci*(curr_x_g-w0)+di*(curr_y_g-z0)+y0\n",
    "\n",
    "                        curr_pos_covs = gaia_covs[curr_img]/np.power(orig_pix_ratio*ratio,2)\n",
    "                        final_pos_cov = np.einsum('ij,njk->nik',inv_matrix,np.einsum('nij,jk->nik',curr_pos_covs,inv_matrix.T))\n",
    "\n",
    "                        comp_cov = hst_cov+final_pos_cov\n",
    "                        comp_cov_inv = np.linalg.inv(comp_cov)\n",
    "\n",
    "                        dpixels = np.array([x_final-curr_x,y_final-curr_y]).T\n",
    "\n",
    "                        ll[curr_img] = -0.5*np.log(np.linalg.det(comp_cov))\\\n",
    "                                         -0.5*np.einsum('ki,ki->k',dpixels,np.einsum('kij,kj->ki',comp_cov_inv,dpixels))   \n",
    "                    return np.sum(ll+lp)\n",
    "                \n",
    "                print('Initial MCMC Fitting of parameters using proper motions averages from priors:')\n",
    "\n",
    "                with Pool(n_threads) as pool:\n",
    "                    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnpost, pool = pool)\n",
    "                    for j, result in enumerate(tqdm(sampler.sample(pos, iterations=nsteps),total=nsteps,smoothing=0.1)):\n",
    "                        pass\n",
    "\n",
    "                samplerChain = sampler.chain\n",
    "                samples = samplerChain[:, burnin:, :].reshape((-1, ndim))\n",
    "                median_params = np.percentile(samples,50,axis=0)\n",
    "                median_param_errs = np.std(samples,axis=0)\n",
    "                median_covs = np.cov(samples,rowvar=False)\n",
    "                np.save(f'{trans_path}{image_name}_6p_transformation_INITIAL.npy',median_params)\n",
    "                np.save(f'{trans_path}{image_name}_6p_transformation_INITIAL_covs.npy',median_covs)\n",
    "                \n",
    "                orig_offsets = np.sqrt(np.power(true_dx_g,2)+np.power(true_dy_g,2))\n",
    "                orig_xy_offsets = np.array([true_dx_g,true_dy_g]).T\n",
    "                median_offset = np.zeros_like(orig_offsets)\n",
    "                median_xy_offset = np.zeros_like(orig_xy_offsets)\n",
    "                median_xy_offset_hst = np.zeros_like(orig_xy_offsets)\n",
    "\n",
    "                median_param_errs = np.std(samples,axis=0)\n",
    "                best_samp_ind = np.argmin(np.sum(np.power((samples-median_params)/median_param_errs,2),axis=1))\n",
    "                best_sample = samples[best_samp_ind]   \n",
    "\n",
    "                acpt_fracs = np.sum((np.sum(np.abs(samplerChain[:,:-1]-samplerChain[:,1:]),axis=2)>1e-15),axis=0)/samplerChain.shape[0]\n",
    "                minKeep = burnin\n",
    "                stats_vals = (acpt_fracs[minKeep:].min(),np.median(acpt_fracs[minKeep:]),np.mean(acpt_fracs[minKeep:]),acpt_fracs[minKeep:].max())\n",
    "\n",
    "                ndim_plot = n_param_shared+n_param_indv*n_im_show\n",
    "                if show_plots:\n",
    "                    fig = plt.figure(figsize=[12,6])\n",
    "                    gs = gridspec.GridSpec(1,2,width_ratios=[3,1],wspace=0)\n",
    "                    ax0 = plt.subplot(gs[:, 0])    \n",
    "                    plt.plot(np.arange(len(acpt_fracs)),acpt_fracs,lw=1,alpha=1)\n",
    "                    acc_lim = plt.ylim()\n",
    "                    plt.axvline(minKeep,c='r',label=f'Burnin ({burnin} steps)')\n",
    "                    plt.axhline(stats_vals[1],label='Median: %.3f'%stats_vals[1],c='k',ls='--')\n",
    "                    plt.axhline(stats_vals[2],label='Mean: %.3f'%stats_vals[2],c='k',ls='-')\n",
    "                    plt.axhline(stats_vals[0],label='Min: %.3f\\nMax: %.3f'%(stats_vals[0],stats_vals[-1]),c='grey')\n",
    "                    plt.axhline(stats_vals[-1],c='grey')\n",
    "                    plt.legend(loc='best')\n",
    "                    ax0.tick_params(axis='both',direction='inout',length=5,bottom=True,left=True,right=True)\n",
    "                    plt.xlabel('Step Number')\n",
    "                    plt.ylabel('Acceptance Fraction')\n",
    "                    ax1 = plt.subplot(gs[:, 1])\n",
    "                    ax1.axis('off')\n",
    "                    plt.hist(acpt_fracs[minKeep:],bins=min(len(acpt_fracs)-minKeep,100),density=True,cumulative=True,histtype='step',lw=3,orientation='horizontal')\n",
    "                    plt.axhline(stats_vals[1],label='Median: %.3f'%stats_vals[1],c='k',ls='--')\n",
    "                    plt.axhline(stats_vals[2],label='Mean: %.3f'%stats_vals[2],c='k',ls='-')\n",
    "                    plt.axhline(stats_vals[0],label='Min: %.3f\\nMax: %.3f'%(stats_vals[0],stats_vals[-1]),c='grey')\n",
    "                    plt.axhline(stats_vals[-1],c='grey')\n",
    "                    #plt.legend(loc='best')\n",
    "                    plt.ylim(acc_lim)\n",
    "                    xlim = np.array(plt.xlim());xlim[-1] *= 1.15\n",
    "                    plt.xlim(xlim)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.figure(figsize=[13,9/5*ndim_plot])\n",
    "                    for dim in range(ndim_plot):\n",
    "                        plt.subplot(ndim_plot,1,dim+1)\n",
    "                        plt.plot(samplerChain[:,:,dim].T,alpha=0.25)\n",
    "                        if dim != ndim_plot-1:\n",
    "                            plt.xticks([])\n",
    "                        else:\n",
    "                            plt.xticks(np.arange(0, samplerChain.shape[1]+1, samplerChain.shape[1]/10).astype(int))\n",
    "                        plt.ylabel(dimLabels[dim])\n",
    "                        plt.axvline(x=burnin,lw=2,ls='--',c='r')\n",
    "                        plt.axhline(truths[dim],lw=2,ls='--',c='C0')\n",
    "                    plt.xlabel('Step Number')\n",
    "                    #plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                corner.corner(samples[:,:ndim_plot], \n",
    "                              labels=dimLabels[:ndim_plot], \n",
    "                              quantiles=[0.16, 0.5, 0.84], show_titles=True,\n",
    "                              truths=truths,\n",
    "                              title_kwargs={\"fontsize\": 12})\n",
    "                plt.savefig(f'{trans_path}{image_name}_initial_transparam_fit.png')\n",
    "                if show_plots:\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    plt.close('all')\n",
    "\n",
    "                sample_cov = np.cov(samples[:,:ndim_plot],rowvar=False)\n",
    "                sample_median = np.median(samples[:,:ndim_plot],axis=0)\n",
    "\n",
    "                n_sim = 2000\n",
    "                samp_inds = np.random.choice(len(samples),n_sim,replace=False).astype(int)\n",
    "                new_offset_samps = np.zeros((n_sim,len(orig_offsets)))\n",
    "                new_offset_xy_samps = np.zeros((n_sim,len(orig_offsets),2))\n",
    "                new_pm_xy_hst_samps = np.zeros((n_sim,len(orig_offsets),2))\n",
    "                new_pm_ra_dec_samps = np.zeros((n_sim,len(orig_offsets),2))\n",
    "\n",
    "                x0s = np.copy(param_outputs[:,0])\n",
    "                y0s = np.copy(param_outputs[:,1])\n",
    "                for i in range(n_sim):\n",
    "                    sample = np.copy(samples[samp_inds[i]])\n",
    "\n",
    "                    rots = sample[n_param_shared+0::n_param_indv]\n",
    "                    ratios = sample[n_param_shared+1::n_param_indv]\n",
    "                    w0s = sample[n_param_shared+2::n_param_indv]\n",
    "                    z0s = sample[n_param_shared+3::n_param_indv]\n",
    "                    on_skews = sample[n_param_shared+4::n_param_indv]\n",
    "                    off_skews = sample[n_param_shared+5::n_param_indv]\n",
    "\n",
    "                    for j in range(len(x0s)):\n",
    "                        curr_img = np.where(img_nums == j)[0]\n",
    "                        curr_x,curr_y = x[curr_img],y[curr_img]\n",
    "                        curr_x_g,curr_y_g = x_g[curr_img],y_g[curr_img]\n",
    "                        curr_times = delta_times[curr_img]\n",
    "\n",
    "                        x0,y0,w0,z0 = x0s[j],y0s[j],w0s[j],z0s[j]\n",
    "                        rot,ratio = rots[j],ratios[j]\n",
    "                        on_skew,off_skew = on_skews[j],off_skews[j]\n",
    "                        a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "\n",
    "                        x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                        y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                        dx_trans = curr_x_g-x_trans\n",
    "                        dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        if np.any(np.abs(dx_trans) > 100) or np.any(np.abs(dy_trans) > 100):\n",
    "                            a,b,c,d = -1*np.array([a,b,c,d])\n",
    "\n",
    "                            x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                            y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                            dx_trans = curr_x_g-x_trans\n",
    "                            dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        dpix_trans = np.sqrt(np.power(dx_trans,2)+np.power(dy_trans,2))\n",
    "\n",
    "                        det = a*d-b*c\n",
    "                        #inverse matrix for de-transforming\n",
    "                        ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                        matrix = np.array([[a,b],[c,d]])\n",
    "                        inv_matrix = np.array([[ai,bi],[ci,di]])\n",
    "\n",
    "                        x_final = ai*(curr_x_g-w0)+bi*(curr_y_g-z0)+x0 #HST final position\n",
    "                        y_final = ci*(curr_x_g-w0)+di*(curr_y_g-z0)+y0\n",
    "\n",
    "                        dpixels = np.array([x_final-curr_x,y_final-curr_y]).T\n",
    "        #                 new_offset_xy_samps[i,curr_img,0] = dx_trans\n",
    "        #                 new_offset_xy_samps[i,curr_img,1] = dy_trans\n",
    "        #                 new_offset_samps[i,curr_img] = np.copy(dpix_trans)\n",
    "                        new_offset_xy_samps[i,curr_img,0] = dpixels[:,0]\n",
    "                        new_offset_xy_samps[i,curr_img,1] = dpixels[:,1]\n",
    "                        new_offset_samps[i,curr_img] = np.sqrt(np.power(dpixels[:,0],2)+np.power(dpixels[:,1],2))\n",
    "\n",
    "                        x_detrans = x_final\n",
    "                        y_detrans = y_final\n",
    "\n",
    "                        new_pm_xy_hst_samps[i,curr_img,0] = ratio*orig_pix_ratio*(x_detrans-curr_x)/curr_times #delta_x in HST pixels\n",
    "                        new_pm_xy_hst_samps[i,curr_img,1] = ratio*orig_pix_ratio*(y_detrans-curr_y)/curr_times #delta_x in HST                    \n",
    "\n",
    "                        new_pm_ra_dec_samps[i,curr_img,0] = -1*ratio*orig_pix_ratio*dx_trans/curr_times #pm_RA in mas/yr\n",
    "                        new_pm_ra_dec_samps[i,curr_img,1] = ratio*orig_pix_ratio*dy_trans/curr_times #pm_Dec in mas/yr                 \n",
    "\n",
    "            #     new_offset_summary = np.percentile(new_offset_samps,[16,50,84],axis=0)\n",
    "                new_offset_summary = np.percentile(np.sort(new_offset_samps,axis=1),[16,50,84],axis=0)\n",
    "                new_pm_ra_dec_summary = np.percentile(new_pm_ra_dec_samps,[16,50,84],axis=0)\n",
    "                \n",
    "                sample = np.copy(median_params)\n",
    "                \n",
    "                rots = sample[n_param_shared+0::n_param_indv]\n",
    "                ratios = sample[n_param_shared+1::n_param_indv]\n",
    "                w0s = sample[n_param_shared+2::n_param_indv]\n",
    "                z0s = sample[n_param_shared+3::n_param_indv]\n",
    "                on_skews = sample[n_param_shared+4::n_param_indv]\n",
    "                off_skews = sample[n_param_shared+5::n_param_indv]\n",
    "\n",
    "                median_offset_samps = np.zeros((len(orig_offsets)))\n",
    "                median_offset_xy_samps = np.zeros((len(orig_offsets),2))\n",
    "                median_offset_xy_samps_Gaia = np.zeros((len(orig_offsets),2))\n",
    "                median_pm_xy_hst_samps = np.zeros((len(orig_offsets),2))\n",
    "\n",
    "                for j in range(len(x0s)):\n",
    "                    curr_img = np.where(img_nums == j)[0]\n",
    "                    curr_x,curr_y = x[curr_img],y[curr_img]\n",
    "                    curr_x_g,curr_y_g = x_g[curr_img],y_g[curr_img]\n",
    "                    curr_times = delta_times[curr_img]\n",
    "\n",
    "                    x0,y0,w0,z0 = x0s[j],y0s[j],w0s[j],z0s[j]\n",
    "                    rot,ratio = rots[j],ratios[j]\n",
    "                    on_skew,off_skew = on_skews[j],off_skews[j]\n",
    "                    a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "\n",
    "                    x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                    y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                    dx_trans = curr_x_g-x_trans\n",
    "                    dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                    if np.any(np.abs(dx_trans) > 100) or np.any(np.abs(dy_trans) > 100):\n",
    "                        a,b,c,d = -1*np.array([a,b,c,d])\n",
    "\n",
    "                        x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                        y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                        dx_trans = curr_x_g-x_trans\n",
    "                        dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                    dpix_trans = np.sqrt(np.power(dx_trans,2)+np.power(dy_trans,2))\n",
    "                    median_offset_xy_samps_Gaia[curr_img,0] = dx_trans\n",
    "                    median_offset_xy_samps_Gaia[curr_img,1] = dy_trans\n",
    "\n",
    "                    det = a*d-b*c\n",
    "                    #inverse matrix for de-transforming\n",
    "                    ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                    matrix = np.array([[a,b],[c,d]])\n",
    "                    inv_matrix = np.array([[ai,bi],[ci,di]])\n",
    "\n",
    "                    x_final = ai*(curr_x_g-w0)+bi*(curr_y_g-z0)+x0 #HST final position\n",
    "                    y_final = ci*(curr_x_g-w0)+di*(curr_y_g-z0)+y0\n",
    "\n",
    "                    dpixels = np.array([x_final-curr_x,y_final-curr_y]).T\n",
    "    #                 new_offset_xy_samps[i,curr_img,0] = dx_trans\n",
    "    #                 new_offset_xy_samps[i,curr_img,1] = dy_trans\n",
    "    #                 new_offset_samps[i,curr_img] = np.copy(dpix_trans)\n",
    "                    median_offset_xy_samps[curr_img,0] = dpixels[:,0]\n",
    "                    median_offset_xy_samps[curr_img,1] = dpixels[:,1]\n",
    "                    median_offset_samps[curr_img] = np.sqrt(np.power(dpixels[:,0],2)+np.power(dpixels[:,1],2))\n",
    "\n",
    "                    x_detrans = x_final\n",
    "                    y_detrans = y_final\n",
    "\n",
    "                    median_pm_xy_hst_samps[curr_img,0] = ratio*orig_pix_ratio*(x_detrans-curr_x)/curr_times #delta_x in HST pixels\n",
    "                    median_pm_xy_hst_samps[curr_img,1] = ratio*orig_pix_ratio*(y_detrans-curr_y)/curr_times #delta_x in HST                    \n",
    "                \n",
    "                if show_plots:\n",
    "                    plt.figure(figsize=[10,5])\n",
    "                    plt.hist(orig_offsets,bins=10000,density=True,cumulative=True,histtype='step',lw=3,label='True')\n",
    "                    plt.hist(new_offset_summary[1],bins=10000,density=True,cumulative=True,histtype='step',label='New Fit',lw=2)\n",
    "                    plt.hist(new_offset_summary[0],bins=10000,density=True,cumulative=True,histtype='step',color='C1')\n",
    "                    plt.hist(new_offset_summary[2],bins=10000,density=True,cumulative=True,histtype='step',color='C1')\n",
    "                    plt.hist(np.sqrt(np.power(median_pm_xy_hst_samps[:,0],2)+np.power(median_pm_xy_hst_samps[:,1],2)),\n",
    "                             bins=10000,density=True,cumulative=True,histtype='step',lw=3,label='Pipeline Output')\n",
    "                    xlim = plt.xlim()\n",
    "                    for i in range(min(n_sim,200)):\n",
    "                        plt.hist(new_offset_samps[i],bins=10000,density=True,cumulative=True,histtype='step',lw=1,alpha=0.1,color='grey',zorder=-1e10)\n",
    "                    plt.xlim(xlim)\n",
    "                    plt.xlabel('Residual Pixel Offset (HST Pixels)');plt.ylabel('CDF')\n",
    "                    plt.legend(loc=6,bbox_to_anchor=(0.3,0.2))\n",
    "                    plt.show()\n",
    "\n",
    "                new_offsets_xy_samps_1d = np.zeros((n_sim*len(orig_offsets),2))\n",
    "                new_offsets_xy_samps_1d[:,0] = np.ravel(new_offset_xy_samps[:,:,0])\n",
    "                new_offsets_xy_samps_1d[:,1] = np.ravel(new_offset_xy_samps[:,:,1])\n",
    "                \n",
    "                if show_plots:\n",
    "                    fig = corner.corner(new_offsets_xy_samps_1d, \n",
    "                                          labels=[r'$\\Delta X$',r'$\\Delta Y$'], \n",
    "                                          quantiles=[0.16, 0.5, 0.84], show_titles=True,\n",
    "                                          title_kwargs={\"fontsize\": 12},bins=30)\n",
    "                    ax = fig.axes[0]\n",
    "                    xlim = ax.get_xlim()\n",
    "                    new_ax = ax.twinx()\n",
    "                    np.median(np.ravel(new_offset_xy_samps[:,:,0]))\n",
    "                    curr_x_vals = np.ravel(np.median(new_offset_xy_samps[:,:,0],axis=0))\n",
    "                    curr_y_vals = np.ravel(np.median(new_offset_xy_samps[:,:,1],axis=0))\n",
    "                    new_ax.hist(true_dx_g,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C0')\n",
    "                    new_ax.hist(curr_y_vals,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C1')\n",
    "                    new_ax.set_yticks([])\n",
    "                    ax = fig.axes[3]\n",
    "                    xlim = ax.get_xlim()\n",
    "                    new_ax = ax.twinx()\n",
    "                    new_ax.hist(true_dy_g,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C0')\n",
    "                    new_ax.hist(curr_y_vals,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C1')\n",
    "                    new_ax.set_yticks([])\n",
    "                    ax = fig.axes[2]\n",
    "                    ax.scatter(true_dy_g,true_dx_g,s=5,color='C0')\n",
    "                    ax.scatter(curr_x_vals,curr_y_vals,s=2,color='C1')\n",
    "                    plt.show()\n",
    "                    \n",
    "                    use_vals = (gaia_pm_errs[:,0] < 50) #only use good gaia pms in average\n",
    "                    ave_gaia_ivars = np.power(gaia_pm_errs[use_vals],-2)\n",
    "                    ave_gaia_pms = np.sum(ave_gaia_ivars*gaia_pms[use_vals],axis=0)/np.sum(ave_gaia_ivars,axis=0)\n",
    "                    ave_gaia_pm_errs = np.power(np.sum(ave_gaia_ivars,axis=0),-0.5)\n",
    "\n",
    "                    plt.figure(figsize=(7,7))\n",
    "                    color = 'C0'\n",
    "                    median_posterior_pms = np.median(new_pm_ra_dec_samps+ave_gaia_pms,axis=0)\n",
    "                    plt.scatter(median_posterior_pms[:,0]-star_pms[:,0],\n",
    "                                median_posterior_pms[:,1]-star_pms[:,1],\n",
    "                                s=100,facecolor='None',edgecolor=color,alpha=0.7)\n",
    "                    for star_ind in range(len(median_posterior_pms)):\n",
    "                        curr_samps = new_pm_ra_dec_samps[:,star_ind]+ave_gaia_pms-star_pms[star_ind]\n",
    "                        curr_med = np.median(curr_samps,axis=0)\n",
    "                        curr_cov = np.cov(curr_samps,rowvar=False)\n",
    "                        #add on uncertainty on average\n",
    "                        curr_cov[0,0] += ave_gaia_pm_errs[0]**2 \n",
    "                        curr_cov[1,1] += ave_gaia_pm_errs[1]**2\n",
    "\n",
    "                        curr_vals,curr_vects = np.linalg.eig(curr_cov)\n",
    "                        curr_vals = np.sqrt(curr_vals)\n",
    "\n",
    "                        err_vects = np.zeros_like(curr_vects)\n",
    "                        err_vects[0] = curr_vals[0]*curr_vects[:,0]\n",
    "                        err_vects[1] = curr_vals[1]*curr_vects[:,1]    \n",
    "\n",
    "                        err1_plot = [curr_med[0]-err_vects[0,0],curr_med[0]+err_vects[0,0]],\\\n",
    "                                    [curr_med[1]-err_vects[0,1],curr_med[1]+err_vects[0,1]]\n",
    "                        err2_plot = [curr_med[0]-err_vects[1,0],curr_med[0]+err_vects[1,0]],\\\n",
    "                                    [curr_med[1]-err_vects[1,1],curr_med[1]+err_vects[1,1]]\n",
    "\n",
    "                        zorder = -1e5\n",
    "\n",
    "                        plt.plot(err1_plot[0],err1_plot[1],color=color,lw=1,alpha=0.7,zorder=zorder-2)\n",
    "                        plt.plot(err2_plot[0],err2_plot[1],color=color,lw=1,alpha=0.7,zorder=zorder-1)\n",
    "                    plt.axvline(0,c='k',ls='--',lw=0.5,zorder=1e10)\n",
    "                    plt.axhline(0,c='k',ls='--',lw=0.5,zorder=1e10)\n",
    "                    ax = plt.gca()\n",
    "                    ax.set_aspect('equal')\n",
    "                    plt.xlabel('$\\Delta \\mu_{\\mathrm{RA}}$ (mas/yr)')\n",
    "                    plt.ylabel('$\\Delta \\mu_{\\mathrm{Dec}}$ (mas/yr)')\n",
    "                    plt.show()\n",
    "                \n",
    "                \n",
    "                rot,ratio,w0,z0,on_skew,off_skew = median_params\n",
    "                x0 = x0s[0]\n",
    "                y0 = y0s[0]\n",
    "                a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)                    \n",
    "                \n",
    "                #save the best fit median values using the observed pixel offsets, and no prior PM info\n",
    "                with open(trans_file,'w') as f:\n",
    "                    f.write('#### FAKE FIELD ####\\n')\n",
    "                    f.write('\\tField_Name: %s\\n'%chosen_field)\n",
    "                    f.write('\\tn_stars: %d\\n'%n_star)\n",
    "                    f.write('\\tDelta_Time (years): %f\\n'%delta_time)\n",
    "                    f.write('\\tseed: = %d\\n'%seed)\n",
    "\n",
    "                    f.write('\\n#### MASTER FRAME INFO ####\\n')\n",
    "                    f.write('\\tX_CENTER:\\t5000.0\\n')\n",
    "                    f.write('\\tY_CENTER:\\t5000.0\\n')\n",
    "                    f.write('\\tRA_CENTER:\\t%f\\n'%ra)\n",
    "                    f.write('\\tDEC_CENTER:\\t%f\\n'%dec)\n",
    "                    f.write('\\tSCALE (mas/pix):\\t%f\\n'%orig_pix_scale)\n",
    "                    f.write('\\n#### GAIA INFO ####\\n')\n",
    "\n",
    "                    f.write('\\n#### NEW TRANSFORMATIONS AFTER CLIP ####\\n')\n",
    "                    f.write('\\n')\n",
    "                    #put in the transformation parameters\n",
    "                    f.write('\\tSTARS FOUND IN COMMON:\\t%d\\n'%n_star)\n",
    "                    f.write('\\tTRANSFORMATION MATRIX:\\n\\n')\n",
    "                    f.write('\\t\\tAG: %f\\n'%a)\n",
    "                    f.write('\\t\\tBG: %f\\n'%b)\n",
    "                    f.write('\\t\\tCG: %f\\n'%c)\n",
    "                    f.write('\\t\\tDG: %f\\n'%d)\n",
    "                    f.write('\\t\\tXo: %f\\n'%x0)\n",
    "                    f.write('\\t\\tYo: %f\\n'%y0)\n",
    "                    f.write('\\t\\tWo: %f\\n'%w0)\n",
    "                    f.write('\\t\\tZo: %f\\n\\n'%z0)\n",
    "                    f.write('\\tROTATION (deg): %f\\n'%rot)\n",
    "                    f.write('\\tPIXEL-SCALE RATIO: %f\\n'%ratio)\n",
    "                    f.write('\\tREAL IMG PIXEL SCALE (mas/pix): %f\\n\\n'%(orig_pix_scale*ratio))\n",
    "                    f.write('\\tMAGNITUDE ZP: %f\\n\\n'%mag_zp)\n",
    "                    f.write('\\n#### SAVING MAT FILE ####\\n')\n",
    "                    \n",
    "                if (n_star >= 20) and (show_plots):\n",
    "                    plt.figure(figsize=(10,5))\n",
    "                    plt.hist(all_dx,histtype='step',label=r'$\\Delta X_G$')\n",
    "                    plt.hist(all_dy,histtype='step',label=r'$\\Delta Y_G$')\n",
    "                    plt.hist(all_offsets[:,0],histtype='step',label=r'Total $\\Delta X$')\n",
    "                    plt.hist(all_offsets[:,1],histtype='step',label=r'Total $\\Delta Y$')\n",
    "                    plt.legend(loc=6,bbox_to_anchor=(1.05,0.5))\n",
    "                    plt.show()\n",
    "                    \n",
    "                    aslkdjsdlkds\n",
    "                    \n",
    "# n_star = n_star_options[-1]\n",
    "# seed = seed_options[0]\n",
    "# delta_time = time_options[0] #years\n",
    "# chosen_field = 'FAKE_FIELD_01'\n",
    "\n",
    "# chosen_params = fake_field_params[chosen_field]\n",
    "# rot,ratio,w0,z0,on_skew,off_skew = chosen_params\n",
    "# a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "# x0,y0 = 0,0\n",
    "# mag_zp = 32.40\n",
    "# orig_pix_scale = 50 #mas/year\n",
    "# pix_scale = orig_pix_scale*ratio\n",
    "# ra,dec = 11.52660000,42.22526400 #near M31\n",
    "\n",
    "# n_star_string = f'n{n_star:03d}'\n",
    "# seed_string = f's{seed:03d}'\n",
    "# time_string = f't{round(delta_time*10):03d}'\n",
    "\n",
    "# np.random.seed(n_star*seed)\n",
    "# print(n_star_string,time_string,seed_string)\n",
    "\n",
    "#make fake output files with known transformation parameters\n",
    "#and see how well it can recover those values for different numbers of stars/trans params/delta_time\n",
    "\n",
    "#pick proper motions (maybe draw magnitude from real results, then choose random angle) and delta_time\n",
    "#define transformation parameters \n",
    "#define original HST position and then use PM vector (and transformation) to get Gaia position\n",
    "#save those outputs like the pipeline expects\n",
    "#read in data just like pipeline outputs, and see if we can recover as function of n_stars, transform params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "field = 'Fornax_dSph'\n",
    "\n",
    "im_names = ['j8fnezfmq',\\\n",
    "            'j8fnezfrq',\\\n",
    "            'j8fnf0fxq',\\\n",
    "            'j8fnf0g2q',\\\n",
    "            'j8hoonf2q',\\\n",
    "            'j8hooofaq']\n",
    "\n",
    "image_params = {}\n",
    "for im_ind,im_name in enumerate(im_names):\n",
    "    test_path = f'/Volumes/Kevin_Astro/Astronomy/HST_Gaia_PMs/GaiaHub_results/{field}/HST/mastDownload/HST/{im_name}/'\n",
    "    fname = f'{test_path}{im_name}_flc_6p_transformation.txt'\n",
    "\n",
    "    with open(fname,'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    stop_skipping = False\n",
    "    for line in lines:\n",
    "        if ('NEW TRANSFORMATIONS AFTER CLIP' not in line) and (not stop_skipping):\n",
    "            continue\n",
    "        else:\n",
    "            stop_skipping = True\n",
    "        if 'AG:' in line:\n",
    "            ag = float(line.strip().split(':')[-1])\n",
    "        if 'BG:' in line:\n",
    "            bg = float(line.strip().split(':')[-1])\n",
    "        if 'CG:' in line:\n",
    "            cg = float(line.strip().split(':')[-1])        \n",
    "        if 'DG:' in line:\n",
    "            dg = float(line.strip().split(':')[-1])        \n",
    "        if 'Xo:' in line:\n",
    "            x0 = float(line.strip().split(':')[-1])        \n",
    "        if 'Yo:' in line:\n",
    "            y0 = float(line.strip().split(':')[-1])        \n",
    "        if 'Wo:' in line:\n",
    "            w0 = float(line.strip().split(':')[-1])        \n",
    "        if 'Zo:' in line:\n",
    "            z0 = float(line.strip().split(':')[-1])        \n",
    "        if 'ROTATION (deg):' in line:\n",
    "            rot = float(line.strip().split(':')[-1])        \n",
    "        if 'PIXEL-SCALE RATIO:' in line:\n",
    "            ratio = float(line.strip().split(':')[-1]) \n",
    "\n",
    "    on_skew = 0.5*(ag-dg)\n",
    "    off_skew = 0.5*(bg+cg)\n",
    "\n",
    "    im_num = 'im%02d'%(im_ind+1)\n",
    "    \n",
    "    image_params[im_num] = np.array([rot,ratio,w0,z0,on_skew,off_skew,x0,y0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make multiple observations of the same set of stars to test the _MULTI pipeline\n",
    "#Base the transformation parameters off of the Fornax images\n",
    "\n",
    "show_plots = False\n",
    "# show_plots = True\n",
    "\n",
    "#rot,ratio,w0,z0,on_skew,off_skew,x0,y0 = chosen_params\n",
    "chosen_field = 'FAKE_FIELD_05'\n",
    "hst_image_offsets = np.linspace(0,1,len(im_names))*(1/365) #time between hst observations, years\n",
    "\n",
    "chosen_field = 'FAKE_FIELD_06'\n",
    "hst_image_offsets = np.linspace(0,1,len(im_names))*4.5 #time between hst observations, years\n",
    "\n",
    "n_star_options = np.array([5,10,15,20,25,30,40,50,75,100,150,200])[::-1]\n",
    "\n",
    "n_star_options = np.array([1000])[::-1]\n",
    "# n_star_options = np.array([5,6,7,8,9,10,11,12,13,14,15])[::-1]\n",
    "seed_options = np.arange(101,105+1).astype(int)\n",
    "# time_options = np.array([5,6,7,8,9,10,12.5,15,17.5,20])\n",
    "\n",
    "time_options = np.array([5,7.5,10,12.5,15])[::-1]\n",
    "time_options = np.sort(np.append(time_options,time_options+0.5))[::-1]\n",
    "# time_options = np.array([10,11,12,13,14,15])[::-1]\n",
    "\n",
    "print('Current number of combinations:',n_star_options.size*seed_options.size*time_options.size)\n",
    "#what is the uncertainty on measuring the positions? \n",
    "hst_pix_sigmas = 0.5/50 #in hst pixels from https://ui.adsabs.harvard.edu/abs/2022ApJ...933...76D/abstract\n",
    "\n",
    "#chosen_field == 'COSMOS':\n",
    "ra_center = '10:00:36.50'\n",
    "dec_center = '+02:20:47.8'\n",
    "\n",
    "field_coord = coord.SkyCoord(ra_center, dec_center, unit=(u.hourangle, u.deg))\n",
    "l = field_coord.galactic.l.radian\n",
    "b = field_coord.galactic.b.radian\n",
    "ra_deg = field_coord.ra.deg\n",
    "dec_deg = field_coord.dec.deg\n",
    "\n",
    "time_offsets = (-0.000,0.000) #in years, from the Gaia Time (2016.0)\n",
    "\n",
    "if not os.path.isdir(f'{path}{chosen_field}/'):\n",
    "    os.makedirs(f'{path}{chosen_field}/')\n",
    "\n",
    "field_num = int(chosen_field.split('_')[-1])\n",
    "\n",
    "for nstar_ind,n_star in enumerate(n_star_options):\n",
    "    nstar = n_star\n",
    "    n_stars = n_star\n",
    "    n_star_string = f'n{n_star:03d}'\n",
    "    for time_ind,delta_time in enumerate(time_options):\n",
    "        time_string = f't{round(delta_time*10):03d}'\n",
    "\n",
    "        #ensure there are at least 200 stars when summing over the seeds\n",
    "        n_seed_options = max(5,int(round(200/n_star)))\n",
    "#         n_seed_options = 1\n",
    "        seed_options = np.arange(101,101+n_seed_options,1).astype(int)\n",
    "        np.random.seed(((n_star+0)*(field_num+1000)*int(delta_time*10+10000))%(2**32))\n",
    "        \n",
    "        for seed_ind,seed in enumerate(seed_options):\n",
    "            seed_string = f's{seed:03d}'\n",
    "            #each row is a star\n",
    "\n",
    "            #draw PMs and errors from real measurements, then add noise\n",
    "#                     star_inds = np.random.choice(len(pm_size_and_errs),size=n_star,replace=False) \n",
    "\n",
    "            temp_param_weights = np.copy(new_param_weights)\n",
    "#                     temp_param_weights[large_pms] = 0\n",
    "#                     temp_param_weights /= np.sum(temp_param_weights)\n",
    "            star_inds = np.random.choice(len(new_param_weights),\n",
    "                                         p=temp_param_weights,\n",
    "                                         size=n_star,replace=True) \n",
    "\n",
    "            star_pm_and_errs = pm_size_and_errs[star_inds]\n",
    "            star_gmags = star_pm_and_errs[:,-2]\n",
    "            star_hst_mags = star_pm_and_errs[:,-1]\n",
    "            star_pm_errs = star_pm_and_errs[:,[2,3]]\n",
    "            star_pms = star_pm_and_errs[:,[0,1]]\n",
    "#                     star_pms = np.array([np.random.randn(n_star)*pm_errs[0]+pm_center[0],\\\n",
    "#                                          np.random.randn(n_star)*pm_errs[1]+pm_center[1]]).T\n",
    "            star_pm_size = np.sqrt(np.power(star_pms[:,0],2)+np.power(star_pms[:,1],2))\n",
    "#                     star_pm_dist_params = 0,0.5*np.diff(np.percentile(star_pm_size,[0.5,99.5]))[0]\n",
    "            star_pm_dist_params = np.median(star_pm_size),0.5*np.diff(np.percentile(star_pm_size,[16,84]))[0]\n",
    "            outliers = np.where((star_pm_size-star_pm_dist_params[0]) > 10*star_pm_dist_params[1])[0]\n",
    "\n",
    "            replace_n_star = len(outliers)\n",
    "            replace_count = 0\n",
    "            while replace_n_star > 0:\n",
    "                break\n",
    "#                         replace_star_inds = np.random.choice(len(pm_size_and_errs),size=replace_n_star,replace=False)\n",
    "                replace_star_inds = np.random.choice(len(new_param_weights),\n",
    "                                                         p=temp_param_weights,\n",
    "                                                         size=replace_n_star,replace=True)\n",
    "                star_inds[outliers] = replace_star_inds\n",
    "\n",
    "                replace_star_pm_and_errs = pm_size_and_errs[replace_star_inds]\n",
    "                replace_star_gmags = replace_star_pm_and_errs[:,-2]\n",
    "                replace_star_hst_mags = replace_star_pm_and_errs[:,-1]\n",
    "                replace_star_pm_errs = replace_star_pm_and_errs[:,[2,3]]\n",
    "                replace_star_pms = replace_star_pm_and_errs[:,[0,1]]\n",
    "#                         replace_star_pms = replace_star_pm_and_errs[:,[0,1]]+np.random.randn((2*replace_n_star)).reshape((replace_n_star,2))*replace_star_pm_errs\n",
    "#                         replace_star_pms = np.array([np.random.randn(replace_n_star)*pm_errs[0]+pm_center[0],\\\n",
    "#                                                      np.random.randn(replace_n_star)*pm_errs[1]+pm_center[1]]).T\n",
    "                replace_star_pm_size = np.sqrt(np.power(replace_star_pms[:,0],2)+np.power(replace_star_pms[:,1],2))\n",
    "                star_pms[outliers] = np.copy(replace_star_pms)\n",
    "                star_pm_and_errs[outliers] = np.copy(replace_star_pm_and_errs)\n",
    "                star_pm_size[outliers] = np.copy(replace_star_pm_size)\n",
    "                outliers = np.where((star_pm_size-star_pm_dist_params[0]) > 10*star_pm_dist_params[1])[0]\n",
    "                replace_n_star = len(outliers)\n",
    "                replace_count += 1\n",
    "#                     print(star_pm_dist_params,np.sum(outliers),replace_count)\n",
    "\n",
    "            star_gmags = star_pm_and_errs[:,-2]\n",
    "            star_hst_mags = star_pm_and_errs[:,-1]\n",
    "            star_pm_errs = star_pm_and_errs[:,[2,3]]\n",
    "            star_dists = new_params[star_inds,10] #in kpc\n",
    "            star_parallaxes = 1/star_dists\n",
    "            gaia_time_offsets = np.random.rand(n_star)*(time_offsets[1]-time_offsets[0])+time_offsets[0]\n",
    "            star_gaia_times = gaia_ref_epoch+gaia_time_offsets*u.year\n",
    "\n",
    "            stationary = np.zeros(len(star_inds)).astype(bool)\n",
    "            if chosen_field == 'FAKE_FIELD_02':\n",
    "                #make one of the stars a stationary source\n",
    "                n_stationary = 1\n",
    "#                         n_stationary = n_star\n",
    "#                         n_stationary = int(0.5*n_star)\n",
    "                stationary[:n_stationary] = True\n",
    "            star_pms[stationary] = 0.0\n",
    "            star_parallaxes[stationary] = 1e-6 #mas, corresponds to a giga-parsec distance\n",
    "            star_dists[stationary] = np.power(star_parallaxes[stationary],-1)\n",
    "            \n",
    "            #get Gaia-measured PMs and errors for building priors\n",
    "            faint_stars = (star_gmags > 21)\n",
    "#                     gaia_pm_err_sizes = model(star_gmags,*popt)\n",
    "            gaia_pm_err_sizes = pm_error(star_gmags)\n",
    "            pm_frac_ranges = [0.9,1.1] #pm_x_err/pm_y_err = frac\n",
    "            frac_draws = np.random.rand(n_star)*(pm_frac_ranges[1]-pm_frac_ranges[0])+pm_frac_ranges[0]\n",
    "            gaia_pmdec_err = gaia_pm_err_sizes*np.sqrt(1/(1+np.power(frac_draws,2)))\n",
    "            gaia_pmra_err = gaia_pmdec_err*frac_draws                  \n",
    "\n",
    "            gaia_pm_errs = np.array([gaia_pmra_err,gaia_pmdec_err]).T\n",
    "            gaia_pms = star_pms+np.random.randn((2*n_star)).reshape((n_star,2))*gaia_pm_errs\n",
    "            #no Gaia measure for stars fainter than G=21, so give 0 pm and large uncertainty for prior\n",
    "            gaia_pms[faint_stars] = 0\n",
    "            gaia_pm_errs[faint_stars] = 50                       \n",
    "            gaia_pms_and_errs = np.array([gaia_pms,gaia_pm_errs])\n",
    "\n",
    "            gaia_pos_err_sizes = pos_error(star_gmags)\n",
    "            pos_frac_ranges = [0.9,1.1] #x_err/y_err = frac\n",
    "            frac_draws = np.random.rand(n_star)*(pos_frac_ranges[1]-pos_frac_ranges[0])+pos_frac_ranges[0]\n",
    "            gaia_dec_err = gaia_pos_err_sizes*np.sqrt(1/(1+np.power(frac_draws,2)))\n",
    "            gaia_ra_err = gaia_dec_err*frac_draws     \n",
    "            gaia_pos_errs = np.array([gaia_ra_err,gaia_dec_err]).T\n",
    "\n",
    "            gaia_parallax_errs = parallax_error(star_gmags)\n",
    "            #gaia data has some negative parallaxes in it\n",
    "            gaia_parallaxes = star_parallaxes+np.random.randn(n_star)*gaia_parallax_errs\n",
    "            \n",
    "            pix_dims = (4096,4096)\n",
    "            xranges = (0,pix_dims[0])\n",
    "            yranges = (0,pix_dims[1])   \n",
    "            \n",
    "            in_from_edge = 10 #pixels\n",
    "            x_gaia_true = np.random.rand(n_star)*(xranges[1]-xranges[0]-2*in_from_edge)+(xranges[0]+in_from_edge)\n",
    "            y_gaia_true = np.random.rand(n_star)*(yranges[1]-yranges[0]-2*in_from_edge)+(yranges[0]+in_from_edge)\n",
    "            true_gaia_xy = np.array([x_gaia_true,y_gaia_true]).T\n",
    "            true_gaia_offsets = np.random.randn(n_star,2)*gaia_pos_errs #in RA,Dec, so remember to use -x,y\n",
    "            \n",
    "            gaia_ids = []\n",
    "            for j in range(n_star):\n",
    "                gaia_ids.append(f'{n_star_string}{time_string}{seed_string}_%03d'%j)\n",
    "            gaia_ids = np.array(gaia_ids)\n",
    "            \n",
    "            for im_ind,hst_image_name in enumerate(image_params):\n",
    "                chosen_params = image_params[hst_image_name]\n",
    "                rot,ratio,w0,z0,on_skew,off_skew,x0,y0 = chosen_params\n",
    "                a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "                det = a*d-b*c\n",
    "                #inverse matrix for de-transforming\n",
    "                ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                mag_zp = 32.40\n",
    "                orig_pix_scale = 50 #mas/year\n",
    "                orig_pix_ratio = orig_pix_scale\n",
    "                pix_scale = orig_pix_scale*ratio\n",
    "\n",
    "                ra,dec = ra_deg,dec_deg #near M31\n",
    "                \n",
    "                star_hst_times = gaia_ref_epoch-np.ones(n_star)*delta_time*u.year+hst_image_offsets[im_ind]*u.year\n",
    "                star_delta_times = (star_gaia_times-star_hst_times).to(u.year).value\n",
    "                \n",
    "                print(field_num,n_star_string,time_string,seed_string)\n",
    "\n",
    "                image_name = f'{hst_image_name}{n_star_string}{time_string}{seed_string}'\n",
    "                trans_path = f'{path}{chosen_field}/HST/mastDownload/HST/{image_name}/'\n",
    "                trans_file = f'{trans_path}{image_name}_6p_transformation.txt'\n",
    "                truths = np.array([rot,ratio,w0,z0,on_skew,off_skew])\n",
    "\n",
    "                if not os.path.isdir(trans_path):\n",
    "                    os.makedirs(trans_path)\n",
    "                print(trans_path)\n",
    "\n",
    "                #save the truth\n",
    "                truth_trans_file = f'{trans_path}{image_name}_6p_transformation_TRUTH.npy'\n",
    "                np.save(f'{truth_trans_file}',np.array([a,b,c,d,x0,y0,w0,z0,rot,ratio,on_skew,off_skew]))\n",
    "\n",
    "                #just use 4096 pixels in each dimension, with (0,0) in the center\n",
    "                np.save(f'{trans_path}{image_name}_HST_Gaia_times.npy',\n",
    "                        np.array([star_hst_times.value,star_gaia_times.value]).T)\n",
    "            \n",
    "                np.save(f'{trans_path}{image_name}_true_PMs.npy',star_pms) #chosen PMs in RA,Dec (mas/year)\n",
    "                np.save(f'{trans_path}{image_name}_true_parallaxes.npy',star_parallaxes) #mas\n",
    "                np.save(f'{trans_path}{image_name}_stationary_points.npy',stationary) #booleans of whether point is stationary\n",
    "\n",
    "                np.save(f'{trans_path}{image_name}_GaiaMeasure_PMs.npy',gaia_pms_and_errs)\n",
    "                np.save(f'{trans_path}{image_name}_GaiaMeasure_RADec_errs.npy',gaia_pos_errs)\n",
    "                np.save(f'{trans_path}{image_name}_GaiaMeasure_parallaxes.npy',\n",
    "                                            np.array([gaia_parallaxes,gaia_parallax_errs]).T)\n",
    "                np.save(f'{trans_path}{image_name}_Gaia_names.npy',gaia_ids)\n",
    "\n",
    "                parallax_offset_vector = np.zeros((n_star,2)) #(delta_ra/parallax,delta_dec/parallax)\n",
    "                for star_ind in range(n_star):\n",
    "                    hst_date = star_hst_times[star_ind]\n",
    "                    gaia_date = star_gaia_times[star_ind]\n",
    "                    parallax_offset_vector[star_ind] = delta_ra_dec_per_parallax(hst_date,gaia_date,\n",
    "                                                                                 ra_deg,dec_deg)        \n",
    "\n",
    "                #change it so that RA = -x_Gaia, Dec = y_Gaia\n",
    "                star_pixel_changes = star_pms*(star_delta_times[:,None]/pix_scale) \n",
    "                star_pixel_changes[:,0] *= -1 #so that x_Gaia = -RA\n",
    "                star_pixel_changes_parallax = -1*(star_parallaxes/pix_scale)[:,None]*parallax_offset_vector \n",
    "                star_pixel_changes_parallax[:,0] *= -1 #so that x_Gaia = -RA\n",
    "                star_pixel_pos_errs = gaia_pos_errs/pix_scale \n",
    "                \n",
    "                mat_file = f'{trans_path}{image_name}_flc.MAT'\n",
    "\n",
    "                with open(mat_file,'w') as f:\n",
    "                    #[X_Gaia, Y_Gaia, X_hst, Y_hst, mag_Gaia, mag_hst, delta_X_G, delta_Y_G, X_trans, Y_trans] (all in pixels)\n",
    "\n",
    "                    all_measures = {\n",
    "                                    'dX_Gaia':np.zeros(nstar),'dY_Gaia':np.zeros(nstar),\n",
    "                                    'X_Gaia':np.zeros(nstar),'Y_Gaia':np.zeros(nstar),\n",
    "                                    'X_HST':np.zeros(nstar),'Y_HST':np.zeros(nstar),\n",
    "                                   }\n",
    "\n",
    "                    all_dx = np.zeros(n_star)\n",
    "                    all_dy = np.zeros(n_star)\n",
    "                    all_offsets = np.zeros((n_star,2))\n",
    "\n",
    "                    for j in range(n_star):\n",
    "                        #add the change from the PM and the parallax\n",
    "                        curr_pixel_changes = np.copy(star_pixel_changes[j]+star_pixel_changes_parallax[j])\n",
    "                        chosen_gaia_x = x_gaia_true[j]\n",
    "                        chosen_gaia_y = y_gaia_true[j]\n",
    "\n",
    "                        curr_pixel_pos_errs = star_pixel_pos_errs[j]\n",
    "\n",
    "                        found_good = False\n",
    "\n",
    "                        while not found_good:\n",
    "                            gaia_end_pix = np.array((chosen_gaia_x,chosen_gaia_y))\n",
    "                            gaia_start_pix = np.array((chosen_gaia_x-curr_pixel_changes[0],\\\n",
    "                                                       chosen_gaia_y-curr_pixel_changes[1]))\n",
    "                            \n",
    "                            hst_end_pix = np.array((ai*(gaia_end_pix[0]-w0)+bi*(gaia_end_pix[1]-z0)+x0,\\\n",
    "                                                    ci*(gaia_end_pix[0]-w0)+di*(gaia_end_pix[1]-z0)+y0))\n",
    "                            hst_start_pix = np.array((ai*(gaia_start_pix[0]-w0)+bi*(gaia_start_pix[1]-z0)+x0,\\\n",
    "                                                      ci*(gaia_start_pix[0]-w0)+di*(gaia_start_pix[1]-z0)+y0))\n",
    "\n",
    "                            hst_pixel_errors = np.random.randn(4)*hst_pix_sigmas\n",
    "\n",
    "                            #add noise to HST pixels\n",
    "                            hst_start_pix[0] += hst_pixel_errors[0]\n",
    "                            hst_start_pix[1] += hst_pixel_errors[1]\n",
    "                            hst_end_pix[0] += hst_pixel_errors[2]\n",
    "                            hst_end_pix[1] += hst_pixel_errors[3]\n",
    "\n",
    "                            trans_start_pix = np.array((a*(hst_start_pix[0]-x0)+b*(hst_start_pix[1]-y0)+w0,\\\n",
    "                                                        c*(hst_start_pix[0]-x0)+d*(hst_start_pix[1]-y0)+z0))\n",
    "\n",
    "                            gaia_pixel_errors = np.random.randn(2)*curr_pixel_pos_errs[0],\\\n",
    "                                                np.random.randn(2)*curr_pixel_pos_errs[1]\n",
    "                            #add noise to Gaia pixels\n",
    "                            gaia_start_pix[0] += gaia_pixel_errors[0][0]\n",
    "                            gaia_start_pix[1] += gaia_pixel_errors[1][0]\n",
    "#                             gaia_end_pix[0] += gaia_pixel_errors[0][1] #don't add noise to the end\n",
    "#                             gaia_end_pix[1] += gaia_pixel_errors[1][1]\n",
    "                            gaia_end_pix[0] += (-1*true_gaia_offsets[j,0])/pix_scale #deltaRA = -deltaX\n",
    "                            gaia_end_pix[1] += (1*true_gaia_offsets[j,1])/pix_scale #deltaDec = +deltaY\n",
    "\n",
    "                            detrans_end_pix = np.array((ai*(gaia_end_pix[0]-w0)+bi*(gaia_end_pix[1]-z0)+x0,\\\n",
    "                                                        ci*(gaia_end_pix[0]-w0)+di*(gaia_end_pix[1]-z0)+y0))\n",
    "\n",
    "                            total_move = np.sqrt((detrans_end_pix[0]-hst_start_pix[0])**2+\n",
    "                                                 (detrans_end_pix[1]-hst_start_pix[1])**2)\n",
    "                            total_offset = np.sqrt((detrans_end_pix[0]-hst_start_pix[0]-curr_pixel_changes[0])**2+\n",
    "                                                   (detrans_end_pix[1]-hst_start_pix[1]-curr_pixel_changes[1])**2)\n",
    "                            total_offset_x = (detrans_end_pix[0]-hst_start_pix[0]-curr_pixel_changes[0])\n",
    "                            total_offset_y = (detrans_end_pix[1]-hst_start_pix[1]-curr_pixel_changes[1])\n",
    "    #                             if total_move < 1.0:\n",
    "    #                                 found_good = True\n",
    "                            found_good = True                                \n",
    "\n",
    "                        curr_star_params = np.zeros(10)*np.nan\n",
    "                        curr_star_params[0] = gaia_end_pix[0]\n",
    "                        curr_star_params[1] = gaia_end_pix[1]\n",
    "                        curr_star_params[2] = hst_start_pix[0]\n",
    "                        curr_star_params[3] = hst_start_pix[1]\n",
    "                        curr_star_params[4] = star_gmags[j]\n",
    "                        curr_star_params[5] = star_hst_mags[j]\n",
    "                        curr_star_params[6] = gaia_end_pix[0]-trans_start_pix[0]\n",
    "                        curr_star_params[7] = gaia_end_pix[1]-trans_start_pix[1]\n",
    "                        curr_star_params[8] = trans_start_pix[0]\n",
    "                        curr_star_params[9] = trans_start_pix[1]\n",
    "\n",
    "                        all_dx[j] = curr_star_params[6]\n",
    "                        all_dy[j] = curr_star_params[7]\n",
    "                        all_offsets[j] = total_offset_x,total_offset_y\n",
    "\n",
    "                        all_measures['X_Gaia'][j] = gaia_end_pix[0]\n",
    "                        all_measures['Y_Gaia'][j] = gaia_end_pix[1]\n",
    "                        all_measures['X_HST'][j] = hst_start_pix[0]\n",
    "                        all_measures['Y_HST'][j] = hst_start_pix[1]\n",
    "                        all_measures['dX_Gaia'][j] = curr_star_params[6]\n",
    "                        all_measures['dY_Gaia'][j] = curr_star_params[7]\n",
    "\n",
    "                        #transform the start and stop coordinates from HST to Gaia\n",
    "                        output_string = ' '.join(['%14.4f'%val for val in curr_star_params])\n",
    "                        f.write(output_string+'\\n')\n",
    "                        \n",
    "                        np.save(f'{trans_path}{image_name}_true_Gaia_RADec.npy',true_gaia_xy)\n",
    "                        np.save(f'{trans_path}{image_name}_true_Gaia_RADec_offsets.npy',true_gaia_offsets)\n",
    "                        \n",
    "                n_threads = 4\n",
    "\n",
    "                poss_fixed_params = []\n",
    "\n",
    "                trans_params = ['Xo','Yo','Wo','Zo','rot','pix_scale_ratio','on_axis_skew','off_axis_skew']\n",
    "\n",
    "            #             TRANSFORMATION MATRIX: X_2 = AG*(X_1-Xo)+BG*(Y_1-Yo)+Wo\n",
    "            #                                    Y_2 = CG*(X_1-Xo)+DG*(Y_1-Yo)+Zo\n",
    "\n",
    "                n_images = 1\n",
    "\n",
    "                param_outputs = np.zeros((n_images,len(trans_params)))\n",
    "                param_outputs[:,0] = x0\n",
    "                param_outputs[:,1] = y0\n",
    "                param_outputs[:,2] = w0\n",
    "                param_outputs[:,3] = z0\n",
    "                param_outputs[:,4] = rot\n",
    "                param_outputs[:,5] = ratio\n",
    "                param_outputs[:,6] = on_skew\n",
    "                param_outputs[:,7] = off_skew\n",
    "\n",
    "                n_stars = n_star\n",
    "\n",
    "    #                 delta_times = np.ones(n_stars)*delta_time\n",
    "                delta_times = star_delta_times\n",
    "\n",
    "                x,y = all_measures['X_HST'],all_measures['Y_HST']\n",
    "                x_g,y_g = all_measures['X_Gaia'],all_measures['Y_Gaia']\n",
    "                true_dx_g,true_dy_g = all_measures['dX_Gaia'],all_measures['dY_Gaia']\n",
    "                img_nums = np.array([0]*len(x))\n",
    "                gaia_ra_errs = gaia_ra_err\n",
    "                gaia_dec_errs = gaia_dec_err\n",
    "                not_stationary = ~stationary\n",
    "\n",
    "                hst_cov = np.zeros((2,2))\n",
    "                hst_cov[0,0] = hst_pix_sigmas**2\n",
    "                hst_cov[1,1] = hst_pix_sigmas**2   \n",
    "\n",
    "                gaia_covs = np.zeros((len(x),2,2)) #in mas, so remember to convert\n",
    "                gaia_covs[:,0,0] = np.power(gaia_ra_errs,2)\n",
    "                gaia_covs[:,1,1] = np.power(gaia_dec_errs,2)\n",
    "\n",
    "                n_im_show = min(2,n_images)\n",
    "                n_param_shared = 0\n",
    "                n_param_indv = 6      \n",
    "\n",
    "                #first guess\n",
    "                pos0 = []\n",
    "                dimLabels = []\n",
    "                #widths to explore for pos0\n",
    "                pos0_widths = []\n",
    "                rot_width = 0.01\n",
    "                ratio_width = 1e-4\n",
    "                wo_width = 0.1\n",
    "                zo_width = 0.1\n",
    "                skew_width = 1e-4\n",
    "                for j in range(n_images):\n",
    "                    xo,yo,wo,zo,rot,ratio,on_skew,off_skew = param_outputs[j]\n",
    "                    pos0.extend([rot,ratio,wo,zo,on_skew,off_skew])\n",
    "                    pos0_widths.extend([rot_width,ratio_width,wo_width,zo_width,skew_width,skew_width])\n",
    "                    dimLabels.extend(['rot$_{%d}$'%(j+1),'ratio$_{%d}$'%(j+1),r'W0$_{%d}$'%(j+1),r'Z0$_{%d}$'%(j+1),'on_skew$_{%d}$'%(j+1),'off_skew$_{%d}$'%(j+1),])\n",
    "                pos0 = np.array(pos0)\n",
    "                orig_pos0 = np.copy(pos0)\n",
    "                pos0_widths = np.array(pos0_widths)\n",
    "\n",
    "                nwalkers,ndim,nsteps = int(len(pos0)*3),len(pos0),100\n",
    "                nwalkers,ndim,nsteps = int(len(pos0)*10),len(pos0),500\n",
    "                nwalkers,ndim,nsteps = max(200,int(len(pos0)*10)),len(pos0),2000\n",
    "                nsteps = 500\n",
    "            #    nwalkers,ndim,nsteps = int(len(pos0)*2),len(pos0),100\n",
    "\n",
    "            #     pos = pos0*(1+1e-3*np.random.randn(nwalkers*ndim).reshape((nwalkers,ndim)))\n",
    "                pos = pos0+np.random.randn(nwalkers*ndim).reshape((nwalkers,ndim))*pos0_widths*0.1\n",
    "                burnin = int(0.7*nsteps)\n",
    "\n",
    "                def lnpost(params):        \n",
    "                    rots = params[0::n_param_indv]\n",
    "                    ratios = params[1::n_param_indv]\n",
    "                    w0s = params[2::n_param_indv]\n",
    "                    z0s = params[3::n_param_indv]\n",
    "                    on_skews = params[4::n_param_indv]\n",
    "                    off_skews = params[5::n_param_indv]\n",
    "                    x0s = param_outputs[:,0]\n",
    "                    y0s = param_outputs[:,1]\n",
    "\n",
    "                    if np.any(np.abs(w0s-param_outputs[:,2]) > 1000):\n",
    "                        return -np.inf\n",
    "                    if np.any(np.abs(z0s-param_outputs[:,3]) > 1000):\n",
    "                        return -np.inf\n",
    "                    if np.any(np.abs(rots-param_outputs[:,4]) > 20):\n",
    "                        return -np.inf\n",
    "\n",
    "                    ll = np.zeros(len(x))\n",
    "                    lp = np.zeros(len(x))\n",
    "\n",
    "                    for j in range(len(x0s)):\n",
    "                        curr_img = np.where(img_nums == j)[0]\n",
    "                        curr_x,curr_y = x[curr_img],y[curr_img]\n",
    "                        curr_x_g,curr_y_g = x_g[curr_img],y_g[curr_img]\n",
    "\n",
    "                        x0,y0,w0,z0 = x0s[j],y0s[j],w0s[j],z0s[j]\n",
    "                        rot,ratio = rots[j],ratios[j]\n",
    "                        on_skew,off_skew = on_skews[j],off_skews[j]\n",
    "                        a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "\n",
    "                        x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                        y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                        dx_trans = curr_x_g-x_trans\n",
    "                        dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        if np.any(np.abs(dx_trans) > 100) or np.any(np.abs(dy_trans) > 100):\n",
    "                            a,b,c,d = -1*np.array([a,b,c,d])\n",
    "\n",
    "                            x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                            y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                            dx_trans = curr_x_g-x_trans\n",
    "                            dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        det = a*d-b*c\n",
    "                        #inverse matrix for de-transforming\n",
    "                        ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                        matrix = np.array([[a,b],[c,d]])\n",
    "                        inv_matrix = np.array([[ai,bi],[ci,di]])\n",
    "\n",
    "                        x_final = ai*(curr_x_g-w0)+bi*(curr_y_g-z0)+x0 #HST final position\n",
    "                        y_final = ci*(curr_x_g-w0)+di*(curr_y_g-z0)+y0\n",
    "\n",
    "                        curr_pos_covs = gaia_covs[curr_img]/np.power(orig_pix_ratio*ratio,2)\n",
    "                        final_pos_cov = np.einsum('ij,njk->nik',inv_matrix,np.einsum('nij,jk->nik',curr_pos_covs,inv_matrix.T))\n",
    "\n",
    "                        comp_cov = hst_cov+final_pos_cov\n",
    "                        comp_cov_inv = np.linalg.inv(comp_cov)\n",
    "\n",
    "                        dpixels = np.array([x_final-curr_x,y_final-curr_y]).T\n",
    "\n",
    "                        ll[curr_img] = -0.5*np.log(np.linalg.det(comp_cov))\\\n",
    "                                         -0.5*np.einsum('ki,ki->k',dpixels,np.einsum('kij,kj->ki',comp_cov_inv,dpixels))   \n",
    "                    return np.sum(ll+lp)\n",
    "\n",
    "                print('Initial MCMC Fitting of parameters using proper motions averages from priors:')\n",
    "\n",
    "                with Pool(n_threads) as pool:\n",
    "                    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnpost, pool = pool)\n",
    "                    for j, result in enumerate(tqdm(sampler.sample(pos, iterations=nsteps),total=nsteps,smoothing=0.1)):\n",
    "                        pass\n",
    "\n",
    "                samplerChain = sampler.chain\n",
    "                samples = samplerChain[:, burnin:, :].reshape((-1, ndim))\n",
    "                median_params = np.percentile(samples,50,axis=0)\n",
    "                median_param_errs = np.std(samples,axis=0)\n",
    "                median_covs = np.cov(samples,rowvar=False)\n",
    "                np.save(f'{trans_path}{image_name}_6p_transformation_INITIAL.npy',median_params)\n",
    "                np.save(f'{trans_path}{image_name}_6p_transformation_INITIAL_covs.npy',median_covs)\n",
    "\n",
    "                orig_offsets = np.sqrt(np.power(true_dx_g,2)+np.power(true_dy_g,2))\n",
    "                orig_xy_offsets = np.array([true_dx_g,true_dy_g]).T\n",
    "                median_offset = np.zeros_like(orig_offsets)\n",
    "                median_xy_offset = np.zeros_like(orig_xy_offsets)\n",
    "                median_xy_offset_hst = np.zeros_like(orig_xy_offsets)\n",
    "\n",
    "                median_param_errs = np.std(samples,axis=0)\n",
    "                best_samp_ind = np.argmin(np.sum(np.power((samples-median_params)/median_param_errs,2),axis=1))\n",
    "                best_sample = samples[best_samp_ind]   \n",
    "\n",
    "                acpt_fracs = np.sum((np.sum(np.abs(samplerChain[:,:-1]-samplerChain[:,1:]),axis=2)>1e-15),axis=0)/samplerChain.shape[0]\n",
    "                minKeep = burnin\n",
    "                stats_vals = (acpt_fracs[minKeep:].min(),np.median(acpt_fracs[minKeep:]),np.mean(acpt_fracs[minKeep:]),acpt_fracs[minKeep:].max())\n",
    "\n",
    "                ndim_plot = n_param_shared+n_param_indv*n_im_show\n",
    "                if show_plots:\n",
    "                    fig = plt.figure(figsize=[12,6])\n",
    "                    gs = gridspec.GridSpec(1,2,width_ratios=[3,1],wspace=0)\n",
    "                    ax0 = plt.subplot(gs[:, 0])    \n",
    "                    plt.plot(np.arange(len(acpt_fracs)),acpt_fracs,lw=1,alpha=1)\n",
    "                    acc_lim = plt.ylim()\n",
    "                    plt.axvline(minKeep,c='r',label=f'Burnin ({burnin} steps)')\n",
    "                    plt.axhline(stats_vals[1],label='Median: %.3f'%stats_vals[1],c='k',ls='--')\n",
    "                    plt.axhline(stats_vals[2],label='Mean: %.3f'%stats_vals[2],c='k',ls='-')\n",
    "                    plt.axhline(stats_vals[0],label='Min: %.3f\\nMax: %.3f'%(stats_vals[0],stats_vals[-1]),c='grey')\n",
    "                    plt.axhline(stats_vals[-1],c='grey')\n",
    "                    plt.legend(loc='best')\n",
    "                    ax0.tick_params(axis='both',direction='inout',length=5,bottom=True,left=True,right=True)\n",
    "                    plt.xlabel('Step Number')\n",
    "                    plt.ylabel('Acceptance Fraction')\n",
    "                    ax1 = plt.subplot(gs[:, 1])\n",
    "                    ax1.axis('off')\n",
    "                    plt.hist(acpt_fracs[minKeep:],bins=min(len(acpt_fracs)-minKeep,100),density=True,cumulative=True,histtype='step',lw=3,orientation='horizontal')\n",
    "                    plt.axhline(stats_vals[1],label='Median: %.3f'%stats_vals[1],c='k',ls='--')\n",
    "                    plt.axhline(stats_vals[2],label='Mean: %.3f'%stats_vals[2],c='k',ls='-')\n",
    "                    plt.axhline(stats_vals[0],label='Min: %.3f\\nMax: %.3f'%(stats_vals[0],stats_vals[-1]),c='grey')\n",
    "                    plt.axhline(stats_vals[-1],c='grey')\n",
    "                    #plt.legend(loc='best')\n",
    "                    plt.ylim(acc_lim)\n",
    "                    xlim = np.array(plt.xlim());xlim[-1] *= 1.15\n",
    "                    plt.xlim(xlim)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.figure(figsize=[13,9/5*ndim_plot])\n",
    "                    for dim in range(ndim_plot):\n",
    "                        plt.subplot(ndim_plot,1,dim+1)\n",
    "                        plt.plot(samplerChain[:,:,dim].T,alpha=0.25)\n",
    "                        if dim != ndim_plot-1:\n",
    "                            plt.xticks([])\n",
    "                        else:\n",
    "                            plt.xticks(np.arange(0, samplerChain.shape[1]+1, samplerChain.shape[1]/10).astype(int))\n",
    "                        plt.ylabel(dimLabels[dim])\n",
    "                        plt.axvline(x=burnin,lw=2,ls='--',c='r')\n",
    "                        plt.axhline(truths[dim],lw=2,ls='--',c='C0')\n",
    "                    plt.xlabel('Step Number')\n",
    "                    #plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                corner.corner(samples[:,:ndim_plot], \n",
    "                              labels=dimLabels[:ndim_plot], \n",
    "                              quantiles=[0.16, 0.5, 0.84], show_titles=True,\n",
    "                              truths=truths,\n",
    "                              title_kwargs={\"fontsize\": 12})\n",
    "                plt.savefig(f'{trans_path}{image_name}_initial_transparam_fit.png')\n",
    "                if show_plots:\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    plt.close('all')\n",
    "\n",
    "                sample_cov = np.cov(samples[:,:ndim_plot],rowvar=False)\n",
    "                sample_median = np.median(samples[:,:ndim_plot],axis=0)\n",
    "\n",
    "                n_sim = 2000\n",
    "                samp_inds = np.random.choice(len(samples),n_sim,replace=False).astype(int)\n",
    "                new_offset_samps = np.zeros((n_sim,len(orig_offsets)))\n",
    "                new_offset_xy_samps = np.zeros((n_sim,len(orig_offsets),2))\n",
    "                new_pm_xy_hst_samps = np.zeros((n_sim,len(orig_offsets),2))\n",
    "                new_pm_ra_dec_samps = np.zeros((n_sim,len(orig_offsets),2))\n",
    "\n",
    "                x0s = np.copy(param_outputs[:,0])\n",
    "                y0s = np.copy(param_outputs[:,1])\n",
    "                for i in range(n_sim):\n",
    "                    sample = np.copy(samples[samp_inds[i]])\n",
    "\n",
    "                    rots = sample[n_param_shared+0::n_param_indv]\n",
    "                    ratios = sample[n_param_shared+1::n_param_indv]\n",
    "                    w0s = sample[n_param_shared+2::n_param_indv]\n",
    "                    z0s = sample[n_param_shared+3::n_param_indv]\n",
    "                    on_skews = sample[n_param_shared+4::n_param_indv]\n",
    "                    off_skews = sample[n_param_shared+5::n_param_indv]\n",
    "\n",
    "                    for j in range(len(x0s)):\n",
    "                        curr_img = np.where(img_nums == j)[0]\n",
    "                        curr_x,curr_y = x[curr_img],y[curr_img]\n",
    "                        curr_x_g,curr_y_g = x_g[curr_img],y_g[curr_img]\n",
    "                        curr_times = delta_times[curr_img]\n",
    "\n",
    "                        x0,y0,w0,z0 = x0s[j],y0s[j],w0s[j],z0s[j]\n",
    "                        rot,ratio = rots[j],ratios[j]\n",
    "                        on_skew,off_skew = on_skews[j],off_skews[j]\n",
    "                        a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "\n",
    "                        x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                        y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                        dx_trans = curr_x_g-x_trans\n",
    "                        dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        if np.any(np.abs(dx_trans) > 100) or np.any(np.abs(dy_trans) > 100):\n",
    "                            a,b,c,d = -1*np.array([a,b,c,d])\n",
    "\n",
    "                            x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                            y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                            dx_trans = curr_x_g-x_trans\n",
    "                            dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                        dpix_trans = np.sqrt(np.power(dx_trans,2)+np.power(dy_trans,2))\n",
    "\n",
    "                        det = a*d-b*c\n",
    "                        #inverse matrix for de-transforming\n",
    "                        ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                        matrix = np.array([[a,b],[c,d]])\n",
    "                        inv_matrix = np.array([[ai,bi],[ci,di]])\n",
    "\n",
    "                        x_final = ai*(curr_x_g-w0)+bi*(curr_y_g-z0)+x0 #HST final position\n",
    "                        y_final = ci*(curr_x_g-w0)+di*(curr_y_g-z0)+y0\n",
    "\n",
    "                        dpixels = np.array([x_final-curr_x,y_final-curr_y]).T\n",
    "        #                 new_offset_xy_samps[i,curr_img,0] = dx_trans\n",
    "        #                 new_offset_xy_samps[i,curr_img,1] = dy_trans\n",
    "        #                 new_offset_samps[i,curr_img] = np.copy(dpix_trans)\n",
    "                        new_offset_xy_samps[i,curr_img,0] = dpixels[:,0]\n",
    "                        new_offset_xy_samps[i,curr_img,1] = dpixels[:,1]\n",
    "                        new_offset_samps[i,curr_img] = np.sqrt(np.power(dpixels[:,0],2)+np.power(dpixels[:,1],2))\n",
    "\n",
    "                        x_detrans = x_final\n",
    "                        y_detrans = y_final\n",
    "\n",
    "                        new_pm_xy_hst_samps[i,curr_img,0] = ratio*orig_pix_ratio*(x_detrans-curr_x)/curr_times #delta_x in HST pixels\n",
    "                        new_pm_xy_hst_samps[i,curr_img,1] = ratio*orig_pix_ratio*(y_detrans-curr_y)/curr_times #delta_x in HST                    \n",
    "\n",
    "                        new_pm_ra_dec_samps[i,curr_img,0] = -1*ratio*orig_pix_ratio*dx_trans/curr_times #pm_RA in mas/yr\n",
    "                        new_pm_ra_dec_samps[i,curr_img,1] = ratio*orig_pix_ratio*dy_trans/curr_times #pm_Dec in mas/yr                 \n",
    "\n",
    "            #     new_offset_summary = np.percentile(new_offset_samps,[16,50,84],axis=0)\n",
    "                new_offset_summary = np.percentile(np.sort(new_offset_samps,axis=1),[16,50,84],axis=0)\n",
    "                new_pm_ra_dec_summary = np.percentile(new_pm_ra_dec_samps,[16,50,84],axis=0)\n",
    "\n",
    "                sample = np.copy(median_params)\n",
    "\n",
    "                rots = sample[n_param_shared+0::n_param_indv]\n",
    "                ratios = sample[n_param_shared+1::n_param_indv]\n",
    "                w0s = sample[n_param_shared+2::n_param_indv]\n",
    "                z0s = sample[n_param_shared+3::n_param_indv]\n",
    "                on_skews = sample[n_param_shared+4::n_param_indv]\n",
    "                off_skews = sample[n_param_shared+5::n_param_indv]\n",
    "\n",
    "                median_offset_samps = np.zeros((len(orig_offsets)))\n",
    "                median_offset_xy_samps = np.zeros((len(orig_offsets),2))\n",
    "                median_offset_xy_samps_Gaia = np.zeros((len(orig_offsets),2))\n",
    "                median_pm_xy_hst_samps = np.zeros((len(orig_offsets),2))\n",
    "\n",
    "                for j in range(len(x0s)):\n",
    "                    curr_img = np.where(img_nums == j)[0]\n",
    "                    curr_x,curr_y = x[curr_img],y[curr_img]\n",
    "                    curr_x_g,curr_y_g = x_g[curr_img],y_g[curr_img]\n",
    "                    curr_times = delta_times[curr_img]\n",
    "\n",
    "                    x0,y0,w0,z0 = x0s[j],y0s[j],w0s[j],z0s[j]\n",
    "                    rot,ratio = rots[j],ratios[j]\n",
    "                    on_skew,off_skew = on_skews[j],off_skews[j]\n",
    "                    a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)\n",
    "\n",
    "                    x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                    y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                    dx_trans = curr_x_g-x_trans\n",
    "                    dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                    if np.any(np.abs(dx_trans) > 100) or np.any(np.abs(dy_trans) > 100):\n",
    "                        a,b,c,d = -1*np.array([a,b,c,d])\n",
    "\n",
    "                        x_trans = a*(curr_x-x0)+b*(curr_y-y0)+w0\n",
    "                        y_trans = c*(curr_x-x0)+d*(curr_y-y0)+z0\n",
    "\n",
    "                        dx_trans = curr_x_g-x_trans\n",
    "                        dy_trans = curr_y_g-y_trans\n",
    "\n",
    "                    dpix_trans = np.sqrt(np.power(dx_trans,2)+np.power(dy_trans,2))\n",
    "                    median_offset_xy_samps_Gaia[curr_img,0] = dx_trans\n",
    "                    median_offset_xy_samps_Gaia[curr_img,1] = dy_trans\n",
    "\n",
    "                    det = a*d-b*c\n",
    "                    #inverse matrix for de-transforming\n",
    "                    ai,bi,ci,di = np.array([d,-b,-c,a])/det\n",
    "                    matrix = np.array([[a,b],[c,d]])\n",
    "                    inv_matrix = np.array([[ai,bi],[ci,di]])\n",
    "\n",
    "                    x_final = ai*(curr_x_g-w0)+bi*(curr_y_g-z0)+x0 #HST final position\n",
    "                    y_final = ci*(curr_x_g-w0)+di*(curr_y_g-z0)+y0\n",
    "\n",
    "                    dpixels = np.array([x_final-curr_x,y_final-curr_y]).T\n",
    "    #                 new_offset_xy_samps[i,curr_img,0] = dx_trans\n",
    "    #                 new_offset_xy_samps[i,curr_img,1] = dy_trans\n",
    "    #                 new_offset_samps[i,curr_img] = np.copy(dpix_trans)\n",
    "                    median_offset_xy_samps[curr_img,0] = dpixels[:,0]\n",
    "                    median_offset_xy_samps[curr_img,1] = dpixels[:,1]\n",
    "                    median_offset_samps[curr_img] = np.sqrt(np.power(dpixels[:,0],2)+np.power(dpixels[:,1],2))\n",
    "\n",
    "                    x_detrans = x_final\n",
    "                    y_detrans = y_final\n",
    "\n",
    "                    median_pm_xy_hst_samps[curr_img,0] = ratio*orig_pix_ratio*(x_detrans-curr_x)/curr_times #delta_x in HST pixels\n",
    "                    median_pm_xy_hst_samps[curr_img,1] = ratio*orig_pix_ratio*(y_detrans-curr_y)/curr_times #delta_x in HST                    \n",
    "\n",
    "                if show_plots:\n",
    "                    plt.figure(figsize=[10,5])\n",
    "                    plt.hist(orig_offsets,bins=10000,density=True,cumulative=True,histtype='step',lw=3,label='True')\n",
    "                    plt.hist(new_offset_summary[1],bins=10000,density=True,cumulative=True,histtype='step',label='New Fit',lw=2)\n",
    "                    plt.hist(new_offset_summary[0],bins=10000,density=True,cumulative=True,histtype='step',color='C1')\n",
    "                    plt.hist(new_offset_summary[2],bins=10000,density=True,cumulative=True,histtype='step',color='C1')\n",
    "                    plt.hist(np.sqrt(np.power(median_pm_xy_hst_samps[:,0],2)+np.power(median_pm_xy_hst_samps[:,1],2)),\n",
    "                             bins=10000,density=True,cumulative=True,histtype='step',lw=3,label='Pipeline Output')\n",
    "                    xlim = plt.xlim()\n",
    "                    for i in range(min(n_sim,200)):\n",
    "                        plt.hist(new_offset_samps[i],bins=10000,density=True,cumulative=True,histtype='step',lw=1,alpha=0.1,color='grey',zorder=-1e10)\n",
    "                    plt.xlim(xlim)\n",
    "                    plt.xlabel('Residual Pixel Offset (HST Pixels)');plt.ylabel('CDF')\n",
    "                    plt.legend(loc=6,bbox_to_anchor=(0.3,0.2))\n",
    "                    plt.show()\n",
    "\n",
    "                new_offsets_xy_samps_1d = np.zeros((n_sim*len(orig_offsets),2))\n",
    "                new_offsets_xy_samps_1d[:,0] = np.ravel(new_offset_xy_samps[:,:,0])\n",
    "                new_offsets_xy_samps_1d[:,1] = np.ravel(new_offset_xy_samps[:,:,1])\n",
    "\n",
    "                if show_plots:\n",
    "                    fig = corner.corner(new_offsets_xy_samps_1d, \n",
    "                                          labels=[r'$\\Delta X$',r'$\\Delta Y$'], \n",
    "                                          quantiles=[0.16, 0.5, 0.84], show_titles=True,\n",
    "                                          title_kwargs={\"fontsize\": 12},bins=30)\n",
    "                    ax = fig.axes[0]\n",
    "                    xlim = ax.get_xlim()\n",
    "                    new_ax = ax.twinx()\n",
    "                    np.median(np.ravel(new_offset_xy_samps[:,:,0]))\n",
    "                    curr_x_vals = np.ravel(np.median(new_offset_xy_samps[:,:,0],axis=0))\n",
    "                    curr_y_vals = np.ravel(np.median(new_offset_xy_samps[:,:,1],axis=0))\n",
    "                    new_ax.hist(true_dx_g,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C0')\n",
    "                    new_ax.hist(curr_y_vals,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C1')\n",
    "                    new_ax.set_yticks([])\n",
    "                    ax = fig.axes[3]\n",
    "                    xlim = ax.get_xlim()\n",
    "                    new_ax = ax.twinx()\n",
    "                    new_ax.hist(true_dy_g,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C0')\n",
    "                    new_ax.hist(curr_y_vals,density=True,alpha=0.75,\n",
    "                            range=xlim,bins=10,histtype='step',lw=2,color='C1')\n",
    "                    new_ax.set_yticks([])\n",
    "                    ax = fig.axes[2]\n",
    "                    ax.scatter(true_dy_g,true_dx_g,s=5,color='C0')\n",
    "                    ax.scatter(curr_x_vals,curr_y_vals,s=2,color='C1')\n",
    "                    plt.show()\n",
    "\n",
    "                    use_vals = (gaia_pm_errs[:,0] < 50) #only use good gaia pms in average\n",
    "                    ave_gaia_ivars = np.power(gaia_pm_errs[use_vals],-2)\n",
    "                    ave_gaia_pms = np.sum(ave_gaia_ivars*gaia_pms[use_vals],axis=0)/np.sum(ave_gaia_ivars,axis=0)\n",
    "                    ave_gaia_pm_errs = np.power(np.sum(ave_gaia_ivars,axis=0),-0.5)\n",
    "\n",
    "                    plt.figure(figsize=(7,7))\n",
    "                    color = 'C0'\n",
    "                    median_posterior_pms = np.median(new_pm_ra_dec_samps+ave_gaia_pms,axis=0)\n",
    "                    plt.scatter(median_posterior_pms[:,0]-star_pms[:,0],\n",
    "                                median_posterior_pms[:,1]-star_pms[:,1],\n",
    "                                s=100,facecolor='None',edgecolor=color,alpha=0.7)\n",
    "                    for star_ind in range(len(median_posterior_pms)):\n",
    "                        curr_samps = new_pm_ra_dec_samps[:,star_ind]+ave_gaia_pms-star_pms[star_ind]\n",
    "                        curr_med = np.median(curr_samps,axis=0)\n",
    "                        curr_cov = np.cov(curr_samps,rowvar=False)\n",
    "                        #add on uncertainty on average\n",
    "                        curr_cov[0,0] += ave_gaia_pm_errs[0]**2 \n",
    "                        curr_cov[1,1] += ave_gaia_pm_errs[1]**2\n",
    "\n",
    "                        curr_vals,curr_vects = np.linalg.eig(curr_cov)\n",
    "                        curr_vals = np.sqrt(curr_vals)\n",
    "\n",
    "                        err_vects = np.zeros_like(curr_vects)\n",
    "                        err_vects[0] = curr_vals[0]*curr_vects[:,0]\n",
    "                        err_vects[1] = curr_vals[1]*curr_vects[:,1]    \n",
    "\n",
    "                        err1_plot = [curr_med[0]-err_vects[0,0],curr_med[0]+err_vects[0,0]],\\\n",
    "                                    [curr_med[1]-err_vects[0,1],curr_med[1]+err_vects[0,1]]\n",
    "                        err2_plot = [curr_med[0]-err_vects[1,0],curr_med[0]+err_vects[1,0]],\\\n",
    "                                    [curr_med[1]-err_vects[1,1],curr_med[1]+err_vects[1,1]]\n",
    "\n",
    "                        zorder = -1e5\n",
    "\n",
    "                        plt.plot(err1_plot[0],err1_plot[1],color=color,lw=1,alpha=0.7,zorder=zorder-2)\n",
    "                        plt.plot(err2_plot[0],err2_plot[1],color=color,lw=1,alpha=0.7,zorder=zorder-1)\n",
    "                    plt.axvline(0,c='k',ls='--',lw=0.5,zorder=1e10)\n",
    "                    plt.axhline(0,c='k',ls='--',lw=0.5,zorder=1e10)\n",
    "                    ax = plt.gca()\n",
    "                    ax.set_aspect('equal')\n",
    "                    plt.xlabel('$\\Delta \\mu_{\\mathrm{RA}}$ (mas/yr)')\n",
    "                    plt.ylabel('$\\Delta \\mu_{\\mathrm{Dec}}$ (mas/yr)')\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "                rot,ratio,w0,z0,on_skew,off_skew = median_params\n",
    "                x0 = x0s[0]\n",
    "                y0 = y0s[0]\n",
    "                a,b,c,d = get_matrix_params(on_skew,off_skew,ratio,rot)                    \n",
    "\n",
    "                #save the best fit median values using the observed pixel offsets, and no prior PM info\n",
    "                with open(trans_file,'w') as f:\n",
    "                    f.write('#### FAKE FIELD ####\\n')\n",
    "                    f.write('\\tField_Name: %s\\n'%chosen_field)\n",
    "                    f.write('\\tn_stars: %d\\n'%n_star)\n",
    "                    f.write('\\tDelta_Time (years): %f\\n'%delta_time)\n",
    "                    f.write('\\tseed: = %d\\n'%seed)\n",
    "\n",
    "                    f.write('\\n#### MASTER FRAME INFO ####\\n')\n",
    "                    f.write('\\tX_CENTER:\\t5000.0\\n')\n",
    "                    f.write('\\tY_CENTER:\\t5000.0\\n')\n",
    "                    f.write('\\tRA_CENTER:\\t%f\\n'%ra)\n",
    "                    f.write('\\tDEC_CENTER:\\t%f\\n'%dec)\n",
    "                    f.write('\\tSCALE (mas/pix):\\t%f\\n'%orig_pix_scale)\n",
    "                    f.write('\\n#### GAIA INFO ####\\n')\n",
    "\n",
    "                    f.write('\\n#### NEW TRANSFORMATIONS AFTER CLIP ####\\n')\n",
    "                    f.write('\\n')\n",
    "                    #put in the transformation parameters\n",
    "                    f.write('\\tSTARS FOUND IN COMMON:\\t%d\\n'%n_star)\n",
    "                    f.write('\\tTRANSFORMATION MATRIX:\\n\\n')\n",
    "                    f.write('\\t\\tAG: %f\\n'%a)\n",
    "                    f.write('\\t\\tBG: %f\\n'%b)\n",
    "                    f.write('\\t\\tCG: %f\\n'%c)\n",
    "                    f.write('\\t\\tDG: %f\\n'%d)\n",
    "                    f.write('\\t\\tXo: %f\\n'%x0)\n",
    "                    f.write('\\t\\tYo: %f\\n'%y0)\n",
    "                    f.write('\\t\\tWo: %f\\n'%w0)\n",
    "                    f.write('\\t\\tZo: %f\\n\\n'%z0)\n",
    "                    f.write('\\tROTATION (deg): %f\\n'%rot)\n",
    "                    f.write('\\tPIXEL-SCALE RATIO: %f\\n'%ratio)\n",
    "                    f.write('\\tREAL IMG PIXEL SCALE (mas/pix): %f\\n\\n'%(orig_pix_scale*ratio))\n",
    "                    f.write('\\tMAGNITUDE ZP: %f\\n\\n'%mag_zp)\n",
    "                    f.write('\\n#### SAVING MAT FILE ####\\n')\n",
    "\n",
    "                if (n_star >= 20) and (show_plots):\n",
    "                    plt.figure(figsize=(10,5))\n",
    "                    plt.hist(all_dx,histtype='step',label=r'$\\Delta X_G$')\n",
    "                    plt.hist(all_dy,histtype='step',label=r'$\\Delta Y_G$')\n",
    "                    plt.hist(all_offsets[:,0],histtype='step',label=r'Total $\\Delta X$')\n",
    "                    plt.hist(all_offsets[:,1],histtype='step',label=r'Total $\\Delta Y$')\n",
    "                    plt.legend(loc=6,bbox_to_anchor=(1.05,0.5))\n",
    "                    plt.show()\n",
    "\n",
    "                    aslkdjsdlkds\n",
    "            lakjlksjdlkjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "Using the Gaia-measured values for star number $i$, which has a prior PM of $(\\mu_{x,i}',\\mu_{y,i}')$, a prior parallax of $\\mathrm{plx}_i'$, a prior initial pixel position of $(x_{H,i}'(t),y_{H,i}'(t))$ in the HST image, and a prior final pixel position of $(x_{G,i}'(t+\\Delta t),y_{G,i}'(t+\\Delta t))$ in the Gaia image:\n",
    "\n",
    "$$\\mathrm{pixel~scale~ratio} = \\sqrt{ad-bc}$$\n",
    "$$\\theta = \\arctan{\\left(\\frac{b-c}{a+d}\\right)}$$\n",
    "$$\\mathrm{on~axis~skew} = \\frac{1}{2}(a-d)$$\n",
    "$$\\mathrm{off~axis~skew} = \\frac{1}{2}(b+c)$$\n",
    "$$\\mathrm{HST~pixel~scale} = \\mathrm{HST~PS} = 50~\\mathrm{mas~yr}^{-1} \\cdot\\left(\\mathrm{pixel~scale~ratio}\\right) $$\n",
    "\n",
    "$$\\pmb R = \\left(\\begin{matrix}\n",
    "a&b\\\\\n",
    "c&d\\\\\n",
    "\\end{matrix}\\right)$$\n",
    "\n",
    "$$\\pmb R_{inv} = \\pmb R^{-1} = \\frac{1}{ad-bc}\\left(\\begin{matrix}\n",
    "d&-b\\\\\n",
    "-c&a\\\\\n",
    "\\end{matrix}\\right)$$\n",
    "\n",
    "Properties of star $i$:\n",
    "\n",
    "$$\\mathrm{parallax}_i = \\mathrm{plx}_i \\sim \\mathcal{N}\\left( \\mathrm{plx}'_i, \\sigma_{\\mathrm{plx},i}\\right)$$\n",
    "$$\\vec{\\Delta \\mathrm{plx}_i} = \\frac{1}{\\mathrm{plx}}\\left(\\begin{matrix}\\Delta \\mathrm{RA}_i\\\\ \\Delta \\mathrm{Dec}_i\\\\\\end{matrix}\\right) = \\mathrm{ORBIT~FUNCTION}(t,t+\\Delta t)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\\mu_{\\mathrm{RA},i}\\\\\\mu_{\\mathrm{Dec},i}\\\\\\end{matrix}\\right) \\sim \\mathcal{N}\\left(\\left(\\begin{matrix}\\mu_{\\mathrm{RA},i}'\\\\\\mu_{\\mathrm{Dec},i}'\\\\\\end{matrix}\\right), \\pmb V_{\\mu,\\mathrm{RA,Dec},i}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\\mu_{x,G,i}\\\\\\mu_{y,G,i}\\\\\\end{matrix}\\right) = \\left(\\begin{matrix}\n",
    "-1&0\\\\\n",
    "0&1\\\\\n",
    "\\end{matrix}\\right)\\left(\\begin{matrix}\\mu_{\\mathrm{RA},i}\\\\\\mu_{\\mathrm{Dec},i}\\\\\\end{matrix}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\\mu_{x,i}\\\\\\mu_{y,i}\\\\\\end{matrix}\\right) \\sim \\mathcal{N}\\left(\\pmb R_{inv}\\cdot \\left(\\begin{matrix}\n",
    "-1&0\\\\\n",
    "0&1\\\\\n",
    "\\end{matrix}\\right)\\cdot \\left(\\begin{matrix}\\mu_{\\mathrm{RA},i}\\\\\\mu_{\\mathrm{Dec},i}\\\\\\end{matrix}\\right), \\pmb V_{\\mu,i} =  \\pmb R_{inv}\\cdot \\pmb V_{\\mu,\\mathrm{RA,Dec},i}\\cdot \\pmb R_{inv}^T\\right)$$\n",
    "\n",
    "\n",
    "$$x_{H,i}(t) \\sim \\mathcal{N}\\left( x_{H,i}'(t), \\sigma_{H,x,i}\\right)$$\n",
    "$$y_{H,i}(t) \\sim \\mathcal{N}\\left( y_{H,i}'(t), \\sigma_{H,y,i}\\right)$$\n",
    "\n",
    "$$x_{H,i}(t+\\Delta t) = x_{H,i}'(t)+\\frac{1}{\\mathrm{HST~PS}} \\times \\left( \\mathrm{plx}'_i \\times \\frac{\\Delta \\mathrm{x}_i}{\\mathrm{plx}}+\\mu_{x,i}'\\times \\Delta t \\right) $$\n",
    "$$y_{H,i}(t+\\Delta t) = y_{H,i}'(t)+\\frac{1}{\\mathrm{HST~PS}} \\times \\left( \\mathrm{plx}'_i \\times \\frac{\\Delta \\mathrm{y}_i}{\\mathrm{plx}}+\\mu_{y,i}'\\times \\Delta t \\right) $$\n",
    "\n",
    "$$\n",
    "\\left(\\begin{matrix}\n",
    "x_{G,i}'(t+\\Delta t)\\\\\n",
    "y_{G,i}'(t+\\Delta t)\\\\\n",
    "\\end{matrix}\\right) = \\pmb R \\cdot \\left(\\begin{matrix}\n",
    "x_{H,i}'(t+\\Delta t) - X_0\\\\\n",
    "y_{H,i}'(t+\\Delta t) - Y_0\\\\\n",
    "\\end{matrix}\\right) + \\left(\\begin{matrix}\n",
    "W_0\\\\\n",
    "Z_0\\\\\n",
    "\\end{matrix}\\right)\n",
    "$$\n",
    "\n",
    "$$x_{G,i}(t+\\Delta t) \\sim \\mathcal{N}(x_{G,i}'(t+\\Delta t),\\sigma_{G,x,i})$$\n",
    "$$y_{G,i}(t+\\Delta t) \\sim \\mathcal{N}(y_{G,i}'(t+\\Delta t),\\sigma_{G,y,i})$$\n",
    "\n",
    "$$\n",
    "\\left(\\begin{matrix}\n",
    "x_{H,i}(t+\\Delta t)\\\\\n",
    "y_{H,i}(t+\\Delta t)\\\\\n",
    "\\end{matrix}\\right) \\sim \\mathcal{N}_2\\left(\\vec \\mu =  \\pmb R_{inv} \\cdot \\left(\\begin{matrix}\n",
    "x_{G,i}(t+\\Delta t) - W_0\\\\\n",
    "y_{G,i}(t+\\Delta t) - Z_0\\\\\n",
    "\\end{matrix}\\right) + \\left(\\begin{matrix}\n",
    "X_0\\\\\n",
    "Y_0\\\\\n",
    "\\end{matrix}\\right), \n",
    "\\pmb V = \\pmb V_{GH,i} = \\pmb R_{inv} \\cdot \\left(\\begin{matrix}\n",
    "\\sigma_{G,x,i}^2 & 0\\\\\n",
    "0              & \\sigma_{G,y,i}^2\\\\\n",
    "\\end{matrix}\\right) \\cdot \\pmb R_{inv}^T \\right)\n",
    "$$\n",
    "\n",
    "We arrive at the following likelihood distribution:\n",
    "\n",
    "$$p(x_{H,i}, y_{H,i}, x_{G,i}, y_{G,i} | a,b,c,d,W_0,Z_0,\\mu_{x,i},\\mu_{y,i},\\mathrm{plx}_i) = \\mathcal{N}_2\\left( \\left(\\begin{matrix}\n",
    "x_{H,i}(t+\\Delta t) - x_{H,i}(t)\\\\\n",
    "y_{H,i}(t+\\Delta t) - y_{H,i}(t)\\\\\n",
    "\\end{matrix}\\right) | \\vec \\mu = \\frac{1}{\\mathrm{HST~PS}} \\cdot \\left(\\begin{matrix}\n",
    "\\mu_{x,i}\\cdot \\Delta t + \\mathrm{plx}'_i \\times \\frac{\\Delta \\mathrm{x}_i}{\\mathrm{plx}}\\\\\n",
    "\\mu_{y,i}\\cdot \\Delta t + \\mathrm{plx}'_i \\times \\frac{\\Delta \\mathrm{y}_i}{\\mathrm{plx}}\\\\\n",
    "\\end{matrix}\\right), \n",
    "\\pmb V = \\pmb V_{T,i} = \\pmb V_{GH,i} + \\left(\\begin{matrix}\n",
    "\\sigma_{H,x,i}^2 & 0\\\\\n",
    "0              & \\sigma_{H,y,i}^2\\\\\n",
    "\\end{matrix}\\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Bayes' Rule, we have the following posterior:\n",
    "\n",
    "$$p(a,b,c,d,W_0,Z_0, \\vec \\mu_{x}, \\vec \\mu_{y}, \\vec{\\mathrm{plx}} | \\vec x_H, \\vec y_H, \\vec x_G \\vec y_G) \\propto p(a,b,c,d,W_0,Z_0) \\cdot  p(\\vec \\mu_{x}, \\vec \\mu_{y}) \\cdot p(\\vec{\\mathrm{plx}}) \\cdot p(\\vec x_H, \\vec y_H, \\vec x_G \\vec y_G | a,b,c,d,W_0,Z_0, \\vec \\mu_{x}, \\vec \\mu_{y}, \\vec{\\mathrm{plx}})\n",
    "$$\n",
    "$$\\propto p(a,b,c,d,W_0,Z_0) \\cdot \\prod_{i=1}^{n_*} p(\\mu_{x,i},\\mu_{y,i})\\cdot p(\\mathrm{plx}_i) \\cdot p(x_{H,i},y_{H,i},x_{G,i},y_{G,i} | a,b,c,d,W_0,Z_0, \\mu_{x,i}, \\mu_{y,i}, \\mathrm{plx}_i)$$\n",
    "\n",
    "Posterior full conditional on $(\\mu_{x,i},\\mu_{y,i})$:\n",
    "$$p(\\mu_{x,i},\\mu_{y,i} | \\mathrm{plx}_i, \\dots) \\propto \\mathcal{N}_2\\left( \\left(\\begin{matrix}\n",
    "\\mu_{x,i}\\\\\n",
    "\\mu_{y,i}\\\\\n",
    "\\end{matrix}\\right) | \\vec \\mu = \\vec \\mu_{i}' = \\left(\\begin{matrix}\n",
    "\\mu_{x,i}'\\\\\n",
    "\\mu_{y,i}'\\\\\n",
    "\\end{matrix}\\right),\n",
    "\\pmb V = \\pmb V_{\\mu,i} = \\left(\\begin{matrix}\n",
    "\\omega_{x,i}^2 & 0\\\\\n",
    "0              & \\omega_{y,i}^2\\\\\n",
    "\\end{matrix}\\right) \\right)\n",
    "\\cdot \\mathcal{N}_2\\left( \\left(\\begin{matrix}\n",
    "x_{H,i}(t+\\Delta t) - x_{H,i}(t) - \\frac{\\mathrm{plx}'_i}{\\mathrm{HST~PS}} \\times \\frac{\\Delta \\mathrm{x}_i}{\\mathrm{plx}}\\\\\n",
    "y_{H,i}(t+\\Delta t) - y_{H,i}(t) - \\frac{\\mathrm{plx}'_i}{\\mathrm{HST~PS}} \\times \\frac{\\Delta \\mathrm{y}_i}{\\mathrm{plx}}\\\\\n",
    "\\end{matrix}\\right) | \\vec \\mu = \\frac{\\Delta t}{\\mathrm{HST~PS}} \\cdot \\left(\\begin{matrix}\n",
    "\\mu_{x,i}\\\\\n",
    "\\mu_{y,i}\\\\\n",
    "\\end{matrix}\\right), \n",
    "\\pmb V = \\pmb V_{T,i} \\right)$$\n",
    "\n",
    "$$\\propto \\mathcal{N}_2\\left( \\left(\\begin{matrix}\n",
    "\\mu_{x,i}\\\\\n",
    "\\mu_{y,i}\\\\\n",
    "\\end{matrix}\\right) | \\vec \\mu = \\vec \\mu_{i}',\n",
    "\\pmb V = \\pmb V_{\\mu,i} \\right)\n",
    "\\cdot \\mathcal{N}_2\\left( \\left(\\begin{matrix}\n",
    "\\mu_{x,i}\\\\\n",
    "\\mu_{y,i}\\\\\n",
    "\\end{matrix}\\right) | \\vec \\mu = \\vec \\mu_{T,i} = \\frac{\\mathrm{HST~PS}}{\\Delta t} \\cdot \\left(\\begin{matrix}\n",
    "x_{H,i}(t+\\Delta t) - x_{H,i}(t)-\\frac{\\mathrm{plx}'_i}{\\mathrm{HST~PS}} \\times \\frac{\\Delta \\mathrm{x}_i}{\\mathrm{plx}}\\\\\n",
    "y_{H,i}(t+\\Delta t) - y_{H,i}(t)-\\frac{\\mathrm{plx}'_i}{\\mathrm{HST~PS}} \\times \\frac{\\Delta \\mathrm{y}_i}{\\mathrm{plx}}\\\\\n",
    "\\end{matrix}\\right), \n",
    "\\pmb V = \\left(\\frac{\\mathrm{HST~PS}}{\\Delta t}\\right)^2 \\pmb V_{T,i} \\right)$$\n",
    "\n",
    "$$\\propto \\mathcal{N}_2\\left( \\left(\\begin{matrix}\n",
    "\\mu_{x,i}\\\\\n",
    "\\mu_{y,i}\\\\\n",
    "\\end{matrix}\\right) | \\pmb V = \\pmb \\Sigma = \\left[\\pmb V_{\\mu,i}^{-1}+\\left(\\frac{\\mathrm{HST~PS}}{\\Delta t}\\right)^{-2} \\pmb V_{T,i}^{-1} \\right]^{-1}, \\vec \\mu = \\pmb \\Sigma \\cdot \\left[\\pmb V_{\\mu,i}^{-1} \\vec \\mu_{i}'+\\left(\\frac{\\mathrm{HST~PS}}{\\Delta t}\\right)^{-2} \\pmb V_{T,i}^{-1} \\vec \\mu_{T,i}\\right]\n",
    " \\right)$$\n",
    "which looks like a weighted average using the measured pixel offsets and the prior on the proper motion. \n",
    "\n",
    "Posterior full conditional on $\\mathrm{plx}_i$:\n",
    "$$p(\\mathrm{plx}_i | \\mu_{x,i},\\mu_{y,i}, \\dots) \\sim \\mathcal{N}\\left( \\mathrm{plx}'_i, \\sigma_{\\mathrm{plx},i}\\right) \\cdot \\mathcal{N}_2\\left( \\vec{\\Delta p_i} = \\left(\\begin{matrix}\n",
    "x_{H,i}(t+\\Delta t) - x_{H,i}(t) - \\mu_{x,i}\\times \\frac{\\Delta t}{\\mathrm{HST~PS}}\\\\\n",
    "y_{H,i}(t+\\Delta t) - y_{H,i}(t) - \\mu_{y,i} \\times \\frac{\\Delta t}{\\mathrm{HST~PS}}\\\\\n",
    "\\end{matrix}\\right) | \\vec \\mu = \\frac{\\mathrm{plx}'_i}{\\mathrm{HST~PS}}\\times \\vec{\\Delta \\mathrm{plx}_i}= \\frac{\\mathrm{plx}'_i}{\\mathrm{HST~PS}}\\times \\left(\\begin{matrix}\n",
    "\\frac{\\Delta \\mathrm{x}_i}{\\mathrm{plx}}\\\\\n",
    "\\frac{\\Delta \\mathrm{y}_i}{\\mathrm{plx}}\\\\\n",
    "\\end{matrix}\\right), \n",
    "\\pmb V = \\pmb V_{T,i} \\right)$$\n",
    "\n",
    "$$\\propto \\mathcal{N}\\left( \\mathrm{plx}'_i, \\sigma_{\\mathrm{plx},i}\\right) \\cdot \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2 = \\sigma_{p,i}^2 = (\\mathrm{HST~PS})^2 \\times \\left[\\vec{\\Delta \\mathrm{plx}_i}^T  \\pmb V_{T,i}^{-1} \\vec{\\Delta \\mathrm{plx}_i}\\right]^{-1}, \\mu = \\mu_{p,i}= \\frac{\\sigma_{p,i}^2}{\\mathrm{HST~PS}} \\times \\left[\\vec{\\Delta p_i}^T \\pmb V_{T,i}^{-1} \\vec{\\Delta \\mathrm{plx}_i} \\right] \\right)$$\n",
    "\n",
    "$$\\propto \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2 = \\left[ \\sigma_{p,i}^{-2} + \\sigma_{\\mathrm{plx},i}^{-2} \\right]^{-1}, \\mu = \\sigma^{2}\\times \\left[\\frac{\\mu_{p,i}}{\\sigma_{p,i}^{2}}+ \\frac{\\mathrm{plx}'_i}{\\sigma_{\\mathrm{plx},i}^2} \\right] \\right)$$\n",
    "\n",
    "We can be more efficient if we get the posterior full conditional on $\\mathrm{plx}_i$ that doesn't depend on $\\vec\\mu_i$. We can do this by remembering:\n",
    "$$p(\\mathrm{plx}_i | \\dots) = \\frac{p(\\vec \\mu_i,\\mathrm{plx}_i | \\dots)}{p(\\vec \\mu_i | \\mathrm{plx}_i, \\dots)}$$\n",
    "and that this is true for any choice of $\\vec \\mu_i$, so we choose it to be the expectation of it's posterior full conditional so that $p(\\vec \\mu_i | \\mathrm{plx}_i, \\dots)$ is a constant that we can ignore, and then:\n",
    "$$p(\\mathrm{plx}_i | \\dots) \\propto p(\\mathrm{plx}_i, \\vec \\mu_i=\\hat \\mu_i | \\dots)\\\\\n",
    " \\propto \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2 = \\left[\\sigma_{1,i}^{-2} + \\sigma_{2,i}^{-2} + \\sigma_{3,i}^{-2} \\right]^{-1}, \\mu = \\sigma^2 \\times \\left[\\frac{\\mu_{1,i}}{\\sigma_{1,i}^2} + \\frac{\\mu_{2,i}}{\\sigma_{2,i}^2} + \\frac{\\mu_{3,i}}{\\sigma_{3,i}^2} \\right] \\right)$$\n",
    "where \n",
    "$$\\sigma_{1,i}^2 = \\sigma_{\\mathrm{plx},i}^2$$\n",
    "$$\\mu_{1,i} = \\mathrm{plx}_i'$$\n",
    "\n",
    "$$\\vec a_{2,i} = \\frac{1}{\\mathrm{HST~PS}}\\cdot \\frac{\\Delta t}{\\mathrm{HST~PS}} \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{T,i}^{-1} \\cdot \\vec{\\Delta \\mathrm{plx}_i}$$\n",
    "$$\\vec b_{2,i} = \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec \\mu_{i}'-\\vec \\mu_{i}' + \\frac{\\Delta t}{\\mathrm{HST~PS}} \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{T,i}^{-1} \\cdot \\vec{\\Delta d_i}$$\n",
    "$$\\sigma_{2,i}^2 = \\left[\\vec{a_{2,i}}^T \\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec{a_{2,i}} \\right]^{-1}$$\n",
    "$$\\mu_{2,i} = \\sigma_{2,i}^2\\times \\left[\\vec{a_{2,i}}^T \\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec{b_{2,i}} \\right]$$\n",
    "\n",
    "$$\\vec a_{3,i} = \\frac{1}{\\mathrm{HST~PS}} \\left[\\vec{\\Delta \\mathrm{plx}_i} - \\left( \\frac{\\Delta t}{\\mathrm{HST~PS}}\\right)^2\\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{T,i}^{-1} \\cdot \\vec{\\Delta \\mathrm{plx}_i} \\right]$$\n",
    "$$\\vec b_{3,i} = \\vec{\\Delta d_{i}}- \\left( \\frac{\\Delta t}{\\mathrm{HST~PS}}\\right)^2\\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{T,i}^{-1} \\cdot \\vec{\\Delta d_i} - \\frac{\\Delta t}{\\mathrm{HST~PS}} \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec{\\mu_i}' $$\n",
    "$$\\sigma_{3,i}^2 = \\left[\\vec{a_{3,i}}^T \\cdot \\pmb V_{T,i}^{-1} \\cdot \\vec{a_{3,i}} \\right]^{-1}$$\n",
    "$$\\mu_{3,i} = \\sigma_{3,i}^2\\times \\left[\\vec{a_{3,i}}^T \\cdot \\pmb V_{T,i}^{-1} \\cdot \\vec{b_{3,i}} \\right]$$\n",
    "\n",
    "For a given set of transformation parameters, we can draw samples directly from $p(\\vec \\mu, \\vec{\\mathrm{plx}} | \\mathrm{trans~params}, \\dots)$, and then we can measure\n",
    "$$p(\\mathrm{trans~params} | \\dots) = \\frac{p(\\mathrm{trans~params}, \\vec \\mu, \\vec{\\mathrm{plx} | \\dots)}}{p(\\vec \\mu, \\vec{\\mathrm{plx}} | \\mathrm{trans~params}, \\dots)}$$\n",
    "and in this way, we can use fewer MCMC walkers. \n",
    "\n",
    "At each iteration:\n",
    "* Draw $(a,b,c,d,W_0,Z_0)$ samples and accept new samples using MH algorithm;\n",
    "* Draw $\\vec \\mu_i$ vectors for each star by Gibbs sampling\n",
    "* Also add in the appropriate math to include the effects of parallax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "Using the Gaia-measured values for star number $i$, which has a prior PM of $(\\mu_{x,i}',\\mu_{y,i}')$, a prior parallax of $\\mathrm{plx}_i'$, a prior initial pixel position of $(x_{H,i}'(t),y_{H,i}'(t))$ in the HST image, and a prior final pixel position of $(x_{G,i}'(t+\\Delta t),y_{G,i}'(t+\\Delta t))$ in the Gaia image:\n",
    "\n",
    "$$\\mathrm{pixel~scale~ratio} = \\sqrt{ad-bc}$$\n",
    "$$\\theta = \\arctan{\\left(\\frac{b-c}{a+d}\\right)}$$\n",
    "$$\\mathrm{on~axis~skew} = \\frac{1}{2}(a-d)$$\n",
    "$$\\mathrm{off~axis~skew} = \\frac{1}{2}(b+c)$$\n",
    "$$\\mathrm{HST~pixel~scale} = \\mathrm{HST~PS} = 50~\\mathrm{mas~yr}^{-1} \\cdot\\left(\\mathrm{pixel~scale~ratio}\\right) $$\n",
    "\n",
    "$$\\pmb R = \\left(\\begin{matrix}\n",
    "a&b\\\\\n",
    "c&d\\\\\n",
    "\\end{matrix}\\right)$$\n",
    "\n",
    "To convert between vectors/matrices in RA, Dec to vectors in Gaia's $(x,y)$ (still in units of mas):\n",
    "$$\\pmb A_{M2G} = \\left(\\begin{matrix}\n",
    "-1&0\\\\\n",
    "0&1\\\\\n",
    "\\end{matrix}\\right)$$\n",
    "and \n",
    "$$\\pmb A_{M2G,~inv} =\\pmb A_{M2G}^{-1} = \\pmb A_{M2G}$$\n",
    "\n",
    "Properties of star $i$:\n",
    "\n",
    "$$\\mathrm{parallax}_i = \\mathrm{plx}_i \\sim \\mathcal{N}\\left( \\mathrm{plx}'_i, \\sigma_{\\mathrm{plx},i}\\right)$$\n",
    "$$\\vec{\\Delta \\mathrm{plx}_i} = \\frac{1}{\\mathrm{plx}}\\left(\\begin{matrix}\\Delta \\mathrm{RA}_i\\\\ \\Delta \\mathrm{Dec}_i\\\\\\end{matrix}\\right) = \\mathrm{ORBIT~FUNCTION}(t,t+\\Delta t)$$\n",
    "\n",
    "$$\\vec \\mu_{i} = \\left(\\begin{matrix}\\mu_{\\mathrm{RA},i}\\\\\\mu_{\\mathrm{Dec},i}\\\\\\end{matrix}\\right) \\sim \\mathcal{N}\\left(\\left(\\begin{matrix}\\mu_{\\mathrm{RA},i}'\\\\\\mu_{\\mathrm{Dec},i}'\\\\\\end{matrix}\\right), \\pmb V_{\\mu,i}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\\mu_{x,G,i}\\\\\\mu_{y,G,i}\\\\\\end{matrix}\\right) = \\pmb A_{M2G} \\cdot\\left(\\begin{matrix}\\mu_{\\mathrm{RA},i}\\\\\\mu_{\\mathrm{Dec},i}\\\\\\end{matrix}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}x_{H,i}(t)\\\\y_{H,i}(t)\\\\\\end{matrix}\\right) \\sim \\mathcal{N}\\left(\\left(\\begin{matrix}x_{H,i}'(t)\\\\y_{H,i}'(t)\\\\\\end{matrix}\\right), \\pmb V_{H,i}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}x_{G,i}(t+\\Delta t)\\\\y_{G,i}(t+\\Delta t)\\\\\\end{matrix}\\right) \\sim \\mathcal{N}\\left(\\left(\\begin{matrix}x_{G,i}'(t+\\Delta t)\\\\y_{G,i}'(t+\\Delta t)\\\\\\end{matrix}\\right), \\pmb V_{G,i}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}x_{G,i}(t)\\\\y_{G,i}(t)\\\\\\end{matrix}\\right) \\sim \\mathcal{N}\\left(\\pmb R \\cdot \\left(\\begin{matrix}x_{H,i}'(t)-X_0\\\\y_{H,i}'(t)-Y_0\\\\\\end{matrix}\\right)+\\left(\\begin{matrix}W_0\\\\Z_0\\\\\\end{matrix}\\right),\\pmb R \\cdot  \\pmb V_{H,i} \\cdot\\pmb R^T  \\right)$$\n",
    "\n",
    "$$\\vec{\\Delta d_{G,i}} = \\left(\\begin{matrix}x_{G,i}(t+\\Delta t)-x_{G,i}(t)\\\\y_{G,i}(t+\\Delta t)-y_{G,i}(t)\\\\\\end{matrix}\\right) \\sim \\mathcal{N}\\left(\\vec{\\Delta d_{G,i}}' = \\left(\\begin{matrix}x_{G,i}'(t+\\Delta t)\\\\y_{G,i}'(t+\\Delta t)\\\\\\end{matrix}\\right)-\\pmb R \\cdot \\left(\\begin{matrix}x_{H,i}'(t)-X_0\\\\y_{H,i}'(t)-Y_0\\\\\\end{matrix}\\right)-\\left(\\begin{matrix}W_0\\\\Z_0\\\\\\end{matrix}\\right), \\pmb V_{d,i}= \\pmb V_{G,i}+\\pmb R \\cdot  \\pmb V_{H,i} \\cdot\\pmb R^T\\right)$$\n",
    "\n",
    "$$\\vec{\\Delta d_{G,i}} = \\frac{1}{\\mathrm{HST~PS}} \\cdot \\pmb A_{M2G} \\cdot \\left(\\vec \\mu_i\\cdot \\Delta t + \\mathrm{plx}_i \\cdot \\vec{\\Delta \\mathrm{plx}_i}\\right)$$\n",
    "\n",
    "This gives the following likelihood:\n",
    "\n",
    "$$p(x_{H,i}, y_{H,i}, x_{G,i}, y_{G,i} | a,b,c,d,W_0,Z_0,\\vec \\mu_{i},\\mathrm{plx}_i) = \\mathcal{N}_2\\left( \\vec{\\Delta d_{G,i}} | \\vec \\mu = \\frac{1}{\\mathrm{HST~PS}} \\cdot \\pmb A_{M2G} \\cdot \\left(\\vec \\mu_i\\cdot \\Delta t + \\mathrm{plx}_i \\cdot \\vec{\\Delta \\mathrm{plx}_i}\\right), \n",
    "\\pmb V = \\pmb V_{d,i} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Bayes' Rule, we have the following posterior:\n",
    "\n",
    "$$p(a,b,c,d,W_0,Z_0, \\vec \\mu, \\vec{\\mathrm{plx}} | \\vec x_H, \\vec y_H, \\vec x_G \\vec y_G) \\propto p(a,b,c,d,W_0,Z_0) \\cdot  p(\\vec \\mu) \\cdot p(\\vec{\\mathrm{plx}}) \\cdot p(\\vec x_H, \\vec y_H, \\vec x_G \\vec y_G | a,b,c,d,W_0,Z_0, \\vec \\mu, \\vec{\\mathrm{plx}})\n",
    "$$\n",
    "$$\\propto p(a,b,c,d,W_0,Z_0) \\cdot \\prod_{i=1}^{n_*} p(\\vec \\mu_{i})\\cdot p(\\mathrm{plx}_i) \\cdot p(x_{H,i},y_{H,i},x_{G,i},y_{G,i} | a,b,c,d,W_0,Z_0, \\vec \\mu_{i}, \\mathrm{plx}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the total motion of the star $i$ (in mas) to observation $j$ to be:\n",
    "$$\\vec{\\Delta m_{ij}} = \\left(\\pmb I_{2x2}\\cdot \\mathrm{plx_i} \\right)\\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\left( \\pmb I_{2x2}\\cdot \\Delta t_j\\right) \\cdot \\vec \\mu_i - \\vec{\\Delta \\theta_{i}}$$\n",
    "$$= \\pmb{\\mathrm{plx_i}}\\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\pmb{\\Delta t_j} \\cdot \\vec \\mu_i - \\vec{\\Delta \\theta_{i}}$$\n",
    "\n",
    "Then we have:\n",
    "$$\\vec{\\Delta d_{ij}} \\sim \\mathcal{N}\\left(\\pmb J_{ij} \\cdot \\vec{\\Delta m_{ij}}, \\pmb V_{d,ij}\\right)$$\n",
    "where $\\pmb J_{ij}$ is the jacobian that transforms RA,Dec offsets into offsets in planar XY (and ideally also accounts for the effect of moving from one epoch to another).\n",
    "\n",
    "Then we have the posterior full conditional $\\vec{\\Delta m_{ij}}$:\n",
    "$$p\\left(\\vec \\mu_i, \\mathrm{plx}_i, \\vec{\\Delta \\theta_i} | \\vec{\\mathrm{transform~params}}, \\dots \\right) \\propto p\\left(\\mathrm{plx}_i\\right)\\cdot p\\left(\\vec \\mu_i \\right)\\cdot p\\left(\\vec{\\Delta \\theta_i}\\right)\\cdot \\prod_{j=1}^{n_{im}} \\mathcal{N}\\left(\\vec{\\Delta d_{ij}}-\\pmb J_{ij} \\cdot \\vec{\\Delta m_{ij}}, \\pmb V_{d,ij} | \\mathrm{transform~params}_j\\right)$$\n",
    "$$\\propto p\\left(\\mathrm{plx}_i\\right)\\cdot p\\left(\\vec \\mu_i \\right)\\cdot p\\left(\\vec{\\Delta \\theta_i}\\right)\\cdot \\prod_{j=1}^{n_{im}} \\mathcal{N}\\left(\\vec{\\Delta m_{ij}} - \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}}, \\pmb J_{ij}^{-1} \\cdot \\pmb V_{d,ij} \\cdot \\pmb J_{ij}^{T,-1} \\right)$$\n",
    "$$\\propto \\exp\\left(-\\frac{1}{2\\sigma_{\\mathrm{plx},i}^2}\\left(\\mathrm{plx}_i-\\mathrm{plx}'_i\\right)^2 - \\frac{1}{2}\\left(\\vec \\mu_i-\\vec \\mu'_i\\right)^T\\cdot\\pmb V^{-1}_{\\mu,i} \\cdot \\left(\\vec \\mu_i-\\vec \\mu'_i\\right) - \\frac{1}{2}\\left(\\vec{\\Delta \\theta_i}-\\vec{\\Delta \\theta_i}'\\right)^T\\cdot\\pmb V^{-1}_{\\theta,i} \\cdot \\left(\\vec{\\Delta \\theta_i}-\\vec{\\Delta \\theta_i}'\\right)\\right) \\cdot \\\\ \\exp\\left(\\sum_{j=1}^{n_{im}} -\\frac{1}{2} \\left(\\vec{\\Delta m_{ij}} - \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right)^T \\cdot \\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\vec{\\Delta m_{ij}} - \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right) \\right)$$\n",
    "\n",
    "\n",
    "Because the math is much easier, we will assume that there is no prior correlation between the components of $\\vec{\\Delta m_{ij}}$. We know this isn't true because Gaia measures correlations between these parameters, and this will cause our priors to be more diffuse than they could be. In the future, we should do the proper math to include the correlation.\n",
    "\n",
    "Because of it's lack of coefficients, it is easiest to solve for the posterior full conditional on $\\vec{\\Delta \\theta_i}$ first:\n",
    "$$\\left(\\vec{\\Delta \\theta_i} | \\vec\\mu_i, \\mathrm{plx}_i,\\dots \\right) \\sim \\mathcal{N}\\left( \\pmb \\Sigma_{\\theta,i} = \\left[\\pmb V^{-1}_{\\theta,i}+ \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij}\\right]^{-1}, \\\\ \n",
    "\\vec \\mu_{\\theta,i} = \\pmb \\Sigma_{\\theta,i}\\cdot\\left[\\pmb V^{-1}_{\\theta,i}\\cdot \\vec{\\Delta \\theta}'_{i} + \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\pmb{\\mathrm{plx}_i} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}}+ \\pmb{\\Delta t_{j}}\\cdot \\vec\\mu_i  - \\pmb J^{-1}_{ij}\\cdot \\vec{\\Delta d_{ij}}\\right) \\right]\\right)$$\n",
    "\n",
    "With this equation in hand, and using $$p(\\vec\\mu_i, \\mathrm{plx}_i | \\dots) = \\frac{p(\\vec \\mu_i, \\mathrm{plx}_i, \\vec{\\Delta \\theta_i} | \\dots)}{p(\\vec{\\Delta \\theta_i}| \\vec\\mu_i, \\mathrm{plx}_i, \\dots)},$$\n",
    "we can plug in $\\vec{\\Delta \\theta_i} = \\vec \\mu_{\\theta,i}$ in to $p\\left(\\vec \\mu_i, \\mathrm{plx}_i, \\vec{\\Delta \\theta_i} | \\dots \\right)$ to get $p(\\vec\\mu_i, \\mathrm{plx}_i | \\dots)$. This works out to:\n",
    "$$p(\\vec\\mu_i, \\mathrm{plx}_i | \\dots) \\propto \\exp\\left(-\\frac{1}{2\\sigma_{\\mathrm{plx},i}^2}\\left(\\mathrm{plx}_i-\\mathrm{plx}'_i\\right)^2 - \\frac{1}{2}\\left(\\vec \\mu_i-\\vec \\mu'_i\\right)^T\\cdot\\pmb V^{-1}_{\\mu,i} \\cdot \\left(\\vec \\mu_i-\\vec \\mu'_i\\right) - \\frac{1}{2}\\left(\\vec \\mu_{\\theta,i}-\\vec{\\Delta \\theta_i}'\\right)^T\\cdot\\pmb V^{-1}_{\\theta,i} \\cdot \\left(\\vec \\mu_{\\theta,i}-\\vec{\\Delta \\theta_i}'\\right)\\right) \\cdot \\\\ \\exp\\left(-\\frac{1}{2}\\sum_{j=1}^{n_{im}}  \\left(\\pmb{\\mathrm{plx_i}} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\pmb{\\Delta t_{j}}\\cdot\\vec \\mu_i - \\vec \\mu_{\\theta,i} - \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right)^T \\cdot \\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\pmb{\\mathrm{plx_i}} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\pmb{\\Delta t_{j}}\\cdot\\vec \\mu_i - \\vec \\mu_{\\theta,i} - \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next easiest term to solve for is $\\vec \\mu_i$. If we rewrite $\\vec \\mu_{\\theta,i}$ to be in terms of $\\vec \\mu_i$, then we get:\n",
    "$$\\pmb A_{\\mu,i} = \\left[ \\pmb \\Sigma_{\\theta,i} \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\Delta t_{j} \\right]$$\n",
    "$$\\vec B_{\\mu,i} = \\pmb \\Sigma_{\\theta,i} \\cdot \\left[\\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} -\\pmb V_{\\theta,i}^{-1}\\cdot \\vec{\\Delta \\theta_i'}  - \\mathrm{plx}_i  \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}}\\right]$$\n",
    "\n",
    "$$\\vec \\mu_{\\theta,i} = \\pmb A_{\\mu,i} \\cdot \\vec \\mu_i - \\vec B_{\\mu,i}$$\n",
    "\n",
    "Then we have: \n",
    "$$\\mathcal{N}\\left(\\vec \\mu_{\\theta,i}-\\vec{\\Delta\\theta_i}', \\pmb V_{\\theta,i} \\right) \\implies \\mathcal{N}\\left(\\vec \\mu_i | \\pmb \\Sigma_{\\mu,\\theta,i} = \\left[ \\pmb A_{\\mu,i}^{T} \\cdot \\pmb V_{\\theta,i}^{-1} \\cdot \\pmb A_{\\mu,i} \\right]^{-1} , \\vec \\mu_{\\mu,\\theta,i} = \\pmb A_{\\mu,i}^{-1} \\cdot \\left[\\vec{\\Delta\\theta_i}'+\\vec B_{\\mu,i}\\right]  \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can define:\n",
    "$$\\pmb C_{\\mu,ij} = \\pmb{\\Delta t_j} - \\pmb A_{\\mu,i}$$\n",
    "$$\\vec{D_{\\mu,ij}} = \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}} - \\vec B_{\\mu,i} - \\pmb{\\mathrm{plx}_i} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} $$\n",
    "\n",
    "\n",
    "$$\\vec{\\Delta m_{ij}}-\\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}} = \\pmb C_{\\mu,ij} \\cdot \\vec \\mu_i - \\vec D_{\\mu,ij}$$\n",
    "\n",
    "\n",
    "So that we have: \n",
    "$$\\mathcal{N}\\left(\\vec{\\Delta m_{ij}}- \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}}, \\left[ \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1} \\cdot  \\pmb J_{ij} \\right]^{-1} \\right) \\implies \\mathcal{N}\\left(\\vec \\mu_i | \\pmb \\Sigma_{\\mu,d,ij} = \\left[  \\pmb C_{\\mu,ij}^T \\cdot \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1} \\cdot  \\pmb J_{ij} \\cdot \\pmb C_{\\mu,ij} \\right]^{-1} , \\vec \\mu_{\\mu,d,ij} = \\pmb C_{\\mu,ij}^{-1} \\cdot \\vec D_{\\mu,ij}  \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we find that the posterior full conditional is:\n",
    "$$p(\\vec \\mu_i |\\mathrm{plx}_i \\dots) \\propto \n",
    "\\mathcal{N}\\left(\\vec \\mu_i'-\\vec\\mu_i, \\pmb V_{\\mu,i}\\right) \\cdot \n",
    "\\mathcal{N}\\left(\\vec\\mu_i-\\hat \\mu_{\\mu}, \\pmb{\\hat V_{\\mu}}\\right) \\cdot \n",
    "\\mathcal{N}\\left(\\vec \\mu_i | \\pmb \\Sigma_{\\mu,\\theta,i} = \\left[ \\pmb A_{\\mu,i}^{T} \\cdot \\pmb V_{\\theta,i}^{-1} \\cdot \\pmb A_{\\mu,i} \\right]^{-1} , \\vec \\mu_{\\mu,\\theta,i} = \\pmb A_{\\mu,i}^{-1} \\cdot \\left[\\vec{\\Delta\\theta_i}'+\\vec B_{\\mu,i}\\right]  \\right) \\cdot\n",
    "\\prod_{j=1}^{n_{im}}\\mathcal{N}\\left(\\vec \\mu_i | \\pmb \\Sigma_{\\mu,d,ij} = \\left[\\pmb C_{\\mu,ij}^T \\cdot \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1} \\cdot  \\pmb J_{ij} \\cdot \\pmb C_{\\mu,ij} \\right]^{-1} , \\vec \\mu_{\\mu,d,ij} = \\pmb C_{\\mu,ij}^{-1} \\cdot \\vec D_{\\mu,ij}  \\right)\n",
    "$$\n",
    "\n",
    "Where we have also added in a (fairly diffuse) population prior on the $\\vec\\mu_i$ values (e.g. $\\vec \\mu_i \\sim \\mathcal{N}\\left(\\hat \\mu_{\\mu}, \\pmb{\\hat V_{\\mu}} \\right)$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which looks like a multiplication of a bunch of MVNs with respect to $\\mu_i$. So we arrive at the following:\n",
    "$$p(\\vec \\mu_i |\\mathrm{plx}_i \\dots) \\propto \n",
    "\\mathcal{N}\\left(\n",
    "\\pmb\\Sigma_{\\mu,i} = \\left[\\pmb V_{\\mu,i}^{-1} + \\pmb{\\hat V_{\\mu}}^{-1} +\\pmb \\Sigma_{\\mu,\\theta,i}^{-1}+\\sum_{j=1}^{n_{im}} \\pmb \\Sigma_{\\mu,d,ij}^{-1} \\right]^{-1},\\\\\n",
    "\\vec \\mu_{\\mu,i} = \\pmb\\Sigma_{\\mu,i} \\cdot \\left[ \\pmb V_{\\mu,i}^{-1}\\cdot \\vec \\mu_i' + \\pmb{\\hat V_{\\mu}}^{-1}\\cdot  \\hat \\mu_{\\mu}+\\pmb \\Sigma_{\\mu,\\theta,i}^{-1} \\cdot \\vec \\mu_{\\mu,\\theta,i} +\\sum_{j=1}^{n_{im}} \\pmb \\Sigma_{\\mu,d,ij}^{-1} \\cdot \\pmb C_{\\mu,ij}^{-1} \\cdot \\vec D_{\\mu,ij}\\right] \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same arguments as before, we can plug $\\vec \\mu_i = \\vec \\mu_{\\mu,i}$ into $p\\left(\\vec \\mu_i, \\mathrm{plx}_i | \\dots \\right)$ to get $p\\left(\\mathrm{plx}_i | \\dots \\right)$:\n",
    "$$p(\\mathrm{plx}_i | \\dots) \\propto \\exp\\left(-\\frac{1}{2\\sigma_{\\mathrm{plx},i}^2}\\left(\\mathrm{plx}_i-\\mathrm{plx}'_i\\right)^2 - \\frac{1}{2}\\left(\\vec \\mu_{\\mu,i}-\\vec \\mu'_i\\right)^T\\cdot\\pmb V^{-1}_{\\mu,i} \\cdot \\left(\\mu_{\\mu,i}-\\vec \\mu'_i\\right) - \\frac{1}{2}\\left(\\vec \\mu_{\\theta,i}-\\vec{\\Delta \\theta_i}'\\right)^T\\cdot\\pmb V^{-1}_{\\theta,i} \\cdot \\left(\\vec \\mu_{\\theta,i}-\\vec{\\Delta \\theta_i}'\\right)\\right) \\cdot \\\\ \\exp\\left(\\sum_{j=1}^{n_{im}} -\\frac{1}{2} \\left(\\pmb{\\mathrm{plx_i}} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\pmb{\\Delta t_{j}}\\cdot\\mu_{\\mu,i} - \\vec \\mu_{\\theta,i} - \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right)^T \\cdot \\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\pmb{\\mathrm{plx_i}} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\pmb{\\Delta t_{j}}\\cdot\\mu_{\\mu,i} - \\vec \\mu_{\\theta,i} - \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right) \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same arguments as before, we can plug $\\vec \\mu_i = \\vec \\mu_{\\mu,i}$ into $p\\left(\\vec \\mu_i, \\mathrm{plx}_i | \\dots \\right)$ to get $p\\left(\\mathrm{plx}_i | \\dots \\right)$:\n",
    "$$p(\\mathrm{plx}_i | \\dots) \\propto \\exp\\left(-\\frac{1}{2\\sigma_{\\mathrm{plx},i}^2}\\left(\\mathrm{plx}_i-\\mathrm{plx}'_i\\right)^2 - \\frac{1}{2}\\left(\\vec \\mu_{\\mu,i}-\\vec \\mu'_i\\right)^T\\cdot\\pmb V^{-1}_{\\mu,i} \\cdot \\left(\\mu_{\\mu,i}-\\vec \\mu'_i\\right) - \\frac{1}{2}\\left(\\vec \\mu_{\\theta,i}-\\vec{\\Delta \\theta_i}'\\right)^T\\cdot\\pmb V^{-1}_{\\theta,i} \\cdot \\left(\\vec \\mu_{\\theta,i}-\\vec{\\Delta \\theta_i}'\\right)\\right) \\cdot \\\\ \\exp\\left(\\sum_{j=1}^{n_{im}} -\\frac{1}{2(\\mathrm{PS})^2} \\left(\\pmb{\\mathrm{plx_i}} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\pmb{\\Delta t_{j}}\\cdot\\mu_{\\mu,i} - \\vec \\mu_{\\theta,i} - (\\mathrm{PS})\\cdot\\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right)^T \\cdot \\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\pmb{\\mathrm{plx_i}} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\pmb{\\Delta t_{j}}\\cdot\\mu_{\\mu,i} - \\vec \\mu_{\\theta,i} - (\\mathrm{PS})\\cdot\\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right) \\right)$$\n",
    "\n",
    "We can rewrite the definition of $\\vec \\mu_{\\mu,i}$ to be more helpful:\n",
    "$$\\vec \\mu_{\\mu,i} = \\pmb \\Sigma_{\\mu,i}\\cdot \\left[\\pmb V_{\\mu,i}^{-1}\\cdot \\vec \\mu_i' + \\pmb A_{\\mu,i}^T \\cdot \\pmb V_{\\theta,i}^{-1}\\cdot \\left[ \\vec{\\Delta\\theta}'_i - \\pmb \\Sigma_{\\theta,i}\\cdot \\left\\{ \\pmb V_{\\theta,i}^{-1}\\cdot \\vec{\\Delta\\theta}'_i+\\frac{1}{(\\mathrm{PS})^2} \\sum_{j=1}^{n_{im}}\\pmb J^T_{ij}\\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij}\\cdot \\left( \\pmb{\\mathrm{plx}_i} \\cdot \\vec{\\Delta \\mathrm{plx}}_i- (\\mathrm{PS})\\cdot\\pmb J^{-1}_{ij} \\cdot \\vec{\\Delta d}_{ij}\\right)\\right\\} \\right] + \\frac{1}{(\\mathrm{PS})^2}\\sum_{j=1}^{n_{im}} \\pmb C_{\\mu,ij}^T \\cdot \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1} \\cdot \\pmb J_{ij}\\cdot \\left[ (\\mathrm{PS})\\cdot \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}} + \\pmb\\Sigma_{\\theta,i}\\cdot \\pmb V^{-1}_{\\theta,i}\\cdot \\vec{\\Delta \\theta}'_i - \\pmb{\\mathrm{plx}_i} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} +\\frac{1}{(\\mathrm{PS})^2}\\pmb \\Sigma_{\\theta,i} \\cdot \\sum_{j=1}^{n_{im}}\\left(\\pmb J_{ij}^{T} \\cdot \\pmb V_{d,ij}^{-1} \\cdot \\pmb J_{ij} \\cdot \\left\\{\\pmb{\\mathrm{plx}_i}\\cdot \\vec{\\Delta \\mathrm{plx}_{ij}}-(\\mathrm{PS})\\cdot \\pmb J_{ij}^{-1}\\vec{\\Delta d_{ij}}\\right\\}\\right) \\right] \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite $\\vec B_{\\mu,i}$ with $\\mathrm{plx}_i$ in mind to get:\n",
    "$$\\vec B_{\\mu,i} = \\pmb \\Sigma_{\\theta,i} \\cdot \\left[\\frac{1}{(\\mathrm{PS})^2}  \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot (\\mathrm{PS})\\cdot \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} -\\pmb V_{\\theta,i}^{-1}\\cdot \\vec{\\Delta \\theta_i'}  - \\mathrm{plx}_i \\cdot \\frac{1}{(\\mathrm{PS})^2}  \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}}\\right]\\\\\n",
    "$$\n",
    "$$ = \\pmb \\Sigma_{\\theta,i} \\cdot \\left[\\frac{1}{(\\mathrm{PS})^2} \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot (\\mathrm{PS})\\cdot \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} -\\pmb V_{\\theta,i}^{-1}\\cdot \\vec{\\Delta \\theta_i'}\\right] - \\mathrm{plx}_i \\cdot \\pmb \\Sigma_{\\theta,i} \\cdot \\frac{1}{(\\mathrm{PS})^2}  \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}}\\\\\n",
    "= \\mathrm{plx}_i \\cdot \\vec{A_{\\mathrm{plx},\\mu,i}} - \\vec{B_{\\mathrm{plx},\\mu,i}}$$\n",
    "\n",
    "where\n",
    "$$\\vec{A_{\\mathrm{plx},\\mu,i}} = -\\pmb \\Sigma_{\\theta,i} \\cdot \\frac{1}{(\\mathrm{PS})^2}  \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}}$$\n",
    "$$\\vec{B_{\\mathrm{plx},\\mu,i}} = \\pmb \\Sigma_{\\theta,i} \\cdot \\left[\\pmb V_{\\theta,i}^{-1}\\cdot \\vec{\\Delta \\theta_i'} - \\frac{1}{(\\mathrm{PS})^2} \\cdot \\sum_{j=1}^{n_{im}} \\pmb J_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot (\\mathrm{PS})\\cdot \\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}} \\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets us to:\n",
    "$$\\vec \\mu_{\\mu,i} = \\pmb\\Sigma_{\\mu,i} \\cdot \\left[ \\pmb V_{\\mu,i}^{-1}\\cdot \\vec \\mu_i' + \\pmb{\\hat V_{\\mu}}^{-1}\\cdot  \\hat \\mu_{\\mu} + \\pmb \\Sigma_{\\mu,\\theta,i}^{-1} \\cdot \\pmb A_{\\mu,i}^{-1} \\cdot \\left(\\vec{\\Delta \\theta_i}' + \\mathrm{plx}_i \\cdot \\vec{A_{\\mathrm{plx},\\mu,i}} - \\vec{B_{\\mathrm{plx},\\mu,i}} \\right) \\\\\n",
    "-\\sum_{j=1}^{n_{im}} \\pmb \\Sigma_{\\mu,d,ij}^{-1} \\cdot \\pmb C_{\\mu,ij}^{-1} \\cdot \\left( \\mathrm{plx}_i \\cdot \\vec{A_{\\mathrm{plx},\\mu,i}} - \\vec{B_{\\mathrm{plx},\\mu,i}} + \\mathrm{plx}_i \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} -(\\mathrm{PS}) \\cdot \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}}  \\right) \\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\vec \\mu_{\\mu,i} = \n",
    "\\mathrm{plx}_i \\cdot \\pmb\\Sigma_{\\mu,i} \\cdot \\left[\\pmb \\Sigma_{\\mu,\\theta,i}^{-1} \\cdot \\pmb A_{\\mu,i}^{-1} \\cdot \\vec{A_{\\mathrm{plx},\\mu,i}} -\\sum_{j=1}^{n_{im}} \\pmb \\Sigma_{\\mu,d,ij}^{-1} \\cdot \\pmb C_{\\mu,ij}^{-1} \\cdot \\left(  \\vec{A_{\\mathrm{plx},\\mu,i}} + \\vec{\\Delta \\mathrm{plx}_{ij}}   \\right)\\right]\\\\\n",
    "+\\pmb\\Sigma_{\\mu,i} \\cdot \\left[\\pmb V_{\\mu,i}^{-1}\\cdot \\vec \\mu_i' + \\pmb{\\hat V_{\\mu}}^{-1}\\cdot  \\hat \\mu_{\\mu}+ \\pmb \\Sigma_{\\mu,\\theta,i}^{-1} \\cdot \\pmb A_{\\mu,i}^{-1}\\cdot  \\left( \\vec{\\Delta \\theta_i}' - \\vec{B_{\\mathrm{plx},\\mu,i}}\\right) +\\sum_{j=1}^{n_{im}} \\pmb \\Sigma_{\\mu,d,ij}^{-1} \\cdot \\pmb C_{\\mu,ij}^{-1} \\cdot \\left( \\vec{B_{\\mathrm{plx},\\mu,i}} +(\\mathrm{PS}) \\cdot \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}}  \\right)\\right] \\\\\n",
    "= \\mathrm{plx}_i \\cdot \\vec C_{\\mathrm{plx},\\mu,i} - \\vec D_{\\mathrm{plx},\\mu,i}$$\n",
    "\n",
    "where\n",
    "$$\\vec C_{\\mathrm{plx},\\mu,i} = \\pmb\\Sigma_{\\mu,i} \\cdot \\left[\\pmb \\Sigma_{\\mu,\\theta,i}^{-1} \\cdot \\pmb A_{\\mu,i}^{-1} \\cdot \\vec{A_{\\mathrm{plx},\\mu,i}} -\\sum_{j=1}^{n_{im}} \\pmb \\Sigma_{\\mu,d,ij}^{-1} \\cdot \\pmb C_{\\mu,ij}^{-1} \\cdot \\left(  \\vec{A_{\\mathrm{plx},\\mu,i}} + \\vec{\\Delta \\mathrm{plx}_{ij}}   \\right)\\right]$$\n",
    "$$\\vec D_{\\mathrm{plx},\\mu,i} = -\\pmb\\Sigma_{\\mu,i} \\cdot \\left[\\pmb V_{\\mu,i}^{-1}\\cdot \\vec \\mu_i' + \\pmb{\\hat V_{\\mu}}^{-1}\\cdot  \\hat \\mu_{\\mu}+ \\pmb \\Sigma_{\\mu,\\theta,i}^{-1} \\cdot \\pmb A_{\\mu,i}^{-1}\\cdot  \\left( \\vec{\\Delta \\theta_i}' - \\vec{B_{\\mathrm{plx},\\mu,i}}\\right) +\\sum_{j=1}^{n_{im}} \\pmb \\Sigma_{\\mu,d,ij}^{-1} \\cdot \\pmb C_{\\mu,ij}^{-1} \\cdot \\left( \\vec{B_{\\mathrm{plx},\\mu,i}} +(\\mathrm{PS}) \\cdot \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}}  \\right)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can rewrite $\\vec \\mu_{\\theta,i}$ as:\n",
    "$$\\vec \\mu_{\\theta,i} = \\pmb \\Sigma_{\\theta,i}\\cdot\\left[\\pmb V^{-1}_{\\theta,i}\\cdot \\vec{\\Delta \\theta}'_{i} + \\sum_{j=1}^{n_{im}} \\frac{1}{(\\mathrm{PS})^2}\\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\mathrm{plx}_i \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}}+ \\pmb{\\Delta t_{j}}\\cdot \\left(\\mathrm{plx}_i\\cdot \\vec{C_{\\mathrm{plx},\\mu,i}}-\\vec{D_{\\mathrm{plx},\\mu,i}} \\right)  -(\\mathrm{PS}) \\cdot \\pmb J^{-1}_{ij}\\cdot \\vec{\\Delta d_{ij}}\\right) \\right]$$\n",
    "$$= \n",
    "\\mathrm{plx}_i\\cdot \\pmb \\Sigma_{\\theta,i}\\cdot\\left[\\sum_{j=1}^{n_{im}} \\frac{1}{(\\mathrm{PS})^2}\\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\vec{\\Delta \\mathrm{plx}_{ij}}+ \\Delta t_{j}\\cdot \\vec{C_{\\mathrm{plx},\\mu,i}}\\right) \\right]\\\\\n",
    "-\\pmb \\Sigma_{\\theta,i}\\cdot\\left[\\sum_{j=1}^{n_{im}} \\frac{1}{(\\mathrm{PS})^2}\\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\Delta t_{j}\\cdot \\vec{D_{\\mathrm{plx},\\mu,i}}  +(\\mathrm{PS}) \\cdot \\pmb J^{-1}_{ij}\\cdot \\vec{\\Delta d_{ij}}\\right) -\\pmb V^{-1}_{\\theta,i}\\cdot \\vec{\\Delta \\theta}'_{i} \\right]\\\\\n",
    "= \\mathrm{plx}_i\\cdot\\vec{E_{\\mathrm{plx},\\theta,i}}-\\vec{F_{\\mathrm{plx},\\theta,i}}$$\n",
    "where \n",
    "$$\\vec{E_{\\mathrm{plx},\\theta,i}} = \\pmb \\Sigma_{\\theta,i}\\cdot\\left[\\sum_{j=1}^{n_{im}} \\frac{1}{(\\mathrm{PS})^2}\\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\vec{\\Delta \\mathrm{plx}_{ij}}+ \\Delta t_{j}\\cdot \\vec{C_{\\mathrm{plx},\\mu,i}}\\right) \\right]$$\n",
    "$$\\vec{F_{\\mathrm{plx},\\theta,i}} = \\pmb \\Sigma_{\\theta,i}\\cdot\\left[\\sum_{j=1}^{n_{im}} \\frac{1}{(\\mathrm{PS})^2}\\pmb J_{ij}^{T} \\cdot \\pmb V^{-1}_{d,ij} \\cdot \\pmb J_{ij} \\cdot \\left(\\Delta t_{j}\\cdot \\vec{D_{\\mathrm{plx},\\mu,i}}  +(\\mathrm{PS}) \\cdot \\pmb J^{-1}_{ij}\\cdot \\vec{\\Delta d_{ij}}\\right) -\\pmb V^{-1}_{\\theta,i}\\cdot \\vec{\\Delta \\theta}'_{i} \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can rewrite $\\vec{\\Delta m_{ij}}-(\\mathrm{PS})\\cdot \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}}$:\n",
    "\n",
    "$$\\vec{\\Delta m_{ij}}-(\\mathrm{PS})\\cdot \\pmb J_{ij}^{-1} \\cdot \\vec{\\Delta d_{ij}} \n",
    "= \\mathrm{plx_i} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\Delta t_{j}\\cdot\\vec \\mu_i - \\vec \\mu_{\\theta,i} - (\\mathrm{PS})\\cdot\\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}}\\\\\n",
    "= \\mathrm{plx_i} \\cdot \\vec{\\Delta \\mathrm{plx}_{ij}} + \\Delta t_{j}\\cdot\\left(\\mathrm{plx}_i\\cdot \\vec{C_{\\mathrm{plx},\\mu,i}}-\\vec{D_{\\mathrm{plx},\\mu,i}}\\right) - \\left(\\mathrm{plx}_i\\cdot \\vec{E_{\\mathrm{plx},\\theta,i}}-\\vec{F_{\\mathrm{plx},\\theta,i}}\\right) - (\\mathrm{PS})\\cdot\\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}}\\\\\n",
    "= \\mathrm{plx_i} \\cdot \\left[\\vec{\\Delta \\mathrm{plx}_{ij}} +\\Delta t_{j}\\cdot \\vec{C_{\\mathrm{plx},\\mu,i}} -\\vec{E_{\\mathrm{plx},\\theta,i}}\\right] - \\left[\\Delta t_{j}\\cdot \\vec{D_{\\mathrm{plx},\\mu,i}} - \\vec{F_{\\mathrm{plx},\\theta,i}} + (\\mathrm{PS})\\cdot\\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}}\\right]\\\\\n",
    "=\\mathrm{plx_i} \\cdot G_{\\mathrm{plx},d,ij} - \\vec H_{\\mathrm{plx},d,ij}$$\n",
    "where:\n",
    "$$\\vec G_{\\mathrm{plx},d,ij} = \\left[\\vec{\\Delta \\mathrm{plx}_{ij}} +\\Delta t_{j}\\cdot \\vec{C_{\\mathrm{plx},\\mu,i}} -\\vec{E_{\\mathrm{plx},\\theta,i}}\\right]$$\n",
    "$$\\vec H_{\\mathrm{plx},d,ij} = \\left[\\Delta t_{j}\\cdot \\vec{D_{\\mathrm{plx},\\mu,i}} - \\vec{F_{\\mathrm{plx},\\theta,i}} + (\\mathrm{PS})\\cdot\\pmb J_{ij}^{-1}\\cdot \\vec{\\Delta d_{ij}}\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can make use of the following relationship to deal with the MVNs that contain the $\\mathrm{plx}_i$ factors:\n",
    "$$\\mathcal{N}\\left(a\\cdot \\vec X-\\vec Y ,\\pmb V\\right)\\implies \\mathcal{N}\\left(a | \\sigma^2 = \\left[\\vec X^T \\cdot \\pmb V^{-1} \\cdot \\vec X \\right], \\mu = \\sigma^2\\cdot \\left[\\vec X^T \\cdot \\pmb V^{-1} \\cdot \\vec Y\\right] \\right)$$ to arrive at:\n",
    "$$p(\\mathrm{plx}_i | \\dots) \\propto \n",
    "\\mathcal{N}\\left(\\mathrm{plx}_i | \\hat\\sigma_{\\mathrm{plx}}^2, \\hat{\\mathrm{plx}} \\right) \\cdot \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2_{\\mathrm{plx},i}, \\mathrm{plx}'_i\\right) \\cdot \\\\\n",
    "\\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2_{\\mathrm{plx},\\mu,i} = \\left[\\vec C_{\\mathrm{plx},\\mu,i}^T \\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec C_{\\mathrm{plx},\\mu,i} \\right]^{-1}, \\mu_{\\mathrm{plx},\\mu,i} = \\sigma^2_{\\mathrm{plx},\\mu,i} \\cdot \\left[\\vec C_{\\mathrm{plx},\\mu,i}^T \\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\left(\\vec D_{\\mathrm{plx},\\mu,i}+\\vec\\mu_i' \\right)\\right] \\right) \\cdot \\\\\n",
    "\\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2_{\\mathrm{plx},\\mu,i} = \\left[\\vec C_{\\mathrm{plx},\\hat\\mu,i}^T \\cdot \\pmb{\\hat V_{\\mu}}^{-1} \\cdot \\vec C_{\\mathrm{plx},\\mu,i} \\right]^{-1}, \\mu_{\\mathrm{plx},\\hat\\mu,i} = \\sigma^2_{\\mathrm{plx},\\mu,i} \\cdot \\left[\\vec C_{\\mathrm{plx},\\mu,i}^T \\cdot \\pmb{\\hat V_{\\mu}}^{-1} \\cdot \\left(\\vec D_{\\mathrm{plx},\\mu,i}+\\hat \\mu_{\\mu} \\right)\\right] \\right) \\cdot \\\\\n",
    "\\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2_{\\mathrm{plx},\\theta,i} = \\left[\\vec E_{\\mathrm{plx},\\theta,i}^T \\cdot \\pmb V_{\\theta,i}^{-1} \\cdot \\vec E_{\\mathrm{plx},\\theta,i} \\right]^{-1}, \\mu_{\\mathrm{plx},\\theta,i} = \\sigma^2_{\\mathrm{plx},\\theta,i} \\cdot \\left[\\vec E_{\\mathrm{plx},\\theta,i}^T \\cdot \\pmb V_{\\theta,i}^{-1} \\cdot \\left(\\vec F_{\\mathrm{plx},\\theta,i} +\\vec{\\Delta \\theta_i}'\\right)\\right] \\right) \\cdot \\\\\n",
    "\\prod_{j=1}^{n_{im}} \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2_{\\mathrm{plx},d,ij} = \\left[\\vec G_{\\mathrm{plx},d,ij}^T \\cdot \\pmb J_{ij}^{T} \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\vec G_{\\mathrm{plx},d,ij} \\right]^{-1}, \\mu_{\\mathrm{plx},d,ij} = \\sigma^2_{\\mathrm{plx},d,ij} \\cdot \\left[ \\vec G_{\\mathrm{plx},d,ij}^T \\cdot \\pmb J_{ij}^{T} \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb J_{ij} \\cdot \\vec H_{\\mathrm{plx},d,ij} \\right] \\right)\n",
    "$$\n",
    "Where we have also added in a (fairly diffuse) population prior on the $\\mathrm{plx}_i$ values (e.g. $\\mathrm{plx}_i \\sim \\mathcal{N}\\left(\\hat{\\mathrm{plx}}, \\hat\\sigma_{\\mathrm{plx}}^2 \\right)$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ultimately works out to:\n",
    "$$p(\\mathrm{plx}_i | \\dots) = \n",
    "\\mathcal{N}\\left(\\hat{\\sigma_{\\mathrm{plx},i}}^2 = \\left[ \\hat\\sigma_{\\mathrm{plx}}^{-2}+\\sigma^{-2}_{\\mathrm{plx},i} + \\sigma^{-2}_{\\mathrm{plx},\\theta,i} + \\sigma^{-2}_{\\mathrm{plx},\\mu,i} + \\sigma^{-2}_{\\mathrm{plx},\\hat\\mu,i} + \\sum_{j=1}^{n_{im}} \\sigma^{-2}_{\\mathrm{plx},d,ij}\\right]^{-1}, \\\\\n",
    "\\hat{\\mu_{\\mathrm{plx},i}} = \\hat{\\sigma_{\\mathrm{plx},i}}^2 \\cdot \\left[ \\hat\\sigma_{\\mathrm{plx}}^{-2} \\cdot \\hat{\\mathrm{plx}}+ \\sigma^{-2}_{\\mathrm{plx},i}\\cdot \\mathrm{plx}_i' + \\sigma^{-2}_{\\mathrm{plx},\\theta,i}\\cdot\\mu_{\\mathrm{plx},\\theta,i} + \\sigma^{-2}_{\\mathrm{plx},\\mu,i}\\cdot\\mu_{\\mathrm{plx},\\mu,i} + \\sigma^{-2}_{\\mathrm{plx},\\hat\\mu,i}\\cdot\\mu_{\\mathrm{plx},\\hat\\mu,i} + \\sum_{j=1}^{n_{im}} \\sigma^{-2}_{\\mathrm{plx},d,ij} \\cdot \\mu_{\\mathrm{plx},d,ij}\\right] \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have $p(\\mathrm{plx}_i | \\dots)$ and $p(\\vec \\mu_i | \\mathrm{plx}_i, \\dots)$ and $p(\\vec{\\Delta \\theta_i} | \\vec \\mu_i, \\mathrm{plx}_i, \\dots)$, we can do the following steps for a given set of transformation parameters:\n",
    "* draw samples of $\\mathrm{plx}_i$\n",
    "* then use those $\\mathrm{plx}_i$ samples to draw samples from $\\left( \\vec \\mu_i | \\mathrm{plx}_i \\right)$\n",
    "* then use those $\\left( \\vec \\mu_i, \\mathrm{plx}_i \\right)$ samples to draw samples from $\\left( \\vec{\\Delta \\theta_i} | \\vec \\mu_i, \\mathrm{plx}_i \\right)$\n",
    "* calculate the posterior probability of the transformation parameters using: $$p(\\vec{\\mathrm{transform~params}} | \\dots) = \\frac{p(\\vec{\\mathrm{transform~params}}, \\pmb{\\vec \\mu}, \\vec{\\mathrm{plx}}, \\pmb{\\vec{\\Delta \\theta}} | \\dots)}{\\prod_{j=1}^{n_{im}} p(\\vec \\mu_i, \\mathrm{plx}_i, \\vec{\\Delta \\theta_i} | \\vec{\\mathrm{transform~params}},\\dots)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior full conditional on $\\vec \\mu_i$:\n",
    "$$p(\\vec \\mu_{i} | \\mathrm{plx}_i, \\dots) \\propto \\mathcal{N}_2\\left( \\vec \\mu_{i} | \\vec \\mu_{i}',\n",
    "\\pmb V_{\\mu,i}  \\right)\n",
    "\\cdot \\mathcal{N}_2\\left( \\vec{\\Delta d}_{G,i} - \\frac{1}{\\mathrm{HST~PS}}\\mathrm{plx}_i \\cdot \\pmb A_{M2G} \\cdot \\vec{\\Delta \\mathrm{plx}_i} | \\vec \\mu = \\frac{\\Delta t}{\\mathrm{HST~PS}} \\cdot \\pmb A_{M2G} \\cdot \\vec \\mu_i, \n",
    "\\pmb V = \\pmb V_{d,i} \\right)$$\n",
    "\n",
    "$$\\propto \\mathcal{N}_2\\left( \\vec \\mu_{i} | \\vec \\mu_{i}',\n",
    "\\pmb V_{\\mu,i}  \\right)\n",
    "\\cdot \\mathcal{N}_2\\left( \\vec \\mu_i | \\vec \\mu = \\vec \\mu_{d,\\mu,i} = \\frac{\\mathrm{HST~PS}}{\\Delta t} \\cdot \\left( \\pmb A_{M2G}\\cdot \\vec{\\Delta d}_{G,i} - \\frac{1}{\\mathrm{HST~PS}}\\mathrm{plx}_i \\cdot \\vec{\\Delta \\mathrm{plx}_i} \\right), \n",
    "\\pmb V = \\left(\\frac{\\mathrm{HST~PS}}{\\Delta t}\\right)^2 \\pmb V_{d,\\mu,i} \\right)$$\n",
    "where $$\\pmb V_{d,\\mu,i} = \\pmb A_{M2G}\\cdot \\pmb V_{d,i} \\cdot \\pmb A_{M2G} $$\n",
    "\n",
    "$$\\propto \\mathcal{N}_2\\left( \\vec \\mu_{i} | \\pmb V = \\hat{\\pmb \\Sigma_i} = \\left[\\pmb V_{\\mu,i}^{-1}+\\left(\\frac{\\mathrm{HST~PS}}{\\Delta t}\\right)^{-2} \\pmb V_{d,\\mu,i}^{-1} \\right]^{-1}, \\vec \\mu  = \\hat \\mu_i= \\hat{\\pmb \\Sigma_i} \\cdot \\left[ \\pmb V_{\\mu,i}^{-1} \\cdot \\vec \\mu_{i}'+\\left(\\frac{\\mathrm{HST~PS}}{\\Delta t}\\right)^{-2} \\pmb V_{d,\\mu,i}^{-1} \\cdot \\vec \\mu_{d,\\mu,i}\\right]\n",
    " \\right)$$\n",
    "which looks like a weighted average using the measured pixel offsets and the prior on the proper motion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the posterior full conditional on $\\mathrm{plx}_i$:\n",
    "$$p(\\mathrm{plx}_i | \\vec \\mu_{i}, \\dots) \\sim \\mathcal{N}\\left( \\mathrm{plx}'_i, \\sigma_{\\mathrm{plx},i}\\right) \\cdot \\mathcal{N}_2\\left( \\vec{\\Delta p_i} =  \\vec{\\Delta d}_{G,i} - \\frac{\\Delta t}{\\mathrm{HST~PS}} \\pmb A_{M2G} \\cdot \\vec \\mu_i | \\vec \\mu = \\frac{\\mathrm{plx}_i}{\\mathrm{HST~PS}}\\pmb A_{M2G} \\cdot \\vec{\\Delta \\mathrm{plx}_i}, \n",
    "\\pmb V = \\pmb V_{d,i} \\right)$$\n",
    "\n",
    "$$\\propto \\mathcal{N}\\left( \\mathrm{plx}'_i, \\sigma_{\\mathrm{plx},i}\\right) \\cdot \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2 = \\sigma_{p,i}^2 = (\\mathrm{HST~PS})^2 \\cdot \\left[\\vec{\\Delta \\mathrm{plx}_i}^T \\cdot \\pmb V_{d,\\mu,i}^{-1} \\cdot \\vec{\\Delta \\mathrm{plx}_i}\\right]^{-1}, \\mu = \\mu_{p,i}= \\frac{\\sigma_{p,i}^2}{\\mathrm{HST~PS}} \\cdot \\left[\\vec{\\Delta p_i}^T \\cdot \\pmb V_{d,\\mu,i}^{-1} \\cdot \\pmb A_{M2G} \\cdot \\vec{\\Delta \\mathrm{plx}_i} \\right] \\right)$$\n",
    "\n",
    "$$\\propto \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2 = \\left[ \\sigma_{p,i}^{-2} + \\sigma_{\\mathrm{plx},i}^{-2} \\right]^{-1}, \\mu = \\sigma^{2}\\cdot \\left[\\frac{\\mu_{p,i}}{\\sigma_{p,i}^{2}}+ \\frac{\\mathrm{plx}'_i}{\\sigma_{\\mathrm{plx},i}^2} \\right] \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be more efficient if we get the posterior full conditional on $\\mathrm{plx}_i$ that doesn't depend on $\\vec\\mu_i$. We can do this by remembering:\n",
    "$$p(\\mathrm{plx}_i | \\dots) = \\frac{p(\\vec \\mu_i,\\mathrm{plx}_i | \\dots)}{p(\\vec \\mu_i | \\mathrm{plx}_i, \\dots)}$$\n",
    "and that this is true for any choice of $\\vec \\mu_i$, so we choose it to be the expectation of it's posterior full conditional so that $p(\\vec \\mu_i | \\mathrm{plx}_i, \\dots)$ just contributes a few new terms that depend on $\\mathrm{plx}_i$, and then:\n",
    "$$p(\\mathrm{plx}_i | \\dots) \\propto p(\\mathrm{plx}_i, \\vec \\mu_i=\\hat \\mu_i | \\dots)\\\\\n",
    " \\propto \\mathcal{N}\\left(\\mathrm{plx}_i | \\sigma^2 = \\left[\\sigma_{1,i}^{-2} + \\sigma_{2,i}^{-2} + \\sigma_{3,i}^{-2} \\right]^{-1}, \\mu = \\sigma^2 \\cdot \\left[\\frac{\\mu_{1,i}}{\\sigma_{1,i}^2} + \\frac{\\mu_{2,i}}{\\sigma_{2,i}^2} + \\frac{\\mu_{3,i}}{\\sigma_{3,i}^2} \\right] \\right)$$\n",
    "where \n",
    "$$\\sigma_{1,i}^2 = \\sigma_{\\mathrm{plx},i}^2$$\n",
    "$$\\mu_{1,i} = \\mathrm{plx}_i'$$\n",
    "\n",
    "$$\\vec a_{2,i} = \\frac{1}{\\mathrm{HST~PS}}\\cdot \\frac{\\Delta t}{\\mathrm{HST~PS}} \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{d,\\mu,i}^{-1} \\cdot \\vec{\\Delta \\mathrm{plx}_i}$$\n",
    "$$\\vec b_{2,i} = \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec \\mu_{i}'-\\vec \\mu_{i}' + \\frac{\\Delta t}{\\mathrm{HST~PS}} \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{d,\\mu,i}^{-1} \\cdot\\pmb A_{M2G,~inv}\\cdot \\vec{\\Delta d}_{G,i} $$\n",
    "$$\\sigma_{2,i}^2 = \\left[\\vec{a_{2,i}}^T \\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec{a_{2,i}} \\right]^{-1}$$\n",
    "$$\\mu_{2,i} = \\sigma_{2,i}^2\\cdot \\left[\\vec{a_{2,i}}^T \\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec{b_{2,i}} \\right]$$\n",
    "\n",
    "$$\\vec a_{3,i} = \\frac{1}{\\mathrm{HST~PS}} \\left[\\pmb A_{M2G}\\cdot \\vec{\\Delta \\mathrm{plx}_i} - \\left( \\frac{\\Delta t}{\\mathrm{HST~PS}}\\right)^2 \\pmb A_{M2G}\\cdot \\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{d,\\mu,i}^{-1} \\cdot \\vec{\\Delta \\mathrm{plx}_i} \\right]$$\n",
    "$$\\vec b_{3,i} = \\vec{\\Delta d_{i}}- \\left( \\frac{\\Delta t}{\\mathrm{HST~PS}}\\right)^2\\pmb A_{M2G}\\cdot\\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{d,\\mu,i}^{-1} \\cdot \\pmb A_{M2G}\\cdot \\vec{\\Delta d_i} - \\frac{\\Delta t}{\\mathrm{HST~PS}} \\pmb A_{M2G}\\cdot\\hat{\\pmb \\Sigma_{i}}\\cdot \\pmb V_{\\mu,i}^{-1} \\cdot \\vec{\\mu_i}' $$\n",
    "$$\\sigma_{3,i}^2 = \\left[\\vec{a_{3,i}}^T \\cdot \\pmb V_{d,i}^{-1} \\cdot \\vec{a_{3,i}} \\right]^{-1}$$\n",
    "$$\\mu_{3,i} = \\sigma_{3,i}^2\\cdot \\left[\\vec{a_{3,i}}^T \\cdot \\pmb V_{d,i}^{-1} \\cdot \\vec{b_{3,i}} \\right]$$\n",
    "\n",
    "For a given set of transformation parameters, we can draw samples directly from $p(\\vec \\mu, \\vec{\\mathrm{plx}} | \\mathrm{trans~params}, \\dots)$, and then we can measure\n",
    "$$p(\\mathrm{trans~params} | \\dots) = \\frac{p(\\mathrm{trans~params}, \\vec \\mu, \\vec{\\mathrm{plx} | \\dots)}}{p(\\vec \\mu, \\vec{\\mathrm{plx}} | \\mathrm{trans~params}, \\dots)}$$\n",
    "and in this way, we can use fewer MCMC walkers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation relationship:\n",
    "$$\\mathrm{transform~params} = \\vec T = (a,b,c,d,W_0,Z_0)$$\n",
    "\n",
    "$$\\mathrm{HST-Gaia~Offset}_i = \\left(\\begin{matrix}x_{G,i}(t+\\Delta t)\\\\y_{G,i}(t+\\Delta t)\\\\\\end{matrix}\\right) - \\left[ \\left(\\begin{matrix}\n",
    "a&b\\\\\n",
    "c&d\\\\\n",
    "\\end{matrix}\\right) \\cdot \\left(\\begin{matrix}x_{H,i}(t)-X_0\\\\y_{H,i}(t)-Y_0\\\\\\end{matrix}\\right)+\\left(\\begin{matrix}W_0\\\\Z_0\\\\\\end{matrix}\\right)\\right]$$\n",
    "\n",
    "The likelihood is given as:\n",
    "$$\\mathrm{Observed~HST-Gaia~Offset}_i\\sim \\mathcal{N}_2 \\left(\\mathrm{offset~from~Gaia~Position}+\\mathrm{offset~from~PM}_i+\\mathrm{offset~from~parallax}_i, \\pmb V_{\\mathrm{data},i} \\right)$$\n",
    "\n",
    "The priors come from Gaia (where they exist) as:\n",
    "$$\\left( \\begin{matrix} \\Delta \\mathrm{RA}_i\\\\ \\Delta \\mathrm{Dec}_i\\end{matrix}\\right) = \\vec{\\Delta\\theta_i} \\sim \\mathcal{N}_2 \\left(\\left( \\begin{matrix} 0 \\\\ 0 \\end{matrix}\\right), \\pmb V_{\\mathrm{Gaia~Pos},i} \\right)$$\n",
    "\n",
    "$$\\mathrm{PM}_i = \\vec \\mu_i \\sim \\mathcal{N}_2 \\left(\\mathrm{Gaia~PM}_i, \\pmb V_{\\mathrm{Gaia~PM},i} \\right)$$\n",
    "\n",
    "$$\\mathrm{parallax}_i = \\mathrm{plx}_i \\sim \\mathcal{N} \\left(\\mathrm{Gaia~parallax}_i, \\sigma^2_{\\mathrm{Gaia~parallax},i}\\right)$$\n",
    "\n",
    "The posterior distribution is then: \n",
    "$$p(\\vec T, \\vec{\\Delta\\theta}, \\vec \\mu, \\vec{\\mathrm{plx}} | \\vec x_H, \\vec y_H, \\vec x_G \\vec y_G) \\propto p(\\vec T) \\cdot \\prod_{i=1}^{n_*} p(\\vec{\\Delta\\theta_i}) \\cdot p(\\vec \\mu_{i})\\cdot p(\\mathrm{plx}_i) \\cdot p(x_{H,i},y_{H,i},x_{G,i},y_{G,i} | \\vec T, \\vec{\\Delta\\theta_i}, \\vec \\mu_{i}, \\mathrm{plx}_i)$$\n",
    "\n",
    "Because of the conjugacy between the priors and likelihood, we are able to quickly get samples of $\\left(\\vec{\\Delta\\theta_i}, \\vec \\mu_{i}, \\mathrm{plx}_i | \\vec T, \\mathrm{data}\\right)$ directly from the posterior conditional distributions without requiring the slow step of MCMC sampling. \n",
    "\n",
    "We can quickly evaluate $$p\\left(\\vec T | \\mathrm{data}\\right) = \\frac{p\\left(\\vec T, \\vec{\\Delta\\theta}, \\vec \\mu, \\vec{\\mathrm{plx}} | \\mathrm{data}\\right)}{p\\left(\\vec{\\Delta\\theta}, \\vec \\mu, \\vec{\\mathrm{plx}} | \\vec T, \\mathrm{data}\\right)}$$ and find the tranformation parameters using MCMC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining the star index number $i\\in\\left\\{1,\\dots,n_*\\right\\}$ and the image index number $j\\in\\left\\{1,\\dots,n_{im}\\right\\}$. \n",
    "\n",
    "The scaling/transformation matrix for image $j$ is:\n",
    "$$\\pmb R_{j} =\\left(\\begin{matrix}\n",
    "a_j & b_j\\\\\n",
    "c_j & d_j\\\\\n",
    "\\end{matrix}\\right)$$\n",
    "such that we can change the XY location of pixels in HST into an XY location of pixels in Gaia with:\n",
    "$$\\vec x_{HG,ij} = \\pmb R_j \\cdot \\vec x_{H,ij} + \\vec W_j$$\n",
    "which has a data covariance matrix of:\n",
    "$$\\pmb V_{d,ij} = \\pmb R_j \\cdot V_{H,ij} \\cdot \\pmb R_j^T$$\n",
    "and then we define the following to help with the math later:\n",
    "$$\\vec{\\Delta d_{ij}} = \\vec x_{G,ij}-\\pmb R_j \\cdot \\vec x_{H,ij}$$\n",
    "\n",
    "The vector of values that can cause a star's initial position to be different from it's final position is given by:\n",
    "$$\\vec v_i = \\left( \\begin{matrix}\\Delta\\mathrm{RA}_i\\\\ \\Delta\\mathrm{Dec}_i\\\\ \\mu_{\\mathrm{RA},i}\\\\ \\mu_{\\mathrm{Dec},i}\\\\ \\mathrm{plx}_i\\end{matrix}\\right)$$\n",
    "which has the following prior distribution from Gaia measurements\n",
    "$$\\vec v_i \\sim \\mathcal{N}\\left(\\vec v_{G,i}, \\pmb V_{G,i} \\right)$$\n",
    "\n",
    "The relationship between the target's position in Gaia and HST is given by:\n",
    "$$\\vec{\\Delta d}_{ij} -\\vec{W}_{j} - \\pmb A_{ij} \\cdot \\pmb B_{ij} \\cdot \\vec v_{i} = \\vec 0$$\n",
    "where $$\\pmb B_{ij} =\\left(\\begin{matrix}\n",
    "1 & 0 & \\Delta t_{ij} & 0 & \\Delta \\mathrm{RA}_{\\mathrm{plx},ij} \\\\\n",
    "0 & 1 & 0 &\\Delta t_{ij} & \\Delta \\mathrm{Dec}_{\\mathrm{plx},ij} \\\\\n",
    "\\end{matrix}\\right)$$\n",
    "and $\\pmb A_{ij}$ is the jacobian that allows the transformation from mas in RA and Dec to \"Gaia Pixels\" (i.e. it includes the transformation from polar to planar coordinates, and then includes the pixel scale factor). Ideally, this will also include the effect of moving from one epoch to another (e.g. J2016 of Gaia to the observation time of the HST image).\n",
    "\n",
    "The full posterior distribution is then:\n",
    "$$p(\\mathrm{transform~params},\\vec W_1,\\dots,\\vec W_{n_{im}},\\vec v_{1},\\dots,\\vec v_{n_*} | \\mathrm{data}, \\mathrm{Gaia~measures}) \\propto p(\\mathrm{transform~params})\\prod_{j=1}^{n_{im}} p(\\vec W_j) \\prod_{i=1}^{n_*} p(\\vec v_{i}) p(\\mathrm{data}_{ij} | \\mathrm{transform~params}, W_{j}, \\vec v_i)$$\n",
    "\n",
    "We get the posterior full conditionals on the $\\vec v_i$ vectors as follows:\n",
    "$$\\left(\\vec v_i | \\mathrm{transform~params}_j, \\vec W_j\\right) \\sim \\mathcal{N}\\left( \\pmb \\Sigma_{i} = \\left( \\pmb V_{G,i}^{-1} +  \\sum_{j}^{n_{im}}\\pmb B_{ij}^T \\cdot \\pmb A_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb A_{ij}^T\\cdot \\pmb B_{ij}^T\\right)^{-1}, \\hat v_i = \\pmb \\Sigma_i \\cdot \\left(\\pmb V_{G,i}^{-1}\\cdot \\vec v_{G,i} + \\sum_{j}^{n_{im}}\\pmb B_{ij}^T \\cdot \\pmb A_{ij}^T\\cdot \\pmb V_{d,ij}^{-1}\\left[ \\vec{\\Delta d_{ij}} - \\vec W_{j}\\right] \\right) \\right)$$\n",
    "\n",
    "The posterior full conditional on $\\vec W_j$ is then:\n",
    "$$p\\left(\\vec W_1, \\cdots \\vec W_{n_{im}} | \\mathrm{transform~params}, \\vec v_1,\\dots, \\vec v_{n_*}\\right) = \\frac{p\\left(\\vec W_1, \\cdots \\vec W_{n_{im}}, \\vec v_1, \\dots, \\vec v_{n_*} | \\mathrm{transform~params} \\right)}{p\\left(\\vec v_1, \\dots, \\vec v_{n_*} | \\mathrm{transform~params}, \\vec W_1, \\cdots \\vec W_{n_{im}}\\right)}$$\n",
    "and since this is true for any choice of $\\vec v_i$, we can choose $\\vec v_i = \\hat v_i$, which makes the denominator a constant that we can ignore (all the $\\vec W_j$ terms cancel out), and we only need to evaluate the numerator with $\\vec v_i = \\hat v_i$:\n",
    "$$p\\left(\\vec W_1, \\cdots \\vec W_{n_{im}} | \\mathrm{transform~params}, \\vec v_1,\\dots, \\vec v_{n_*}\\right) \\propto p\\left(\\vec W_1, \\cdots \\vec W_{n_{im}}, \\hat v_1, \\dots, \\hat v_{n_*} | \\mathrm{transform~params} \\right)$$\n",
    "$$\\propto \\prod_{j=1}^{n_{im}} p(\\vec W_j) \\prod_{i=1}^{n_*} \\mathcal{N}\\left(\\vec{\\Delta d_{ij}} - \\vec W_j - \\pmb A_{ij} \\cdot \\pmb B_{ij} \\cdot \\hat v_i, \\pmb V_{d,ij} | \\mathrm{transform~params}_j \\right)$$\n",
    "$$\\propto \\prod_{j=1}^{n_{im}} p(\\vec W_j) \\prod_{i=1}^{n_*} \\mathcal{N}\\left(\\vec{\\Delta d_{ij}} - \\pmb A_{ij} \\cdot \\pmb B_{ij}\\cdot\\pmb \\Sigma_i \\cdot \\left[ \\sum_{k=1}^{n_{im}} \\pmb B_{ik}^T \\cdot \\pmb A_{ik}^T \\cdot \\pmb V_{d,ik}^{-1} \\cdot \\vec{\\Delta d_{ik}} \\right] - \\pmb A_{ij} \\cdot \\pmb B_{ij}\\cdot\\pmb \\Sigma_i \\cdot \\pmb V_{d,ij}^{-1} \\cdot \\vec v_{G,i} - \\pmb A_{ij} \\cdot \\pmb B_{ij}\\cdot\\pmb \\Sigma_i \\cdot \\left[ \\sum_{k=1,k\\neq j}^{n_{im}} \\pmb B_{ik}^T\\cdot \\pmb A_{ik}^T \\cdot \\pmb V_{d,ik}^{-1} \\cdot \\vec W_k\\right]- \\left[\\pmb I_{2x2}+\\pmb A_{ij} \\cdot \\pmb B_{ij}\\cdot \\pmb \\Sigma_i \\cdot \\pmb B_{ij}^T \\cdot \\pmb A_{ij}^T \\cdot \\pmb V_{d,ij}^{-1} \\right] \\cdot \\vec W_j, \\pmb V_{d,ij} | \\mathrm{transform~params}_j \\right)$$\n",
    "\n",
    "To make the math a little easier, we define:\n",
    "$$\\vec{\\Delta_{ij}} = \\vec{\\Delta d_{ij}} - \\pmb A_{ij} \\cdot \\pmb B_{ij}\\cdot\\pmb \\Sigma_i \\cdot \\left[ \\sum_{k=1}^{n_{im}} \\pmb B_{ik}^T \\cdot \\pmb A_{ik}^T \\cdot \\pmb V_{d,ik}^{-1} \\cdot \\vec{\\Delta d_{ik}} \\right] - \\pmb A_{ij} \\cdot \\pmb B_{ij}\\cdot\\pmb \\Sigma_i \\cdot \\pmb V_{d,ij}^{-1} \\cdot \\vec v_{G,i}$$\n",
    "and\n",
    "$$\\pmb G_{ij} = \\left(\\pmb A_{i1} \\cdot \\pmb B_{i1}\\cdot \\pmb \\Sigma_i \\cdot\\pmb B_{i1}^T\\cdot \\pmb A_{i1}^T \\cdot \\pmb V_{d,i1}^{-1}, \\dots, \\left[\\pmb I_{2x2}+\\pmb A_{ij} \\cdot \\pmb B_{ij}\\cdot \\pmb \\Sigma_i \\cdot \\pmb B_{ij}^T \\cdot \\pmb A_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\right],\\dots,  \\pmb A_{in_{im}} \\cdot \\pmb B_{in_{im}}\\cdot \\pmb \\Sigma_i \\cdot \\pmb B_{in_{im}}^T\\cdot \\pmb A_{in_{im}}^T \\cdot \\pmb V_{d,in_{im}}^{-1} \\right)$$\n",
    "and $$\\vec W^T = \\left(\\vec W_1^T,\\dots \\vec W_{n_{im}}^T \\right)$$\n",
    "\n",
    "The posterior full conditional on $\\vec W_j$ is then:\n",
    "$$ \\propto p(\\vec W) \\prod_{j=1}^{n_{im}}  \\prod_{i=1}^{n_*} \\mathcal{N}\\left(\\pmb G_{ij}\\cdot\\vec W -\\vec{\\Delta_{ij}}, \\pmb V_{d,ij} | \\mathrm{transform~params}_j \\right)$$\n",
    "\n",
    "We choose to use a flat (or infinitely large covariance MVN) prior on $\\vec W$), such that we end up with:\n",
    "$$p(\\vec W | \\vec{\\mathrm{transform~params}}) = \\mathcal{N}\\left(\\pmb \\Sigma_W = \\left[\\sum_{j=1}^{n_{im}}\\sum_{i=1}^{n_*} \\pmb G_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\pmb G_{ij} \\right]^{-1}, \\vec \\mu_W = \\pmb \\Sigma_W \\cdot \\left[ \\sum_{j=1}^{n_{im}}\\sum_{i=1}^{n_*} \\pmb G_{ij}^T \\cdot \\pmb V_{d,ij}^{-1}\\cdot \\vec{\\Delta_{ij}} \\right]\\right)$$\n",
    "\n",
    "With these equations, we can draw samples of the transformation parameters using MCMC, then immediately draw the corresponding samples of $\\vec W_j$, and then draw the samples of $\\vec v_i$. We can then use these samples to measure the posterior probability of the transformation parameters to get to the next MCMC step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the best steps so far:\n",
    "* Use the first outputs from GaiaHub to transform the distribution on each star's $\\vec x_{HST}$ to $\\vec {\\mathrm{RA,~Dec}}$ (using the transformation parameters and the center RA, Dec of the HST image), so that the comparison with Gaia priors can be in physical units\n",
    "* During the fitting, use the currently-drawn transformation parameters to get new coordinates of in $\\vec {\\mathrm{RA,~Dec}}$, using the same covariance matrix as before (this is the main assumption)\n",
    "* Do Gibbs sampling to get samples of $\\vec v$ for each star (posterior is multivariate normal), then update $W_0,Z_0$ (posterior is multivariate normal), then update the transformation parameters (posterior is Wishart distribution, https://en.wikipedia.org/wiki/Wishart_distribution)\n",
    "* This should go much faster than MCMC sampling\n",
    "\n",
    "For the transformation matrix parameters, the posterior distribution will be a Wishart on $\\pmb R\\cdot \\pmb V \\cdot \\pmb R^T$, so after getting a sample, we will need to solve for the different parameters of the transformation:\n",
    "$$\\pmb R\\cdot \\pmb V \\cdot \\pmb R^T = \\pmb \\Sigma$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\n",
    "a & b \\\\\n",
    "c & d \\\\\n",
    "\\end{matrix}\\right) \\cdot \\left(\\begin{matrix}\n",
    "v_{1}^2 & \\rho_v v_1 v_2 \\\\\n",
    "\\rho_v v_1 v_2 & v_2^2 \\\\\n",
    "\\end{matrix}\\right) \\cdot \\left(\\begin{matrix}\n",
    "a & c \\\\\n",
    "b & d \\\\\n",
    "\\end{matrix}\\right) = \\left(\\begin{matrix}\n",
    "\\sigma_{1}^2 & \\rho_\\sigma \\sigma_1 \\sigma_2 \\\\\n",
    "\\rho_\\sigma \\sigma_1 \\sigma_2 & \\sigma_2^2 \\\\\n",
    "\\end{matrix}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\n",
    "a^2 v_{1}^2 + 2ab \\rho_v v_1 v_2 + b^2 v_2^2 & ac v_{1}^2 + \\rho_v v_1 v_2 (ad+bc) + bd v_2^2 \\\\\n",
    "ac v_{1}^2 + \\rho_v v_1 v_2 (ad+bc) + bd v_2^2 &  c^2 v_{1}^2 + 2cd \\rho_v v_1 v_2 + d^2 v_2^2\\\\\n",
    "\\end{matrix}\\right) = \\left(\\begin{matrix}\n",
    "\\sigma_{1}^2 & \\rho_\\sigma \\sigma_1 \\sigma_2 \\\\\n",
    "\\rho_\\sigma \\sigma_1 \\sigma_2 & \\sigma_2^2 \\\\\n",
    "\\end{matrix}\\right)$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\n",
    "a^2 v_{1}^2 + 2ab \\rho_v v_1 v_2 + b^2 v_2^2-\\sigma_{1}^2 & ac v_{1}^2 + \\rho_v v_1 v_2 (ad+bc) + bd v_2^2 -\\rho_\\sigma \\sigma_1 \\sigma_2\\\\\n",
    "ac v_{1}^2 + \\rho_v v_1 v_2 (ad+bc) + bd v_2^2 -\\rho_\\sigma \\sigma_1 \\sigma_2&  c^2 v_{1}^2 + 2cd \\rho_v v_1 v_2 + d^2 v_2^2-\\sigma_2^2\\\\\n",
    "\\end{matrix}\\right) = 0\\cdot \\pmb I_{2x2}$$\n",
    "\n",
    "$$\\left(\\begin{matrix}\n",
    "a^2 & 2ab   & b^2 \\\\\n",
    "ac  & ad+bc & bd  \\\\\n",
    "c^2 & 2cd   & d^2\n",
    "\\end{matrix}\\right) \\cdot \\left(\\begin{matrix}\n",
    "v_{1}^2\\\\\n",
    "\\rho_v v_1 v_2\\\\\n",
    "v_{2}^2\n",
    "\\end{matrix}\\right) = \\left(\\begin{matrix}\n",
    "\\sigma_{1}^2\\\\\n",
    "\\rho_\\sigma \\sigma_1 \\sigma_2\\\\\n",
    "\\sigma_{2}^2\n",
    "\\end{matrix}\\right)$$\n",
    "\n",
    "\n",
    "To transform RA,Dec ($\\alpha,\\delta$) into radians in plane of the detector, we use the center of the image ($\\alpha_0,\\delta_0$) as follows:\n",
    "$$X = \\frac{\\cos(\\delta)\\sin(\\alpha-\\alpha_0)}{\\cos(\\delta_0)\\cos(\\delta)\\cos(\\alpha-\\alpha_0)+\\sin(\\delta)\\sin{\\delta_0}}$$\n",
    "\n",
    "$$Y = \\frac{\\sin(\\delta_0)\\cos(\\delta)\\cos(\\alpha-\\alpha_0)-\\cos(\\delta_0\\sin(\\delta))}{\\cos(\\delta_0)\\cos(\\delta)\\cos(\\alpha-\\alpha_0)+\\sin(\\delta)\\sin{\\delta_0}}$$\n",
    "\n",
    "When we need to apply offsets, we have to use the following:\n",
    "$$\\left(\\begin{matrix}\n",
    "\\Delta X \\\\\n",
    "\\Delta Y \\\\\n",
    "\\end{matrix}\\right) = \\left(\\begin{matrix}\n",
    "\\frac{dX}{d\\alpha} & \\frac{dX}{d\\delta} \\\\\n",
    "\\frac{dY}{d\\alpha} & \\frac{dY}{d\\delta} \\\\\n",
    "\\end{matrix}\\right)\\cdot \\left(\\begin{matrix}\n",
    "\\Delta \\alpha \\\\\n",
    "\\Delta \\delta \\\\\n",
    "\\end{matrix}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3aed35897887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnew_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i,j->ij'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_vect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_vect_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hst_gaia_pm_env/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hst_gaia_pm_env/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "c1,c12,c2 = 0.1**2,0.1*0.7*0.9,0.7**2\n",
    "sigma_mat = np.array([[c1,c12],[c12,c2]])\n",
    "v1,v12,v2 = 5**2,5*0.2*(-0.6),0.2**2\n",
    "v_mat = np.array([[v1,v12],[v12,v2]])\n",
    "\n",
    "v_vect = np.array([v1,v12,v2])\n",
    "v_vect_inv = np.array([1/v1,1/v12,1/v2])/len(v_vect)\n",
    "new_mat = np.einsum('i,j->ij',v_vect,v_vect_inv)\n",
    "\n",
    "#np.dot(np.array([c1,c12,c2]),np.linalg.inv(new_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.06935415e-01  3.42815089e-04]\n",
      " [ 2.42406845e-04 -1.00000006e+00]]\n",
      "[[ 7.06935405e-01  3.42804804e-04]\n",
      " [ 2.42399573e-04 -1.00000006e+00]]\n",
      "[[1.00000001 1.00003   ]\n",
      " [1.00003    1.        ]]\n",
      "\n",
      "center jacobian\n",
      "[[ 0.70710678 -0.        ]\n",
      " [ 0.         -1.        ]]\n",
      "\n",
      "max,max jacobian\n",
      "[[ 7.06755782e-01 -3.51042718e-04]\n",
      " [-2.48224564e-04 -1.00000025e+00]]\n",
      "\n",
      "min,max jacobian\n",
      "[[ 7.06755782e-01  3.51042718e-04]\n",
      " [ 2.48224564e-04 -1.00000025e+00]]\n",
      "\n",
      "max,min jacobian\n",
      "[[ 7.07457867e-01 -3.51042718e-04]\n",
      " [-2.48224564e-04 -1.00000025e+00]]\n",
      "\n",
      "min,min jacobian\n",
      "[[ 7.07457867e-01  3.51042718e-04]\n",
      " [ 2.48224564e-04 -1.00000025e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#positions in degrees\n",
    "ra0 = 315\n",
    "dec0 = 45 \n",
    "ratio = 50 #mas/pixel\n",
    "offset_ra = -2000*ratio/1000/3600\n",
    "offset_dec = 1000*ratio/1000/3600\n",
    "ra = ra0+offset_ra\n",
    "dec = dec0+offset_dec\n",
    "#motion values\n",
    "time = 15 #years\n",
    "delta_ra = (80*time)/1000/3600\n",
    "delta_dec = (-20*time)/1000/3600\n",
    "\n",
    "#offset of position we expect for bad stars \n",
    "delta_ra = (3)/1000/3600\n",
    "delta_dec = (3)/1000/3600\n",
    "\n",
    "#change to radians\n",
    "ra *= np.pi/180\n",
    "ra0 *= np.pi/180\n",
    "dec *= np.pi/180\n",
    "dec0 *= np.pi/180\n",
    "delta_ra *= np.pi/180\n",
    "delta_dec *= np.pi/180\n",
    "\n",
    "ra_max = ra0+(2048*ratio/1000/3600)*np.pi/180\n",
    "ra_min = ra0-(2048*ratio/1000/3600)*np.pi/180\n",
    "dec_max = dec0+(2048*ratio/1000/3600)*np.pi/180\n",
    "dec_min = dec0-(2048*ratio/1000/3600)*np.pi/180\n",
    "\n",
    "denom = np.cos(dec0)*np.cos(dec)*np.cos(ra-ra0)+np.sin(dec)*np.sin(dec0)\n",
    "if np.isinf(denom):\n",
    "    denom = np.sign(denom)*1e-100\n",
    "\n",
    "#remember, (X0,Y0)=(0,0)\n",
    "X = (np.cos(dec)*np.sin(ra-ra0))/denom\n",
    "Y = (np.sin(dec0)*np.cos(dec)*np.cos(ra-ra0)-np.cos(dec0)*np.sin(dec))/denom\n",
    "\n",
    "def offset_jac(ra,dec):\n",
    "    denom = np.cos(dec0)*np.cos(dec)*np.cos(ra-ra0)+np.sin(dec)*np.sin(dec0)\n",
    "    if np.isinf(denom):\n",
    "        denom = np.sign(denom)*1e-100\n",
    "    ddenom_dra = (-1*denom**-2*(-1*np.cos(dec0)*np.cos(dec)*np.sin(ra-ra0)))\n",
    "    ddenom_ddec = (-1*denom**-2*(-1*np.cos(dec0)*np.sin(dec)*np.cos(ra-ra0)+np.cos(dec)*np.sin(dec0)))\n",
    "    dxdra = (np.cos(dec)*np.cos(ra-ra0))/denom+\\\n",
    "            (np.cos(dec)*np.sin(ra-ra0))*ddenom_dra\n",
    "    dxddec = (-1*np.sin(dec)*np.sin(ra-ra0))/denom+\\\n",
    "             (np.cos(dec)*np.sin(ra-ra0))*ddenom_ddec\n",
    "    dydra = (-1*np.sin(dec0)*np.cos(dec)*np.sin(ra-ra0))/denom+\\\n",
    "            (np.sin(dec0)*np.cos(dec)*np.cos(ra-ra0)-np.cos(dec0)*np.sin(dec))*ddenom_dra\n",
    "    dyddec = (-1*np.sin(dec0)*np.sin(dec)*np.cos(ra-ra0)-np.cos(dec0)*np.cos(dec))/denom+\\\n",
    "             (np.sin(dec0)*np.cos(dec)*np.cos(ra-ra0)-np.cos(dec0)*np.sin(dec))*ddenom_ddec\n",
    "    jac = np.array([[dxdra,dxddec],[dydra,dyddec]])\n",
    "    return jac\n",
    "\n",
    "print(offset_jac(ra,dec))\n",
    "print(offset_jac(ra+delta_ra,dec+delta_dec))\n",
    "print(offset_jac(ra,dec)/offset_jac(ra+delta_ra,dec+delta_dec))\n",
    "\n",
    "radec_pair_names = ['center','max,max','min,max','max,min','min,min']\n",
    "radec_pairs = np.array([[ra0,dec0],[ra_max,dec_max],[ra_min,dec_max],[ra_max,dec_min],[ra_min,dec_min]])\n",
    "for j,radec_pair in enumerate(radec_pairs):\n",
    "    jac = offset_jac(radec_pair[0],radec_pair[1])\n",
    "    print()\n",
    "    print(radec_pair_names[j],'jacobian')\n",
    "    print(jac)\n",
    "    \n",
    "#     if j == 0:\n",
    "#         first_jac = jac\n",
    "#     print(radec_pair_names[j],'jacobian ratio')\n",
    "#     print(jac/first_jac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each target index $i$, there is a true value $\\theta_i$ that we want to find. We have prior information from previous studies (e.g. Gaia) about what the true value might be and how confident we are:\n",
    "$$y_i \\sim \\mathcal{N}\\left(\\theta_i,\\sigma_{i}^2 \\right)$$\n",
    "This says \"the measured value for target $i$ from the previous study is distributed around the truth based on uncertainty $\\sigma_i$\". Because of physical laws, we know that a directly-observable property of target $i$, $x_i$, is related to $\\theta_i$ by:\n",
    "$$x_i = m \\theta_i + b$$\n",
    "and we have actual measurement $x'_i$ with uncertainty $\\sigma_{x,i}$. As before, this means that the true observable value is related to the actually-measured observable by:\n",
    "$$x'_i \\sim \\mathcal{N}\\left(x_i,\\sigma_{x,i}^2 \\right) = \\mathcal{N}\\left(m \\theta_i + b,\\sigma_{x,i}^2 \\right)$$\n",
    "which we can use to define the likelihood of the measured data as:\n",
    "$$\\prod_{i}^n p(x'_i | m,b,\\theta_i,\\sigma_{x,i}) = \\prod_{i}^n \\mathcal{N}(x'_i | m\\theta_i+b,\\sigma_{x,i})$$\n",
    "\n",
    "We are interested in simulataneously measuring the $\\vec \\theta$ vector as well as $m$ and $b$. The posterior probability is given by Bayes Law:\n",
    "$$p\\left(m,b,\\vec \\theta | \\vec x', \\vec \\sigma_{x}, \\vec \\sigma_i \\right) \\propto p(m,b)\\prod_{i=1}^{n} p(x'_i | m,b,\\theta_i,\\sigma_{x,i}) p(\\theta_i | y_i, \\sigma_i)$$\n",
    "where we can choose some prior distribution for $p(m,b)$ and  is the likelihood. \n",
    "\n",
    "At this point, we could naively plug this into some MCMC algorithm to solve for all the $\\theta_i$ value and $m$ and $b$ together. However, this becomes really slow and inefficient even for moderate numbers of measurements (e.g. $n=10$). We can instead get much further by recognizing that the terms that involve $\\theta_i$ are all normal distributions, so they are therefore conjugate, and we are able to combine them easily to get back another normal distribution. Specifically, we can collect all terms with $\\theta_i$ and see that posterior full conditional on $\\theta_i$ is given by:\n",
    "$$p(\\theta_i | m,b, x_i, \\sigma_{x,i}, \\sigma_i) = \\mathcal{N}\\left(\\mu = \\frac{\\frac{1}{\\sigma_i^2}y_i+\\frac{m^2}{\\sigma_{x,i}^2}\\frac{(x_i-b)}{m}}{\\frac{1}{\\sigma_i^2}+\\frac{m^2}{\\sigma_{x,i}^2}}, \\sigma^2 = \\left[\\frac{1}{\\sigma_i^2}+\\frac{m^2}{\\sigma_{x,i}^2} \\right]^{-1}\\right)$$\n",
    "which looks like an inverse variance weighted average of the measurement implied by the data and the measurement implied by the prior. \n",
    "\n",
    "\n",
    "Now, because we have a nicely-defined distribution for $\\theta_i$ given any choice of $m$ and $b$, we are very quickly able to draw samples from $(\\theta_i | m,b,\\dots)$ without having to use some kind of MCMC algorithm. There is another benefit in that fact that we can use the following relationship to get faster samples of $m$ and $b$ if we do need to use MCMC to sample these parameters:\n",
    "$$p(m,b|\\dots) = \\frac{p(m,b,\\vec\\theta| \\dots)}{p(\\vec \\theta| m,b,\\dots)} = \\frac{p(m,b,\\vec\\theta| \\dots)}{\\prod_i^n p(\\theta_i| m,b,\\dots)}$$\n",
    "and we see that this relationship is true regarless of our choice of $\\theta_i$. This means we can use a current draw of $m$ and $b$ to get samples of $\\vec \\theta$, and then we can immediately evaluate $p(m,b|\\dots)$, which is what we need to be able to do MCMC on these parameters alone. \n",
    "\n",
    "Ultimately, this means that our process to get samples of $m$, $b$, and $\\vec \\theta$ quickly will be to:\n",
    "* initialize walkers with some first guesses of $m$ and $b$;\n",
    "* draw corresponding samples of $\\vec \\theta$ from $p(\\theta_i | m,b, \\dots)$ for all $i$;\n",
    "* use the $\\vec \\theta$ and $m$ and $b$ draws to evaluate $p(m,b|\\dots)$;\n",
    "* do MCMC while repeating this process to get new samples of $m$ and $b$, which quickly give new samples of $\\vec \\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
